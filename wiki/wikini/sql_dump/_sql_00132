INSERT INTO `radiohead_text` VALUES (803,'== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# 수퍼컴센터 협력 - 김혁호 책임 메일 답장\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# 강석우 상무님과 미팅 - 확인 사항 정리\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\n\nI/O Trace Log 관련\n\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n\n이후 진행 방향 및 일정에 대해\n\n상의드리고자 메일 드립니다.\n\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해보면 좋을 듯 합니다.\n\n- 방안1: GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 슈퍼컴내 별도 테스트 장비 활용하여 log 수집\n\n/* 참고로, 저희 Group 내에서 사용하는 16-node cluster를 이용하는 방법은\n   real workload 수집의 의미가 약하다고 판단되어 고민하지 않기로 하였습니다. */\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n\n\n\n상기 건들에 대해서\n\n어떻게 보시는지 의견 부탁 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(804,'== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# 수퍼컴센터 협력 - 김혁호 책임 메일 답장\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# 강석우 상무님과 미팅 - 확인 사항 정리\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\n\nI/O Trace Log 관련\n\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n\n이후 진행 방향 및 일정에 대해\n\n상의드리고자 메일 드립니다.\n\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n\n\n\n상기 건들에 대해서\n\n의견 부탁 드리겠습니다.\n\n\n\n감사합니다.\n\n정명준 드림.\n\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(805,'== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# 수퍼컴센터 협력 - 김혁호 책임 메일 답장\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# 강석우 상무님과 미팅 - 확인 사항 정리\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(806,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(807,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n: Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(808,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n: Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n: A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n: Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n: Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known\nalgorithms on real, non-random data\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(809,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n: Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n: A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n: Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n: Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(810,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n: Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:. Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(811,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n: Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:* A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:* Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:* Abstract\n:* a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(812,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n: Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:* A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:* Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:* Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(813,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n: Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(814,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(815,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:-\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(816,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(817,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(818,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(819,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\nThen, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(820,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(821,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Disk cache ===\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(822,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Disk cache ===\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(823,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Disk cache ===\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n: IBM 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008\n: GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(824,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Disk cache ===\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n: IBM 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008\n: GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n::- SAN 기반의 고성능 파일 공유 시스템\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(825,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Disk cache ===\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008\n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성\n:#\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(826,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Disk cache ===\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(827,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Disk cache ===\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(828,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Disk cache ===\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n=== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(829,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Disk cache ===\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(830,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(831,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(832,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments\n\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(833,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(834,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(835,'== Python grammar ==\n\n=== Asterisk in Python ===\n\nOn asterisks in Python <ref>http://www.technovelty.org/python/on-asterisks-in-python.html</ref>\n\n: Asterisks have lots of meaning in Python. Firstly, consider in a function definition\n\n <pre>\n>>> def function(arg, *vargs, **kargs):\n    print arg\n    print vargs\n    print kargs\n>>> function(1, 2,3,4,5, test1=\"abc\", test2=\"def\")\n1\n(2, 3, 4, 5)\n{\'test1\': \'abc\', \'test2\': \'def\'}\n</pre>\n\n: *vargs puts all left-over non-keyword arguments into a tuple called vargs.\n: **kargs puts all left-over keyword arguments into a dictionary called kargs.\n\n\n: On the other hand, you can use the asterisk with a tuple when calling a function to expand out the elements of the tuple into positional arguments\n\n <pre>\n>>> def function(arg1, arg2, arg3):\n    print arg1, arg2, arg3\n>>> args = (1,2,3)\n>>> function(*args)\n1 2 3\n</pre>\n\n: You can do a similar thing with keyword arguments and a dictionary with the double asterisk operator\n\n <pre>\n\n</pre>\n\n\n\n\n\n\n\n== Python related issues ==\n\n=== Python to binary executable ===\n\n* http://www.contrib.andrew.cmu.edu/~minlix/wordpress/?p=83\n: \'Compile\' Python script into executable (freeze.py) -- [G] Celestial Force\n <pre>\n> python freeze.py helloworld.py\n> make\n</pre>\n\n\n* http://www.py2exe.org/\n: py2exe: a Python distutils extension which converts Python scripts into executable Windows programs, able to run without requiring a Python installation\n\n\n* http://www.pyinstaller.org/ ((B.GOOD))\n: PyInstaller: a program that converts (packages) Python programs into stand-alone executables, under Windows, Linux, Mac OS X, Solaris and AIX\n: Main advantages over similar tools are that (1) PyInstaller works with any version of Python since 2.3, (2) it builds smaller executables thanks to transparent compression, (3) it is fully multi-platform, (4) and use the OS support to load the dynamic libraries, thus ensuring full compatibility.\n: git clone git://github.com/pyinstaller/pyinstaller.git\n\n\n* http://excid3.com/blog/python-binary-executables-with-pyinstaller/#.UbMsHPlQFG0\n: Python binary executables with Pyinstaller! -- Chris Oliver\n\n\n* https://code.google.com/p/pts-mini-gpl/wiki/StaticPython\n: StaticPython: a statically linked version of the Python 2.x and 3.x\n\n=== Python 2 or Python 3 ===\n\n* http://wiki.python.org/moin/Python2orPython3\n: Should I use Python 2 or Python 3 for my development activity? - What are the differences?\n\n== References ==','utf-8'),(836,'== Python grammar ==\n\n=== Asterisk in Python ===\n\nOn asterisks in Python <ref>http://www.technovelty.org/python/on-asterisks-in-python.html</ref>\n\n: Asterisks have lots of meaning in Python. Firstly, consider in a function definition\n\n <pre>\n>>> def function(arg, *vargs, **kargs):\n    print arg\n    print vargs\n    print kargs\n>>> function(1, 2,3,4,5, test1=\"abc\", test2=\"def\")\n1\n(2, 3, 4, 5)\n{\'test1\': \'abc\', \'test2\': \'def\'}\n</pre>\n\n: *vargs puts all left-over non-keyword arguments into a tuple called vargs.\n: **kargs puts all left-over keyword arguments into a dictionary called kargs.\n\n\n: On the other hand, you can use the asterisk with a tuple when calling a function to expand out the elements of the tuple into positional arguments\n\n <pre>\n>>> def function(arg1, arg2, arg3):\n    print arg1, arg2, arg3\n>>> args = (1,2,3)\n>>> function(*args)\n1 2 3\n</pre>\n\n: You can do a similar thing with keyword arguments and a dictionary with the double asterisk operator\n\n <pre>\n>>> def function(arg1=None, arg2=None):\n     print arg1, arg2\n>>> dict = {\"arg1\":\"1\", \"arg2\":\"2\"}\n>>> function(**dict)\n1 2\n</pre>\n\n== Python related issues ==\n\n=== Python to binary executable ===\n\n* http://www.contrib.andrew.cmu.edu/~minlix/wordpress/?p=83\n: \'Compile\' Python script into executable (freeze.py) -- [G] Celestial Force\n <pre>\n> python freeze.py helloworld.py\n> make\n</pre>\n\n\n* http://www.py2exe.org/\n: py2exe: a Python distutils extension which converts Python scripts into executable Windows programs, able to run without requiring a Python installation\n\n\n* http://www.pyinstaller.org/ ((B.GOOD))\n: PyInstaller: a program that converts (packages) Python programs into stand-alone executables, under Windows, Linux, Mac OS X, Solaris and AIX\n: Main advantages over similar tools are that (1) PyInstaller works with any version of Python since 2.3, (2) it builds smaller executables thanks to transparent compression, (3) it is fully multi-platform, (4) and use the OS support to load the dynamic libraries, thus ensuring full compatibility.\n: git clone git://github.com/pyinstaller/pyinstaller.git\n\n\n* http://excid3.com/blog/python-binary-executables-with-pyinstaller/#.UbMsHPlQFG0\n: Python binary executables with Pyinstaller! -- Chris Oliver\n\n\n* https://code.google.com/p/pts-mini-gpl/wiki/StaticPython\n: StaticPython: a statically linked version of the Python 2.x and 3.x\n\n=== Python 2 or Python 3 ===\n\n* http://wiki.python.org/moin/Python2orPython3\n: Should I use Python 2 or Python 3 for my development activity? - What are the differences?\n\n== References ==','utf-8'),(837,'== Python grammar ==\n\n=== Asterisk in Python ===\n\nOn asterisks in Python <ref>http://www.technovelty.org/python/on-asterisks-in-python.html</ref>\n\n: Asterisks have lots of meaning in Python. Firstly, consider in a function definition\n\n <pre>\n>>> def function(arg, *vargs, **kargs):\n    print arg\n    print vargs\n    print kargs\n>>> function(1, 2,3,4,5, test1=\"abc\", test2=\"def\")\n1\n(2, 3, 4, 5)\n{\'test1\': \'abc\', \'test2\': \'def\'}\n</pre>\n\n: *vargs puts all left-over non-keyword arguments into a tuple called vargs.\n: **kargs puts all left-over keyword arguments into a dictionary called kargs.\n\n\n: On the other hand, you can use the asterisk with a tuple when calling a function to expand out the elements of the tuple into positional arguments\n\n <pre>\n>>> def function(arg1, arg2, arg3):\n    print arg1, arg2, arg3\n>>> args = (1,2,3)\n>>> function(*args)\n1 2 3\n</pre>\n\n: You can do a similar thing with keyword arguments and a dictionary with the double asterisk operator\n\n <pre>\n>>> def function(arg1=None, arg2=None):\n     print arg1, arg2\n>>> dict = {\"arg1\":\"1\", \"arg2\":\"2\"}\n>>> function(**dict)\n1 2\n</pre>\n\n== Python related issues ==\n\n=== Python to binary executable ===\n\n* http://www.contrib.andrew.cmu.edu/~minlix/wordpress/?p=83\n: \'Compile\' Python script into executable (freeze.py) -- [G] Celestial Force\n <pre>\n> python freeze.py helloworld.py\n> make\n</pre>\n\n\n* http://www.py2exe.org/\n: py2exe: a Python distutils extension which converts Python scripts into executable Windows programs, able to run without requiring a Python installation\n\n\n* http://www.pyinstaller.org/ ((B.GOOD))\n: PyInstaller: a program that converts (packages) Python programs into stand-alone executables, under Windows, Linux, Mac OS X, Solaris and AIX\n: Main advantages over similar tools are that (1) PyInstaller works with any version of Python since 2.3, (2) it builds smaller executables thanks to transparent compression, (3) it is fully multi-platform, (4) and use the OS support to load the dynamic libraries, thus ensuring full compatibility.\n: git clone git://github.com/pyinstaller/pyinstaller.git\n\n\n* http://excid3.com/blog/python-binary-executables-with-pyinstaller/#.UbMsHPlQFG0\n: Python binary executables with Pyinstaller! -- Chris Oliver\n\n\n* https://code.google.com/p/pts-mini-gpl/wiki/StaticPython\n: StaticPython: a statically linked version of the Python 2.x and 3.x\n\n=== Python 2 or Python 3 ===\n\n* http://wiki.python.org/moin/Python2orPython3\n: Should I use Python 2 or Python 3 for my development activity? - What are the differences?\n\n== References ==\n\n<references/>','utf-8'),(838,'== Python grammar ==\n\n=== Asterisk in Python ===\n\nOn asterisks in Python <ref>http://www.technovelty.org/python/on-asterisks-in-python.html</ref> ((B.GOOD))\n\n: Asterisks have lots of meaning in Python. Firstly, consider in a function definition\n\n <pre>\n>>> def function(arg, *vargs, **kargs):\n    print arg\n    print vargs\n    print kargs\n>>> function(1, 2,3,4,5, test1=\"abc\", test2=\"def\")\n1\n(2, 3, 4, 5)\n{\'test1\': \'abc\', \'test2\': \'def\'}\n</pre>\n\n: *vargs puts all left-over non-keyword arguments into a tuple called vargs.\n: **kargs puts all left-over keyword arguments into a dictionary called kargs.\n\n\n: On the other hand, you can use the asterisk with a tuple when calling a function to expand out the elements of the tuple into positional arguments\n\n <pre>\n>>> def function(arg1, arg2, arg3):\n    print arg1, arg2, arg3\n>>> args = (1,2,3)\n>>> function(*args)\n1 2 3\n</pre>\n\n: You can do a similar thing with keyword arguments and a dictionary with the double asterisk operator\n\n <pre>\n>>> def function(arg1=None, arg2=None):\n     print arg1, arg2\n>>> dict = {\"arg1\":\"1\", \"arg2\":\"2\"}\n>>> function(**dict)\n1 2\n</pre>\n\n== Python related issues ==\n\n=== Python to binary executable ===\n\n* http://www.contrib.andrew.cmu.edu/~minlix/wordpress/?p=83\n: \'Compile\' Python script into executable (freeze.py) -- [G] Celestial Force\n <pre>\n> python freeze.py helloworld.py\n> make\n</pre>\n\n\n* http://www.py2exe.org/\n: py2exe: a Python distutils extension which converts Python scripts into executable Windows programs, able to run without requiring a Python installation\n\n\n* http://www.pyinstaller.org/ ((B.GOOD))\n: PyInstaller: a program that converts (packages) Python programs into stand-alone executables, under Windows, Linux, Mac OS X, Solaris and AIX\n: Main advantages over similar tools are that (1) PyInstaller works with any version of Python since 2.3, (2) it builds smaller executables thanks to transparent compression, (3) it is fully multi-platform, (4) and use the OS support to load the dynamic libraries, thus ensuring full compatibility.\n: git clone git://github.com/pyinstaller/pyinstaller.git\n\n\n* http://excid3.com/blog/python-binary-executables-with-pyinstaller/#.UbMsHPlQFG0\n: Python binary executables with Pyinstaller! -- Chris Oliver\n\n\n* https://code.google.com/p/pts-mini-gpl/wiki/StaticPython\n: StaticPython: a statically linked version of the Python 2.x and 3.x\n\n=== Python 2 or Python 3 ===\n\n* http://wiki.python.org/moin/Python2orPython3\n: Should I use Python 2 or Python 3 for my development activity? - What are the differences?\n\n== References ==\n\n<references/>','utf-8'),(839,'== Python grammar ==\n\n=== Asterisk in Python ===\n\nOn asterisks in Python <ref>http://www.technovelty.org/python/on-asterisks-in-python.html</ref> ((B.GOOD))\n\n: Asterisks have lots of meaning in Python. Firstly, consider in a function definition\n\n <pre>\n>>> def function(arg, *vargs, **kargs):\n    print arg\n    print vargs\n    print kargs\n>>> function(1, 2,3,4,5, test1=\"abc\", test2=\"def\")\n1\n(2, 3, 4, 5)\n{\'test1\': \'abc\', \'test2\': \'def\'}\n</pre>\n\n: *vargs puts all left-over non-keyword arguments into a tuple called vargs.\n: **kargs puts all left-over keyword arguments into a dictionary called kargs.\n\n\n: On the other hand, you can use the asterisk with a tuple when calling a function to expand out the elements of the tuple into positional arguments\n\n <pre>\n>>> def function(arg1, arg2, arg3):\n    print arg1, arg2, arg3\n>>> args = (1,2,3)\n>>> function(*args)\n1 2 3\n</pre>\n\n: You can do a similar thing with keyword arguments and a dictionary with the double asterisk operator\n\n <pre>\n>>> def function(arg1=None, arg2=None):\n     print arg1, arg2\n>>> dict = {\"arg1\":\"1\", \"arg2\":\"2\"}\n>>> function(**dict)\n1 2\n</pre>\n\n\n\n== Python tips ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n== Python related issues ==\n\n=== Python to binary executable ===\n\n* http://www.contrib.andrew.cmu.edu/~minlix/wordpress/?p=83\n: \'Compile\' Python script into executable (freeze.py) -- [G] Celestial Force\n <pre>\n> python freeze.py helloworld.py\n> make\n</pre>\n\n\n* http://www.py2exe.org/\n: py2exe: a Python distutils extension which converts Python scripts into executable Windows programs, able to run without requiring a Python installation\n\n\n* http://www.pyinstaller.org/ ((B.GOOD))\n: PyInstaller: a program that converts (packages) Python programs into stand-alone executables, under Windows, Linux, Mac OS X, Solaris and AIX\n: Main advantages over similar tools are that (1) PyInstaller works with any version of Python since 2.3, (2) it builds smaller executables thanks to transparent compression, (3) it is fully multi-platform, (4) and use the OS support to load the dynamic libraries, thus ensuring full compatibility.\n: git clone git://github.com/pyinstaller/pyinstaller.git\n\n\n* http://excid3.com/blog/python-binary-executables-with-pyinstaller/#.UbMsHPlQFG0\n: Python binary executables with Pyinstaller! -- Chris Oliver\n\n\n* https://code.google.com/p/pts-mini-gpl/wiki/StaticPython\n: StaticPython: a statically linked version of the Python 2.x and 3.x\n\n=== Python 2 or Python 3 ===\n\n* http://wiki.python.org/moin/Python2orPython3\n: Should I use Python 2 or Python 3 for my development activity? - What are the differences?\n\n== References ==\n\n<references/>','utf-8'),(840,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\n[[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(841,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nSee [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(842,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(843,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(844,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n=== Comparison of block caches ===\n\n* http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options\n\n* There appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of:\n\n:* dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:* Flashcache (developed and used by facebook)\n:* Bcache (developed and used by Google )\n:* EnhanceIO (by STEC; based on Flashcache)\n\n* Are there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n\n* I really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:* Price: SSDs are somehow expensive\n:* Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:* Speed: This is where SSDs gets the edge\n:* Durability: An SSD has no moving parts\n\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(845,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n=== Comparison of block cache solutions ===\n\n* \"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\" http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options, AskUbuntu.com, 2011-05-14\n\n* There appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of:\n\n:* dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:* Flashcache (developed and used by facebook)\n:* Bcache (developed and used by Google )\n:* EnhanceIO (by STEC; based on Flashcache)\n\n* Are there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n\n* I really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:* Price: SSDs are somehow expensive\n:* Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:* Speed: This is where SSDs gets the edge\n:* Durability: An SSD has no moving parts\n\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(846,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n=== Comparison of block cache solutions ===\n\n* What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options, AskUbuntu.com, 2011-05-14</ref>\n\n* There appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:* dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:* Flashcache (developed and used by facebook)\n:* Bcache (developed and used by Google )\n:* EnhanceIO (by STEC; based on Flashcache)\n\n* Are there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n\n* I really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n: Price: SSDs are somehow expensive\n: Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n: Speed: This is where SSDs gets the edge\n: Durability: An SSD has no moving parts\n\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(847,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n=== Comparison of block cache solutions ===\n\n* What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options, AskUbuntu.com, 2011-05-14</ref>\n\n* There appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\n* Are there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n\n* I really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n: Price: SSDs are somehow expensive\n: Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n: Speed: This is where SSDs gets the edge\n: Durability: An SSD has no moving parts\n\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8');
INSERT INTO `radiohead_text` VALUES (848,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n=== Comparison of block cache solutions ===\n\n* What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options, AskUbuntu.com, 2011-05-14</ref>\n\n* There appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\n* Are there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n\n* I really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(849,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n=== Comparison of block cache solutions ===\n\n* What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options, AskUbuntu.com, 2011-05-14</ref>\n\n\'\'\'Question\'\'\'\n\n* There appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\nAre there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n* I really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(850,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n=== Comparison of block cache solutions ===\n\n* What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options, AskUbuntu.com, 2011-05-14</ref>\n\n----\n\n* There appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\nAre there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n----\n\n* I really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(851,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n=== Comparison of block cache solutions ===\n\n* What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options, AskUbuntu.com, 2011-05-14</ref> ((B.GOOD))\n\n==== Comparison of block cache solutions: Question ====\n\n* There appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\nAre there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n\n==== Comparison of block cache solutions: Answer ====\n\n* I really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(852,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n=== Comparison of block cache solutions ===\n\n* What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options, AskUbuntu.com, 2011-05-14</ref> ((B.GOOD))\n\n==== Comparison of block cache solutions: Question ====\n\n* There appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\nAre there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n==== Comparison of block cache solutions: Answer ====\n\n* I really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(853,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n=== Comparison of block cache solutions ===\n\n* What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options, AskUbuntu.com, 2011-05-14</ref> ((B.GOOD))\n\n==== Comparison of block cache solutions: Question ====\n\n* There appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\nAre there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n==== Comparison of block cache solutions: Answer ====\n\nI really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(854,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n=== Comparison of block cache solutions ===\n\n* What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options, AskUbuntu.com, 2011-05-14</ref> ((B.GOOD))\n\n==== Comparison of block cache solutions: Question ====\n\nThere appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\nAre there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n==== Comparison of block cache solutions: Answer ====\n\nI really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(855,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n=== Comparison of block cache solutions ===\n\nWhat are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options, AskUbuntu.com, 2011-05-14</ref> ((B.GOOD))\n\n==== Comparison of block cache solutions: Question ====\n\nThere appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\nAre there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n==== Comparison of block cache solutions: Answer ====\n\nI really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(856,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n=== Comparison of block cache solutions ===\n\nWhat are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", AskUbuntu.com, 2011-05-14, http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options</ref> ((B.GOOD))\n\n==== Comparison of block cache solutions: Question ====\n\nThere appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\nAre there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n==== Comparison of block cache solutions: Answer ====\n\nI really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(857,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n\n=== Read-through, Write-through, Write-behind, Refresh-ahead caching ===\n\nRead-through, Write-through, Write-behind, Refresh-ahead caching\n<ref>\"Read-through, Write-through, Write-behind, Refresh-ahead caching,\" Coherence Knowledge Base, Oracle, Jul 22, 2009, http://coherence.oracle.com/display/COH35UG/Read-Through,+Write-Through,+Write-Behind+and+Refresh-Ahead+Caching</ref>\n\n\n=== Comparison of block cache solutions ===\n\nWhat are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", AskUbuntu.com, 2011-05-14, http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options</ref> ((B.GOOD))\n\n==== Comparison of block cache solutions: Question ====\n\nThere appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\nAre there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n==== Comparison of block cache solutions: Answer ====\n\nI really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(858,'\n\n== ## bNote-2013-07-31 ==\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(859,'\n\n== ## bNote-2013-07-31 ==\n\n배경: 메모리사 SAVL 기술이전 시에 같이 들어가야 할 기술로 data placement (cache/tiering) 기술을 고려할 것. (from 이주평 전문님)\n\n\n=== Read-through, Write-through, Write-behind, Refresh-ahead caching ===\n\nRead-through, Write-through, Write-behind, Refresh-ahead caching\n<ref>\"Read-through, Write-through, Write-behind, Refresh-ahead caching,\" Coherence Knowledge Base, Oracle, Jul 22, 2009, http://coherence.oracle.com/display/COH35UG/Read-Through,+Write-Through,+Write-Behind+and+Refresh-Ahead+Caching</ref>\n\n\n=== Comparison of block cache solutions ===\n\nWhat are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", AskUbuntu.com, 2011-05-14, http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options</ref> ((B.GOOD))\n\n==== Comparison of block cache solutions: Question ====\n\nThere appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\nAre there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n==== Comparison of block cache solutions: Answer ====\n\nI really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(860,'\n\n== ## bNote-2013-07-31 ==\n\n배경: 메모리사 SAVL 기술이전 시에 같이 들어가야 할 기술로 data placement (cache/tiering) 기술을 고려할 것. (from 이주평 전문님)\n\n\n=== Read-through, Write-through, Write-behind, Refresh-ahead caching ===\n\nRead-through, Write-through, Write-behind, Refresh-ahead caching\n<ref>\"Read-through, Write-through, Write-behind, Refresh-ahead caching,\" Coherence Knowledge Base, Oracle, Jul 22, 2009, http://coherence.oracle.com/display/COH35UG/Read-Through,+Write-Through,+Write-Behind+and+Refresh-Ahead+Caching</ref>\n\n\n=== Comparison of block cache solutions ===\n\nWhat are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", AskUbuntu.com, 2011-05-14, http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options</ref> ((B.GOOD))\n\n==== Comparison of block cache solutions: Question ====\n\nThere appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\nAre there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n==== Comparison of block cache solutions: Answer ====\n\nI really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(861,'\n\n== ## bNote-2013-07-31 ==\n\n배경: 메모리사 SAVL 기술이전 시에 같이 들어가야 할 기술로 data placement (cache/tiering) 기술을 고려할 것. (from 이주평 전문님)\n\n\n=== Read-through, Write-through, Write-behind, Refresh-ahead caching ===\n\nRead-through, Write-through, Write-behind, Refresh-ahead caching\n<ref>\"Read-through, Write-through, Write-behind, Refresh-ahead caching,\" Coherence Knowledge Base, Oracle, Jul 22, 2009, http://coherence.oracle.com/display/COH35UG/Read-Through,+Write-Through,+Write-Behind+and+Refresh-Ahead+Caching</ref>\n\n* Pluggable Cache Store\n* Read-Through Caching\n* Write-Through Caching\n* Write-Behind Caching\n* Write-Behind Requirements\n* Refresh-Ahead Caching\n* Selecting a Cache Strategy\n* Idempotency\n* Write-Through Limitations\n* Cache Queries\n* Creating a CacheStore Implementation\n* Plugging in a CacheStore Implementation\n* Implementation Considerations\n\n=== Comparison of block cache solutions ===\n\nWhat are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", AskUbuntu.com, 2011-05-14, http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options</ref> ((B.GOOD))\n\n==== Comparison of block cache solutions: Question ====\n\nThere appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\nAre there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n==== Comparison of block cache solutions: Answer ====\n\nI really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(862,'\n\n== ## bNote-2013-07-31 ==\n\n배경: 메모리사 SAVL 기술이전 시에 같이 들어가야 할 기술로 data placement (cache/tiering) 기술을 고려할 것. (from 이주평 전문님)\n\n\n=== Read-through, Write-through, Write-behind, Refresh-ahead caching ===\n\nRead-through, Write-through, Write-behind, Refresh-ahead caching\n<ref>\"Read-through, Write-through, Write-behind, Refresh-ahead caching,\" Coherence Knowledge Base, Oracle, Jul 22, 2009, http://coherence.oracle.com/display/COH35UG/Read-Through,+Write-Through,+Write-Behind+and+Refresh-Ahead+Caching</ref>\n: Oracle Knowledge Base\n\n* Pluggable Cache Store\n* Read-Through Caching\n* Write-Through Caching\n* Write-Behind Caching\n* Write-Behind Requirements\n* Refresh-Ahead Caching\n* Selecting a Cache Strategy\n* Idempotency\n* Write-Through Limitations\n* Cache Queries\n* Creating a CacheStore Implementation\n* Plugging in a CacheStore Implementation\n* Implementation Considerations\n\n=== Comparison of block cache solutions ===\n\nWhat are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", AskUbuntu.com, 2011-05-14, http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options</ref> ((B.GOOD))\n\n==== Comparison of block cache solutions: Question ====\n\nThere appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\nAre there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n==== Comparison of block cache solutions: Answer ====\n\nI really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(863,'\n\n== ## bNote-2013-07-31 ==\n\n배경: 메모리사 SAVL 기술이전 시에 같이 들어가야 할 기술로 data placement (cache/tiering) 기술을 고려할 것. (from 이주평 전문님)\n\n\n=== Read-through, Write-through, Write-behind, Refresh-ahead caching ===\n\nRead-through, Write-through, Write-behind, Refresh-ahead caching\n<ref>\"Read-through, Write-through, Write-behind, Refresh-ahead caching,\" Coherence Knowledge Base, Oracle, Jul 22, 2009, http://coherence.oracle.com/display/COH35UG/Read-Through,+Write-Through,+Write-Behind+and+Refresh-Ahead+Caching</ref>\n: Oracle Knowledge Base\n\n* Pluggable Cache Store\n* Read-Through Caching\n* Write-Through Caching\n* Write-Behind Caching\n* Write-Behind Requirements\n* Refresh-Ahead Caching\n* Selecting a Cache Strategy\n* Idempotency\n* Write-Through Limitations\n* Cache Queries\n* Creating a CacheStore Implementation\n* Plugging in a CacheStore Implementation\n* Implementation Considerations\n\n=== Comparison of block cache solutions ===\n\nWhat are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", AskUbuntu.com, 2011-05-14, http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options</ref> ((B.GOOD))\n\n==== Comparison of block cache solutions: Question ====\n\nThere appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\nAre there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n==== Comparison of block cache solutions: Answer ====\n\nI really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n\n=== Related work ===\n\n* http://www.nec-labs.com/~biplob/Papers/TBF.pdf\n: TBF: A Memory-efficient Replacement Policy for Flash-based Caches\n\n <pre>\nThe performance and capacity characteristics of\nﬂash storage make it attractive to use as a cache. Recencybased cache replacement policies rely on an in-memory full index,\ntypically a B-tree or a hash table, that maps each object to its\nrecency information. Even though the recency information itself\nmay take very little space, the full index for a cache holding N\nkeys requires at least logN bits per key. This metadata overhead\nis undesirably high when used for very large ﬂash-based caches,\nsuch as key–value stores with billions of objects.\nTo solve this problem, we propose a new RAM-frugal cache\nreplacement policy that approximates the least-recently-used\n(LRU) policy. It uses two in-memory Bloom sub-filters (TBF) for\nmaintaining the recency information and leverages an on-ﬂash\nkey–value store to cache objects. TBF requires only one byte of\nRAM per cached object, making it suitable for implementing very\nlarge ﬂash-based caches. We evaluate TBF through simulation\non traces from several block stores and key–value stores, as well\nas evaluate it using the Yahoo! Cloud Serving Benchmark in a\nreal system implementation. Evaluation results show that TBF\nachieves cache hit rate and operations per second comparable to\nthose of LRU in spite of its much smaller memory requirements.\n</pre>\n\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(864,'\n\n== ## bNote-2013-07-31 ==\n\n배경: 메모리사 SAVL 기술이전 시에 같이 들어가야 할 기술로 data placement (cache/tiering) 기술을 고려할 것. (from 이주평 전문님)\n\n\n=== Read-through, Write-through, Write-behind, Refresh-ahead caching ===\n\nRead-through, Write-through, Write-behind, Refresh-ahead caching\n<ref>\"Read-through, Write-through, Write-behind, Refresh-ahead caching,\" Coherence Knowledge Base, Oracle, Jul 22, 2009, http://coherence.oracle.com/display/COH35UG/Read-Through,+Write-Through,+Write-Behind+and+Refresh-Ahead+Caching</ref>\n: Oracle Knowledge Base\n\n* Pluggable Cache Store\n* Read-Through Caching\n* Write-Through Caching\n* Write-Behind Caching\n* Write-Behind Requirements\n* Refresh-Ahead Caching\n* Selecting a Cache Strategy\n* Idempotency\n* Write-Through Limitations\n* Cache Queries\n* Creating a CacheStore Implementation\n* Plugging in a CacheStore Implementation\n* Implementation Considerations\n\n=== Comparison of block cache solutions ===\n\nWhat are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)? <ref>\"What are the advantages/disadvantages of different SSD to HDD caching options (dm-cache, flashcache, bcache, enhanceio)?\", AskUbuntu.com, 2011-05-14, http://askubuntu.com/questions/290502/what-are-the-advantages-disadvantages-of-different-ssd-to-hdd-cacheing-options</ref> ((B.GOOD))\n\n==== Comparison of block cache solutions: Question ====\n\nThere appear to be various different technologies available to use an SSD to act as a cache for HHDs. The ones I know of\n\n:- dm-cache (by Redhat - in the 3.9 Kernel, so it should be in ubuntu 13.10)\n:- Flashcache (developed and used by facebook)\n:- Bcache (developed and used by Google )\n:- EnhanceIO (by STEC; based on Flashcache)\n\nAre there any noteworthy differences in the various implementations? Which one is best for regular desktop PC use - to increase performance of usual programs such as web browsers or games?\n\n==== Comparison of block cache solutions: Answer ====\n\nI really don’t know where to start, since all this is excellent information. I will start with some info about SSD’s, then a description of all the different caching methods, and just go from there. I hope that you\n\n; Advantages/Disadvantages of SSD\n:- Price: SSDs are somehow expensive\n:- Maximum and Common Capacity: High capacity SSD’s are very rare and expensive\n:- Speed: This is where SSDs gets the edge\n:- Durability: An SSD has no moving parts\n\nBest to have a hybrid system, to have the best of both worlds (capacity, reliability, speed, etc.)\n\n; DM-cache\n: The Linux 3.9 kernel (made available on April 28, 2013) introduces SSD caching. The kernel\'s Device mapper now includes a cache target called dm-cache that enables SSDs or other storage device to be used as a cache for a hard drive. It essentially speeds up data writes and reads as it allows the faster SSD to first cache data and then transfer it to the slower hard drive.\n:- Source:Iwn\n\n; What is FlashCache?\n: Flashcache is a module originally written and released by Facebook(Mohan Srinivasan, Paul Saab and Vadim Tkachenko) in April of 2010. It is a kernel module that allows Writethrough caching of a drive on another drive. This is most often used for caching a rotational drive on a smaller solid-state drive for performance reasons. This gives you the speed of an SSD and the size of a standard rotational drive for recently cached files. FlashCache is a general purpose writeback block cache for Linux.\n:- Source:ArchLinux\n\n; What is Bcache?\n: Bcache is a Linux kernel block layer cache. It allows one or more fast disk drives such as flash-based solid state drives (SSDs) to act as a cache for one or more slower hard disk drives.\n: Hard drives are cheap and big, SSDs are fast but small and expensive. Wouldn\'t it be nice if you could transparently get the advantages of both? With Bcache, you can have your cake and eat it too.\n: Bcache patches for the Linux kernel allow one to use SSDs to cache other block devices. It\'s analogous to L2Arc for ZFS, but Bcache also does writeback caching (besides just write through caching), and it\'s filesystem agnostic. It\'s designed to be switched on with a minimum of effort, and to work well without configuration on any setup. By default it won\'t cache sequential IO, just the random reads and writes that SSDs excel at. It\'s meant to be suitable for desktops, servers, high end storage arrays, and perhaps even embedded.\n: The design goal is to be just as fast as the SSD and cached device (depending on cache hit vs. miss, and writethrough vs. writeback writes) to within the margin of error. It\'s not quite there yet, mostly for sequential reads. But testing has shown that it is emphatically possible, and even in some cases to do better - primarily random writes.\n: Source:Bcache\n\n; Disadvantage of Bcache (needs lots of memory)\n: Bcache has a big disadvantage, and that it takes away memory from the system to implement the cache.\n: EnhanceIO is a solution that runs beneath the application layer, enabling applications to utilize the performance benefits of SSDs without major IT infrastructure changes. An SSD cache can yield most of the benefits of switching from HDDs to SSDs at a fraction of the cost of an all-SSD system. A cached system typically operates on less power than an HDD-based system of similar performance, and that creates a side benefit by reducing cooling requirements.\n: An SSD cache can also extend the useful life of an existing system by improving performance to meet growing demands through an incremental investment, rather than through a wholesale upgrade/replacement of the existing system.\n: Caching also enables faster access to the data without the extra storage administration overhead to acquire and install new disk shelves, configuring new LUNs and migrating data to the new LUNs. Caching is almost transparent and requires little if any downtime. EnhanceIO is based upon Flashcache.\n:- Source:Stec-Inc\n\n; Bcache Vs. EnhanceIO\n: bcache is the most worthless of all because it requires specially prepared (formatted) data partition. This makes it difficult (if possible) to attach cache to existing partition with data as one would need 200% capacity and to perform long data-moving in order to activate/deactivate caching.\n: The brilliance of EnhanceIO is that it doesn\'t need intermediate device at all and can be attached to any block device on-the-fly even when device is already mounted. Another super-cool thing is that you can attach EnhanceIO cache not just to partition but to partitioned block device to cache all its partitions at once. Just like flashcache enchanceio modules are built with DKMS and can be used with older kernels.\n:- Source: Debian\n\n; DM Cache Advantages\n: DM caches use a simplified architecture, which makes them adaptable and easy to customize. Users can adjust the block size and the cache capacity based on the amount of data it will have to handle or on the value of the data. If a particular application needs to store a great deal of data in sequence, users can configure the cache for that purpose. If a user wants to record information in a database simultaneously with the cache, that won\'t interfere with the cache\'s operations.\n\n; DM Cache Dis-Advantages\n: One drawback to using a DM cache is that the Linux operating system has limited space for storing metadata. If the cache is large, and includes lots of small blocks, that adds up to a lot of metadata for the stored information. To solve this problem, the user must increase the block size. Another possible problem is that, after a server crash, the cache metadata may no longer match the cache contents, though it is possible to restore the correct configuration eventually.\n:- Source: Complements of Fraser Sherman\n\nSo from the above information it’s clear that EnhanceIO is the way to go, but in my opinion since it’s based on Flashcache, I would go with flash cache. But I will definitely try both of them before making a final decision.\n\n\n=== Related work ===\n\n* http://www.nec-labs.com/~biplob/Papers/TBF.pdf\n: TBF: A Memory-efficient Replacement Policy for Flash-based Caches\n\n <pre>\nThe performance and capacity characteristics of\nﬂash storage make it attractive to use as a cache. Recency-based\ncache replacement policies rely on an in-memory full index,\ntypically a B-tree or a hash table, that maps each object to its\nrecency information. Even though the recency information itself\nmay take very little space, the full index for a cache holding N\nkeys requires at least logN bits per key. This metadata overhead\nis undesirably high when used for very large ﬂash-based caches,\nsuch as key–value stores with billions of objects.\nTo solve this problem, we propose a new RAM-frugal cache\nreplacement policy that approximates the least-recently-used\n(LRU) policy. It uses two in-memory Bloom sub-filters (TBF) for\nmaintaining the recency information and leverages an on-ﬂash\nkey–value store to cache objects. TBF requires only one byte of\nRAM per cached object, making it suitable for implementing very\nlarge ﬂash-based caches. We evaluate TBF through simulation\non traces from several block stores and key–value stores, as well\nas evaluate it using the Yahoo! Cloud Serving Benchmark in a\nreal system implementation. Evaluation results show that TBF\nachieves cache hit rate and operations per second comparable to\nthose of LRU in spite of its much smaller memory requirements.\n</pre>\n\n=== Machine learning - deep learning ===\n\n* http://factorizer.egloos.com/879252\n: Machine learning - deep learning 관련 Good article\n\n* https://www.ipam.ucla.edu/schedule.aspx?pc=gss2012\n: UCLA에서 열린 딥러닝 관련 summer school에서 대가들이 했던 talk과 자료들이라고 하네요.\n\n* https://www.coursera.org/\n: machine learning 강좌를 포함하여 많은 인터넷 강좌들 보유\n: Andrew Ng라는 stanford대 교수의 인터넷 강좌 - 쉽게 정리가 잘 되어 있다고 함\n\n\n=== Data mining ===\n\n* http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf\n: Sherri K. Harms, Jitender Deogun, and Tsgaye Tadesse, \"Discovering sequential association rules with constraints and time lags in multiple sequences,\" HDT 2002 ((B.GOOD))\n\n\n* http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf\n: Dhanya and Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" Journal of geophysical research, vol. 114, 2009\n\n== ## bNote-2013-07-30 ==\n\n=== Memoization in Python ===\n\nPlease see [[Bnote python]]\n\n== ## bNote-2013-07-29 ==\n\n\n=== Disk cache ===\n\nfile-based block cache 혹은 file cache 관련 자료들을 찾다가 검색한 내용들.\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: SSD caching using dm-cache tutorial (2013-06-30) ((B.GOOD))\n\n* http://www.wwpi.com/index.php?Itemid=2701750&view=article&id=13951:file-based-vs-block-based-caching&catid=331:ctr-exclusives&option=com_content\n: File-based caching vs. block-based caching ((B.GOOD))\n\n* http://www.cse.iitb.ac.in/internal/techreports/reports/TR-CSE-2012-45.pdf\n: A Per-file Partitioned Page Cache\n\n* http://www.emc.com/collateral/hardware/data-sheet/h9581-vfcache-ds.pdf\n: EMC VFCache - Server flash cache for superior performance, intelligence, and protection of mission-critical data\n\n* http://www.emc.com/collateral/hardware/white-papers/h10502-vfcache-intro-wp.pdf\n: Introduction to EMC XTREMSW Cache\n\n* http://storageioblog.com/emc-vfcache-respinning-ssd-and-intelligent-caching-part-ii/\n: EMC VFCache respinning SSD and intelligent caching (Part II)\n\n* http://docs.neo4j.org/chunked/stable/configuration-caches.html\n: File buffer cache in Neo4j\n: Neo4j utilizes two different types of caches: A file buffer cache and an object cache\n\n* http://www.google.com/patents/US5809560\n: (특허) Adaptive read-ahead disk cache (US5809560 A)\n\n* http://people.redhat.com/dhowells/fscache/FS-Cache.pdf\n: FS-Cache: A Network Filesystem Caching Facility // David Howells\n\n\n\n=== Deduplication ===\n\n* http://www.cs.utah.edu/~shanth/stuff/research/dup_elim/writeup.txt\n:- Rabin fingerprinting, which is used in some of the redundacy elimination techniques\n::# Rabin Fingerprint\n::# Redundancy elimination techniques in storage systems\n::# File Access vis-a-vis Physical block updates\n::# Thoughts on disk-image delta calculation\n\n\n* http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.pdf\n:- A Framework for Analyzing and Improving Content-Based Chunking Algorithms\n:- Kave Eshghi, Hsiu Khuern Tang, Intelligent Enterprise Technologies Laboratory, HP Laboratories Palo Alto, September 22, 2005\n:- Abstract\n:: a framework for analyzing content-based chunking algorithms, as used for example in the Low Bandwidth Networked File System. We use this framework for the evaluation of the basic sliding window algorithm, and its two known variants. We develop a new chunking algorithm that performs significantly better than the known algorithms on real, non-random data\n\n\n* http://www.snia.org/sites/default/files2/SDC2012/presentations/Revisions/SudiptaSengupta-JimBentonPrimary_Data_Deduplication-revision.pdf\n:- Primary Data Deduplication in Windows Server 2012, Microsoft Corporation, Redmond, WA, USA (SDC 2012, SNIA)\n:- ChunkStash 관련 내용이 슬라이드에 나옴\n\n\n* http://research.microsoft.com/pubs/131571/paper.pdf\n: ChunkStash: Speeding up Inline Storage Deduplication using Flash Memory\n\n== ## bNote-2013-07-26 ==\n\n=== Workload characterization ===\n\n* http://delivery.acm.org/10.1145/1350000/1346260/p21-apparao.pdf?ip=202.20.193.254&id=1346260&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=235140655&CFTOKEN=51516258&__acm__=1374480976_31e10ef866752e70d5fca918404bc214\n: Characterization & analysis of a server consolidation benchmark\n\n* http://www.hpl.hp.com/techreports/2007/HPL-2007-114.pdf?jumpid=reg_R1002_USEN\n: Workload analysis and demand prediction of enterprise data center applications (HP)\n\n* http://165.193.233.120/files/pdf/partners/academic/vpact-workloads.pdf\n: Storage workload characterization and consolidation in virtualized environments (VMware)\n\n* http://www.vmware.com/pdf/vmmark_intro.pdf\n: VMmark: a scalable benchmark for virtualized systems\n\n== ## bNote-2013-07-25 ==\n\n* Task\n:# <strike>변리사 미팅 (10:30~)</strike>\n:# <strike>수퍼컴센터 협력 - 김혁호 책임 메일 답장</strike>\n:# 전략출원 자료 작성 및 예상 질문, 시뮬레이션\n:# Type II Coaccess 측정 방법 구상\n:# Real system 기반 data placement infra 구축 (cache, tiering, vdi, iscsi, vdi gateway)\n:# <strike>강석우 상무님과 미팅 - 확인 사항 정리</strike>\n\n\n=== IBM GPFS ===\n\n==== IBM GPFS 3.2 (2008) ====\n\n* http://www.dbguide.net/upload/20080416/1208334239580.pdf\n:- IBM GPFS 고성능 파일 공유 솔루션 소개 - IBM Korea, 2008 ((B.GOOD))\n:- 2008년 자료로서, 비록 오래되긴 했으나, IBM GPFS에 대한 좋은 Introduction. \n\n* GPFS (General Parallel File System) & SOFS (Scale Out File Services)\n: SAN 기반의 고성능 파일 공유 시스템\n\n* GPFS History\n::- 1996년 Tiger Shark File System - 멀티미디어 Video Server로 구현됨\n::- 2007년 11월 GPFS 3.2 출시 - Page pool size (up to 256GB), Rolling upgrade, backward compatibility, InfiniBand RDMA 지원, Monitoring을 위한 SNMP 기능, SCSI-3, RHEL 5 지원, LUN 당 8개의 NSD 서버 지원, 256개 File System 동시 mount 등 기능 향상\n\n* High performance file sharing solution이 필요한 이유\n:# 파일 서비스에 대한 요구 사항은 더욱 증가하고 있지만, 단순 box별 추가와 개별적 관리는 원하지 않음\n:# 디지털 미디어 사업자들에게 데이터에 대한 병렬 접근은 점점 더 보편화되고 있음\n:# 개별 파일 또는 파일 집합에 대한 데이터 접근 비율이나 응답 속도의 요구가 과거 HPC 수퍼컴퓨팅 분야에서는 가능했던 정도로 높아지고 있음\n:# 클러스터 파일 서버는 이론상 쉽지만, 생성하고 유지하기가 쉽지 않은 복잡한 구조임\n:# 데이터가 점점 증가함으로 인해 Backup windows가 큰 이슈가 됨\n:# 새로운 스토리지를 추가/통합하거나 사용중이던 스토리지를 삭제하는 것은 기존 기간계 (infra) 시스템에 큰 영향을 줌\n:# 정보 수명주기 관리 (ILM)의 통합은 확장될 수록 점점 중요해지고 있음\n\n* Parallel File System의 필요성 (Application 관점)\n:# 여러 노드로부터 데이터를 access해야 할 필요가 있는 경우 (striping?)\n:# 하나의 파일에 대한 공통 저장 장소가 있어야 하는 경우\n:# 장애 시 계속적인 서비스가 필요한 경우\n:# Application에서 사용하는 데이터에 대한 빠른 access가 필요한 경우\n\n* Parallel File System의 필요성 (File System 관점)\n:# Accessibility: 어떠한 node에서도 모든 file을 access해야 하는 경우\n:# Scalability: node, storage, application 추가 시 선형적인 확장성이 필요한 경우\n:# Uniform access: cluster 환경에서 application 개발 시 source의 일관된 관리가 필요한 경우\n:# High capacity: TB files, 여러 개의 TB file system이 필요한 경우\n:# High throughput: 초당 GP의 throughput이 필요한 경우\n:# Parallel data access: 여러 개의 노드에서 동시에 같은 데이터를 access해야 할 필요가 있는 경우\n:# Reliability and fault tolerance: node, disk, network 장애 시에도 지속적인 서비스가 필요한 경우\n\n==== IBM GPFS 3.5 ====\n\n* http://www-03.ibm.com/systems/resources/introduction-to-gpfs-3-5.pdf\n: An introduction to GPFS version 3.5 (August 2012)\n\n=== 수퍼컴센터 협력 - 김혁호 책임 메일 답장 ===\n\n <pre>\n\n김혁호 책임님, 안녕하세요?\n\n\nI/O Trace Log 관련\nIBM GPFS 상황을 상세히 설명해주셔서 감사합니다.\n\n\n이후 진행 방향 및 일정에 대해\n상의드리고자 메일 드립니다.\n\n\n\n\n1. Real I/O Trace Log 수집 건\n\nTrace Log 수집 가능 여부를 확인하기 위해\n시간을 들여 많은 노력을 해주셔서 고맙습니다.\n아쉽게도 IBM 측으로부터 GPFS layer에서의\nrich context data + I/O trace log 수집이 어렵다는 말씀을 들었습니다.\n따라서 다음과 같은 대안을 같이 고민해볼 수 있을 것 같습니다.\n\n- 방안1: 수퍼컴 일반 클러스터 내에서 GPFS layer가 아닌 그 아래의 block layer에서의 I/O trace log 수집\n- 방안2: 수퍼컴 내 별도 테스트 클러스터 장비 활용하여 log 수집\n\n지금까지의 상황이 이러하다면,\n7월 말부터 8월 중순까지는 저희 팀에서 우선 진행해야 할 다른 일들이 있기 때문에\nTrace Log 수집 일정은 8월 중순 지나서 진행해주셔도 될 듯 합니다.\n\n   \n2. 병렬화 및 RSP 적용 건\n\n병렬화 일정 조정에 대해서 문의 드립니다.\n저희쪽에서 몇 주동안 다른 일들이 생기면서\n분석 작업 병렬화를 늦추게 되었습니다.\n따라서 병렬화/RSP 적용 일정을 8월 중순 지나서 진행해주시는 것으로\n조정 가능한지 여쭙고 싶습니다.\n\n\n3. Parameter Sweeping 시의 대규모 스토리지 문제\n\nTask 기반의 병렬화를 생각하고 있습니다.\n즉, 동일한 operation을 parameter를 바꿔가면서\n동일한 데이터에 대해서 수행하는 parameter sweep방식입니다.\n\n다만 hurdle로 보여지는 것은, analysis가 진행되면서\n불가피하게 증가하게 되는 데이터의 사이즈입니다.\n\n현재 analysis engine v1.0 의 경우,\nraw data가 500MB라고 했을 때,\n전처리와 1차/2차 분석을 수행하면서\n데이터 특성에 따라 약 120배~160배로 데이터가 증가하여\n60GB ~ 80GB의 크기가 될 수 있습니다.\n그리고, 필요 시 이 데이터들에 대해서 3차 분석을 진행하기도 합니다.\n따라서 3차 분석이 끝날 때까지는 이 데이터들을 삭제할 수가 없습니다.\n\nParameter sweep 방식으로 진행한다고 했을 때,\n만약 100개의 병렬 task를 동시에 돌린다고 하면\n초기 500MB의 데이터는 동일하다 하더라도,\n그로부터 서로 다른 60GB~80GB의 데이터가 생성될 수 있기 때문에\n6TB에서 8TB의 스토리지 공간이 필요하게 됩니다.\n(그리고 초기 데이터의 사이즈가 500MB가 아니라 4GB 정도 규모만 되더라도\n필요한 스토리지 공간은 48TB~64TB 정도가 될 수 있습니다.)\n아마도 데이터 규모를 예상해서 병렬화의 정도 (task 갯수)를 조절해야 할 것 같습니다.\n\n병렬화 시에 요구되는 대규모 스토리지 문제 해결을 위해\n어떻게 접근할 것인지에 대해서는\n별도로 논의를 해보면 좋겠습니다.\n\n\n\n\n상기 건들에 대해서\n의견 부탁 드리겠습니다.\n\n\n감사합니다.\n정명준 드림.\n\n\n\n\n</pre>\n\n== ## bNote-2013-07-24 ==\n\n=== Supercom data backup ===\n: Total capacity of the data should be set under 100GB per user.\n\n <pre>\n\na1mjjung@secm:~ %4$ du -sm *\n35	R\n1	README\n0	__SUPERCOM__\n1	bd\n1	bdx\n1	bpk\n1	bx_data\n1	cmd\n36	prj\n1	srcx\n1	sys\n237	t\n16531	tsk\n89031	x\n1	x9\n\n</pre>\n\n== ## bNote-2013-07-23 ==\n\n=== Association Rules Mining ===\n\n\n* Discovering sequential association rules with constraints and time lags in multiple sequences <ref>Sherri K. Harms1, Jitender Deogun, and Tsegaye Tadesse, \"Discovering Sequential Association Rules with Constraints and Time Lags in Multiple Sequences,\" Springer-Verlag Berlin Heidelberg 2002, http://yipchikin.net/yipchikin/research/pdf/HDT02.pdf</ref> ((B.GOOD))\n\n* Sequential Association Rule Mining with Time Lags <ref>Sherri K. Harms, Jitender S. Deogun, \"Sequential Association Rule Mining with Time Lags,\" Journal of Intelligent Information Systems, Volume 22 Issue 1, January 2004, http://dl.acm.org/citation.cfm?id=944251</ref>\n\n* Data mining for evolution of association rules for droughts and floods in India using climate inputs <ref>C. T. Dhanya and D. Nagesh Kumar, \"Data mining for evolution of association rules for droughts and floods in India using climate inputs,\" JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 114, D02102, doi:10.1029/2008JD010485, 2009, http://water.columbia.edu/files/2011/11/Kumar2009DataMining1.pdf</ref>\n\n=== Supercom disk usage ===\n\n\n <pre>\na1mjjung@secm:[~] $ du -sk ./\n401211584\n\na1mjjung@secm:~/x/tracelog %4$ du -sh *\n77G	MS_Enterprise\n258G	MS_Production\n8.0K	fio\n206M	myrealtrace.radiohead.v01\n8.0K	tpcc_250gb_48h\n8.0K	wintrace_anal\n25G	wintrace_anal.20130611\n4.6G	wintrace_anal.20130701\n2.4G	wintrace_anal.20130708\n16K	x\n</pre>\n\n=== DKMS (Dynamic Kernel Module Support) ===\n\nDynamic Kernel Module Support (DKMS) is a framework used to generate Linux kernel modules whose sources do not generally reside in the Linux kernel source tree. DKMS enables kernel device drivers to be automatically rebuilt when a new kernel is installed.\nAn essential feature of DKMS is that it automatically recompiles all DKMS modules if a new kernel version is installed. <span style=\"color:red\">\'\'\'This allows drivers and devices outside of the mainline kernel to continue working after a Linux kernel upgrade.\'\'\'</span>\n<span style=\"color:blue\">\'\'\'Another benefit of DKMS is that it allows the installation of a new driver on an existing system, running an arbitrary kernel version, without any need for manual compilation or precompiled packages provided by the vendor.\'\'\'</span>\nDKMS was written by the Linux Engineering Team at Dell in 2003. It is included in many distributions, such as Ubuntu, Debian, Fedora, and SuSE. DKMS is free software released under the terms of the GNU General Public License (GPL) v2 or later.\nDKMS supports both the RPM and DEB package formats out-of-the-box. <ref>Dynamic Kernel Module Support - Wikipedia http://en.wikipedia.org/wiki/Dynamic_Kernel_Module_Support</ref>\n\n== ## bNote-2013-07-17 ==\n\n* [[Intelligent Battery Management System]]\n\n== ## bNote-2013-07-15 ==\n\n\n=== Linux disk cache technologies ===\n\n\n==== SSD caching using dm-cache ====\n\n* http://blog.kylemanna.com/linux/2013/06/30/ssd-caching-using-dmcache-tutorial/\n: [[Tutorial -- SSD caching using dm-cache]]\n: The ultimate guide to the \'dm-cache\' ((B.GOOD))\n: Published: 30 June 2013\n\n==== EnhanceIO, Bcache & DM-Cache Benchmarked ====\n* http://www.phoronix.com/scan.php?page=news_item&px=MTM4ODA\n: Posted by Michael Larabel on June 11, 2013\n\n* A Linux engineer at STEC Inc compared the performance of EnhanceIO, BCache, and DM-Cache. A 100GB HDD was used with a 20GB SSD providing write-through / write-back cache. For those out of the look on these different caching methods\n\n* The summary? \"We found that EnhanceIO provides better throughput on zipf workload (with theta=1.2) in comparison to bcache and dm-cache for write through caches. However, for write back caches, we found that dm-cache had best throughput followed by EnhanceIO and then bcache. Dm-cache commits on-disk metadata every time a REQ_SYNC or REQ_FUA bio is written. If no such requests are made then it commits metadata once every second. If power is lost, it may lose some recent writes. However, EnhanceIO and bcache do not acknowledge IO completion until both IO and metadata hits the SSD. Hence, EnhanceIO and bcache provide higher data integrity at a cost of performance.\"\n\n\n==== EnhanceIO: New Solid State Drive Caching For Linux ====\n\n* http://www.phoronix.com/scan.php?page=news_item&px=MTI3Mzc\n: Posted by Michael Larabel on January 13, 2013\n\n* Based upon Flashcache, STEC Inc has opened up their EnhanceIO SSD caching software for Linux. EnhanceIO uses SSDs as cache devices for traditional HDDs and works with any block device whether it be an actual physical device, a disk partition, a RAID-ed DAS device, SAN volumes, and device mapper volumes. \n\n* EnhanceIO supports caching modes of read-only, write-through, and write-back. The cache replacement policies are random, FIFO, and LRU. \n\n* STEC Inc didn\'t simply make a couple of changes to Flashcache and call it something new, but rather they have made some significant and original improvements. Over Flashcache, EnhanceIO adds a new write-back enhance that\'s designed from scratch, transparent cache support not using the Linux device mapper, large I/O support, a smaller memory footprint, supports loadable replacement policies, optimal alignment of data blocks on SSDs, improved device failure handling, and code optimizations. \n\n* https://github.com/stec-inc/EnhanceIO\n: The GPL-licensed code to EnhanceIO can be found on GitHub.\n\n=== Comparison of placement technologies ===\n\n* Storage System Product 별 Tiering 기술 분석\n\n* [[Automated storage tiering product comparison - Martin Glassborow - April 2011]] \n: http://www.computerweekly.com/feature/Automated-storage-tiering-product-comparison\n\n{| class=\"wikitable sortable\"\n<!--\n| % || Storage Architecture || colspan=5 | Data Placement 기술명 || Notes\n|-\n-->\n! C\\F || Storage Architecture || Placement 기술명 || 기술 상세 (Measure 방식, Migration 방식, Chunk Size, Pre-requisites 등등) || Pros || Cons || Major target workloads || Intelligence 측면 || Notes\n|-\n| EMC VNX series || Scale-up SAN, SSD-HDD hybrid arch. || FAST (Fully Automated Storage Tiering) || - 기본적으로 3-tier 구조 (SAS SSD, SAS HDD, SATA HDD) <br/> - Service time 동안 LUN 단위로 access frequency 측정<br/> - Non-service time 동안 측정된 frequency 값 기반으로 hot/cold data 구분하여 fast tier, slow (capacity) tier로 data migration 실시<br/> - Sub-LUN 단위<br/>  || - 간단한 measure algo. 로 runtime overhead가 낮음 <br/> - Non-service time 동안 이동하는 방식으로서, migration module의 complexity 낮음 || - 변화가 큰 workload에 대해 적응적 대응 어려움<br/> - migration-time이 되기 전까지는 workload 변화를 감지하더라도 대응 불가<br/> || Database, VDI || ... || Any Notes\n|-\n| EMC XtremIO || Scale-out NAS || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NetApp || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| IBM || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HP 3PAR || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| HDS  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Dell Compellent || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Nimble Storage || Scale-out SAN, SSD-HDD hybrid arch. || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Tintri || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Tegile || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| NexGen  || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Nutanix || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|-\n| Scale-IO || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Pure Storage || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Violin Memory || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Skyera || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n| Solidfire || ... || ... || ... || ... || ... || ... || ... || Any Notes\n|- \n\n|}\n\n=== 서울대산학 최종발표회 준비 ===\n\n\n\n* 성민영 연구원에게 문자\n: 민영씨, 연락 주셔서 감사합니다 :) 자료 보내주신 후 알람 부탁 드릴께요~ 그리고 내일 기사분이 교수님께 전화 연락을 드릴 수도 있습니다. 그 외에 혹시나 궁금한 사항이 있으시다면 제게 연락주세요~ 감사합니다. 정명준 드림.\n\n* 성민영 연구원에게 문자\n: 민영씨, 일단 내일 배차 (서울대 신공학관 302동 14:30 탑승) 및 석식 예약까지 해두었습니다. 혹시 교수님께 연락이 닿게 되면 내일 일정에 대해서 확인 후 제게 연락 부탁 드립니다~ 감사합니다. 정명준 드림.\n\n* 교수님께 문자 (0162324667)\n: 교수님, 안녕하세요? 기술원의 정명준 전문입니다. 혹시 내일(7/16, 화) 예정대로 산학최종보고회 진행을 해도 되겠습니까? 이와 관련해서 몇 가지 여쭙기 위해 메일을 보내드렸습니다. 그리고 배차를 해드리려 하는데 오늘 오전 중으로 Pick up 장소 및 시간을 확정해서 기사분께 알려드려야 한다고 합니다. 오늘 오전 중으로 알려주시몇 배차가 가능할 것 같습니다. 답장 기다리고 있겠습니다. 감사합니다. 정명준 드림.\n\n* VIP 방문 등록 정보\n{| class=\"wikitable sortable\"\n! 성명 || 소속 || 직책 / 국적 || 생년월일 || 방문기간 || 방문시간\n|-\n| 엄현상 || 서울대학교 컴퓨터공학부 || 교수 / 대한민국 || 1969-07-21 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n| 성민영 || 서울대학교 컴퓨터공학부 || 석사과정 / 대한민국 || 1987-11-14 || 2013-07-16 (화) || 15:20 ~ 17:50\n|-\n|}\n \n* 준비 내용\n <pre>\n네~ 배차 Pick-up 시간/장소에 대해서 오전 중으로 알려주십사 교수님께 요청을 드렸습니다.\n\n아직 확정 연락이 오지는 않았습니다만, 아마 다음과 같이 될 가능성이 많습니다.\n\n      - Pickup 장소: 서울대 신공학관 302동 앞\n\n      - Pickup 시간: 7/16(화) 14:30\n\n그리고 석식을 함께 하시게 될 것인데,\n\n그러면 석식 마친 후 다시 기술원으로 오신 다음,\n\n기사님께서 다시 서울로 모셔다주시는 것 맞죠?\n\n \n\n그리고 VIP 등록이 되면 교수님과 석사연구원이\n\n별도로 방문자 등록을 하지 않아도 되는 것 맞는지도 궁금합니다~ ^^;;\n\n \n\n \n\nVIP 방문 등록을 위해, 일단 아래 인적사항 보내드립니다.\n\n\n\n참, 그리고 가덕 한정식 예약은 아직 하지 못했네요~ ^^;;;\n\n18:00쯤에 5명으로 예약해주시면 참 좋을 것 같습니다. (대략 30만원 정도 비용 예상하고 있습니다)\n\n \n\n항상 감사합니다~~~\n\n정명준 드림.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 10:27 (GMT+09:00)\n\nTitle : Fwd: Re: 회의실 사용문의\n\n \n\n전문님, VIP등록을 위해서는 아래와같은 내용이 필요하니 교수님과 통승하시는 분들 내용을 적어 보내주시면 처리될거 같습니다.\n\n \n\n그리고 차량을 보내드려야된다면 오늘 오전중에 꼭 어디서 타실껀지 알아야되오니, 꼭 확인 부탁드립니다.\n\n \n\n \n  \n  \n  \n \n \n  \n  \n  \n \n성명(방문자)\n 소속(방문자)\n 직책/국적(방문자)\n 생년월일\n \n \n  \n  \n  \n \n차종\n 차량번호\n 방문기간\n 방문시간\n \n \n  \n  \n  \n \n ※ 반입매체 정보\n   \n \n  \n \n\n\n \n\n \n\n그리고 가덕식당은 예약 완료하신거죠??\n\n예약안하셨다면 제가 예약해드리겠습니다.\n\n연락주세요.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n\n \n\n♥┌───────────┐♥\n\n     삼 성 종 합 기 술 원 \n\n         Yu Yeon Ah\n\n \n\n    Tel.   : 031-280-9858\n\n♥└───────────┘♥\n\n \n\n \n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-07-15 09:34 (GMT+09:00)\n\nTitle : Re: 회의실 사용문의\n\n \n\n연아씨, 안녕하세요? ^^\n\n항상 꼼꼼히 챙겨주셔서 정말 감사합니다. :)\n\n \n\n네~ VIP 등록을 해주시면 정말 감사하겠습니다.\n\n(교수님과 학생 1인, 총 2분이 오실 것인데,\n\n 배차를 하게 되더라도 학생은 정문에서 내려서 따로 와야 하는건지 궁금합니다~)\n\n \n\n지금 교수님께 최종 일정 확인 요청을 드린 상태니까\n\n배차 시간및 Pick up 장소 등에 대해서\n\n오전 중에 답이 올 것 같습니다. (오는대로 바로 알려드리겠습니다)\n\n \n\n일단 회의실은 나일로 제가 잡아두었습니다~ \n\n서울대측 참석 인원은 2분이구요,\n\n석식은 가덕한정식의 4만원짜리 메뉴로 생각하고 있습니다.\n\n석식 참가 인원은 5~8명 정도 생각 중입니다.\n\n \n\n곧 다시 연락 드리겠습니다.\n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : 유연아<yeonah78.yu@samsung.com> 사원/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-07-15 08:44 (GMT+09:00)\n\nTitle : 회의실 사용문의\n\n \n\n \n\n안녕하세요. ICL에  유연아입니다.\n\n \n\n전문님 내일 엄현상 교수님과 3시 30분부터 일정 잡아 놓으신게 있으신데요.\n\n \n\n오시는거 맞으신지와 회의실은 어디서 사용하실껀지.\n\n그리고 석식은 어디서 하시는게 좋으신지 의견을 주셨으면 합니다.\n\n \n\n그리고 엄현상 교수님 오실때 VIP 등록을 해드려야 되나요??\n\n\n답변 부탁드리겠습니다.\n\n \n\n궁금하신 사항이 있으시면 언제든 연락 주세요.. ( ☎9858)\n</pre>\n\n== ## bNote-2013-07-09 ==\n\n=== awk ===\n\n* http://www.thegeekstuff.com/2010/02/awk-conditional-statements/\n\n* http://www.thegeekstuff.com/2010/02/unix-awk-operators/\n\n=== 과제 특허 포트폴리오 분석 ===\n\n{| class=\"wikitable sortable\"\n! 세분류 (L4) || No. || 중요도 (상중하) || 경쟁사 핵심특허 특허번호 (출원인) || 당사 핵심특허 주요특허 (기확보전략출원)\n|-\n| IO Workload 예측 || 1 || 상 || US8429307 (EMC) <br/> 사용자가 요청한 IO에 적용되어야 할 스토리지 서비스/액션(compression, encryption 등)을 NN 기반으로 예측하여 자동으로 수행하는 기술 || RN-201307-019-1 <br/> Coaccess 분석 기반 Data Placement\n|-\n| Data Migration 제어 || 1 || 상 || US6912635 (HP) <br/> 미래에 자주 access될만한 data를 하나의 device에 두지 않고 여러 arrayed storage device에 분산 placement 시키는 기술 || RN-201301-004-1 <br/> Hybrid Cache Architecture\n|}\n\n== ## bNote-2013-07-08 ==\n\n=== IEEE ICCE 2014 Paper ===\n\n* [[IEEE ICCE 2014 Paper]]\n* https://edas.info/index.php\n\n== ## bNote-2013-07-04 ==\n\n\n== References ==\n\n<references/>','utf-8'),(865,'== Python grammar ==\n\n=== Asterisk in Python ===\n\nOn asterisks in Python <ref>http://www.technovelty.org/python/on-asterisks-in-python.html</ref> ((B.GOOD))\n\n: Asterisks have lots of meaning in Python. Firstly, consider in a function definition\n\n <pre>\n>>> def function(arg, *vargs, **kargs):\n    print arg\n    print vargs\n    print kargs\n>>> function(1, 2,3,4,5, test1=\"abc\", test2=\"def\")\n1\n(2, 3, 4, 5)\n{\'test1\': \'abc\', \'test2\': \'def\'}\n</pre>\n\n: *vargs puts all left-over non-keyword arguments into a tuple called vargs.\n: **kargs puts all left-over keyword arguments into a dictionary called kargs.\n\n\n: On the other hand, you can use the asterisk with a tuple when calling a function to expand out the elements of the tuple into positional arguments\n\n <pre>\n>>> def function(arg1, arg2, arg3):\n    print arg1, arg2, arg3\n>>> args = (1,2,3)\n>>> function(*args)\n1 2 3\n</pre>\n\n: You can do a similar thing with keyword arguments and a dictionary with the double asterisk operator\n\n <pre>\n>>> def function(arg1=None, arg2=None):\n     print arg1, arg2\n>>> dict = {\"arg1\":\"1\", \"arg2\":\"2\"}\n>>> function(**dict)\n1 2\n</pre>\n\n\n\n== Python hacking ==\n\n=== Memoization in Python ===\n\n* http://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python\n:- What is memoization and how can I use it in Python?\n:- Memoization effectively refers to remembering (\"memoization\" -> \"memorandum\" -> to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 365 of Cormen et al., Introduction To Algorithms (3e).\n:- A simple example for computing factorials using memoization in Python would be something like this:\n\n <pre>\nfactorial_memo = {}\ndef factorial(k):\n    if k < 2: return 1\n    if not k in factorial_memo:\n        factorial_memo[k] = k * factorial(k-1)\n    return factorial_memo[k]\n</pre>\n\n:- You can get more complicated and encapsulate the memoization process into a class\n\n <pre>\nclass Memoize:\n    def __init__(self, f):\n        self.f = f\n        self.memo = {}\n    def __call__(self, *args):\n        if not args in self.memo:\n            self.memo[args] = self.f(*args)\n        return self.memo[args]\n</pre>\n\n:- Then, you get\n\n <pre>\ndef factorial(k):\n    if k < 2: return 1\n    return k * factorial(k - 1)\n\nfactorial = Memoize(factorial)\n</pre>\n\n:- Here is a different implementation that allows for kwargs as well. I didn\'t think to use a class as the example above does, but the decorator method works equally well here:\n\n <pre>\ndef memoize(fn):\n    \"\"\"returns a memoized version of any function that can be called\n    with the same list of arguments.\n    Usage: foo = memoize(foo)\"\"\"\n\n    def foo(*args, **kwargs):\n        items = tuple(sorted(kwargs.items()))\n        if (args, items) not in foo.past_calls:\n            foo.past_calls[(args, items)] = fn(*args,**kwargs)\n        return foo.past_calls[(args, items)]\n    foo.past_calls = dict([])\n    foo.__name__ = \'memoized_\' + fn.__name__ \n    return foo\n\n@memoize\ndef fib: return 1 if n in [0,1] else fib(n-1) + fib(n-2)\n</pre>\n\n:- One thing to watch out for is that the sorted line won\'t always work for all possible argument types. See [http://stackoverflow.com/questions/6407993/how-to-memoize-kwargs How to memoize **kwargs?] for a discussion of this issue, although it seems that there is no perfect fix.\n\n\n=== LRU and LFU cache decorators (Python recipe) ===\n\nhttp://code.activestate.com/recipes/498245-lru-and-lfu-cache-decorators/\n\n <pre>\nimport collections\nimport functools\nfrom itertools import ifilterfalse\nfrom heapq import nsmallest\nfrom operator import itemgetter\n\nclass Counter(dict):\n    \'Mapping where default values are zero\'\n    def __missing__(self, key):\n        return 0\n\ndef lru_cache(maxsize=100):\n    \'\'\'Least-recently-used cache decorator.\n\n    Arguments to the cached function must be hashable.\n    Cache performance statistics stored in f.hits and f.misses.\n    Clear the cache with f.clear().\n    http://en.wikipedia.org/wiki/Cache_algorithms#Least_Recently_Used\n\n    \'\'\'\n    maxqueue = maxsize * 10\n    def decorating_function(user_function,\n            len=len, iter=iter, tuple=tuple, sorted=sorted, KeyError=KeyError):\n        cache = {}                  # mapping of args to results\n        queue = collections.deque() # order that keys have been used\n        refcount = Counter()        # times each key is in the queue\n        sentinel = object()         # marker for looping around the queue\n        kwd_mark = object()         # separate positional and keyword args\n\n        # lookup optimizations (ugly but fast)\n        queue_append, queue_popleft = queue.append, queue.popleft\n        queue_appendleft, queue_pop = queue.appendleft, queue.pop\n\n        @functools.wraps(user_function)\n        def wrapper(*args, **kwds):\n            # cache key records both positional and keyword args\n            key = args\n            if kwds:\n                key += (kwd_mark,) + tuple(sorted(kwds.items()))\n\n            # record recent use of this key\n            queue_append(key)\n            refcount[key] += 1\n\n            # get cache entry or compute if not found\n            try:\n                result = cache[key]\n                wrapper.hits += 1\n            except KeyError:\n                result = user_function(*args, **kwds)\n                cache[key] = result\n                wrapper.misses += 1\n\n                # purge least recently used cache entry\n                if len(cache) > maxsize:\n                    key = queue_popleft()\n                    refcount[key] -= 1\n                    while refcount[key]:\n                        key = queue_popleft()\n                        refcount[key] -= 1\n                    del cache[key], refcount[key]\n\n            # periodically compact the queue by eliminating duplicate keys\n            # while preserving order of most recent access\n            if len(queue) > maxqueue:\n                refcount.clear()\n                queue_appendleft(sentinel)\n                for key in ifilterfalse(refcount.__contains__,\n                                        iter(queue_pop, sentinel)):\n                    queue_appendleft(key)\n                    refcount[key] = 1\n\n\n            return result\n\n        def clear():\n            cache.clear()\n            queue.clear()\n            refcount.clear()\n            wrapper.hits = wrapper.misses = 0\n\n        wrapper.hits = wrapper.misses = 0\n        wrapper.clear = clear\n        return wrapper\n    return decorating_function\n\n\ndef lfu_cache(maxsize=100):\n    \'\'\'Least-frequenty-used cache decorator.\n\n    Arguments to the cached function must be hashable.\n    Cache performance statistics stored in f.hits and f.misses.\n    Clear the cache with f.clear().\n    http://en.wikipedia.org/wiki/Least_Frequently_Used\n\n    \'\'\'\n    def decorating_function(user_function):\n        cache = {}                      # mapping of args to results\n        use_count = Counter()           # times each key has been accessed\n        kwd_mark = object()             # separate positional and keyword args\n\n        @functools.wraps(user_function)\n        def wrapper(*args, **kwds):\n            key = args\n            if kwds:\n                key += (kwd_mark,) + tuple(sorted(kwds.items()))\n            use_count[key] += 1\n\n            # get cache entry or compute if not found\n            try:\n                result = cache[key]\n                wrapper.hits += 1\n            except KeyError:\n                result = user_function(*args, **kwds)\n                cache[key] = result\n                wrapper.misses += 1\n\n                # purge least frequently used cache entry\n                if len(cache) > maxsize:\n                    for key, _ in nsmallest(maxsize // 10,\n                                            use_count.iteritems(),\n                                            key=itemgetter(1)):\n                        del cache[key], use_count[key]\n\n            return result\n\n        def clear():\n            cache.clear()\n            use_count.clear()\n            wrapper.hits = wrapper.misses = 0\n\n        wrapper.hits = wrapper.misses = 0\n        wrapper.clear = clear\n        return wrapper\n    return decorating_function\n\n\nif __name__ == \'__main__\':\n\n    @lru_cache(maxsize=20)\n    def f(x, y):\n        return 3*x+y\n\n    domain = range(5)\n    from random import choice\n    for i in range(1000):\n        r = f(choice(domain), choice(domain))\n\n    print(f.hits, f.misses)\n\n    @lfu_cache(maxsize=20)\n    def f(x, y):\n        return 3*x+y\n\n    domain = range(5)\n    from random import choice\n    for i in range(1000):\n        r = f(choice(domain), choice(domain))\n\n    print(f.hits, f.misses)\n</pre>\n\n== Python related issues ==\n\n=== Python to binary executable ===\n\n* http://www.contrib.andrew.cmu.edu/~minlix/wordpress/?p=83\n: \'Compile\' Python script into executable (freeze.py) -- [G] Celestial Force\n <pre>\n> python freeze.py helloworld.py\n> make\n</pre>\n\n\n* http://www.py2exe.org/\n: py2exe: a Python distutils extension which converts Python scripts into executable Windows programs, able to run without requiring a Python installation\n\n\n* http://www.pyinstaller.org/ ((B.GOOD))\n: PyInstaller: a program that converts (packages) Python programs into stand-alone executables, under Windows, Linux, Mac OS X, Solaris and AIX\n: Main advantages over similar tools are that (1) PyInstaller works with any version of Python since 2.3, (2) it builds smaller executables thanks to transparent compression, (3) it is fully multi-platform, (4) and use the OS support to load the dynamic libraries, thus ensuring full compatibility.\n: git clone git://github.com/pyinstaller/pyinstaller.git\n\n\n* http://excid3.com/blog/python-binary-executables-with-pyinstaller/#.UbMsHPlQFG0\n: Python binary executables with Pyinstaller! -- Chris Oliver\n\n\n* https://code.google.com/p/pts-mini-gpl/wiki/StaticPython\n: StaticPython: a statically linked version of the Python 2.x and 3.x\n\n=== Python 2 or Python 3 ===\n\n* http://wiki.python.org/moin/Python2orPython3\n: Should I use Python 2 or Python 3 for my development activity? - What are the differences?\n\n== References ==\n\n<references/>','utf-8');
/*!40000 ALTER TABLE `radiohead_text` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `radiohead_transcache`
--

DROP TABLE IF EXISTS `radiohead_transcache`;
