INSERT INTO `radiohead_text` VALUES (1960,'\n\n== ## bNote-2013-09-25 ==\n\n=== Task plan ===\n\n* Linux kernel investigating (analyzing/debugging/profiling) practice\n:- Ftrace, printk, ... in detail\n:- Kernel 내 특정 함수를 Ftraceable하게 만들고 싶다면 어떻게?\n:- Kernel 내 특정 operation chain에 대한 performance profiling을 하고 싶다면?\n\n* Caching/Tiering module\n: Get experienced on manipulation\n: Analyze the kernel function flow\n\n* Analysis of various caching algorithms\n: Build a comparison table\n: MQ, ARC, LRU, LFU, 2Q, ...\n\n* Revisit block I/O flow\n: Analyze kernel function flow\n\n<strike>\n* 이사 어떻게 해야 하는지 확인\n* 재직증명서 관련 문의\n* 아버지 함자 보내드리기\n</strike>\n\n== ## bNote-2013-09-24 ==\n\n=== Task plan ===\n\n* Linux kernel investigating (analyzing/debugging/profiling) practice\n:- Ftrace, printk, ... in detail\n:- Kernel 내 특정 함수를 Ftraceable하게 만들고 싶다면 어떻게?\n:- Kernel 내 특정 operation chain에 대한 performance profiling을 하고 싶다면?\n\n* Caching/Tiering module\n: Get experienced on manipulation\n: Analyze the kernel function flow\n\n* Analysis of various caching algorithms\n: Build a comparison table\n: MQ, ARC, LRU, LFU, 2Q, ...\n\n* Revisit block I/O flow\n: Analyze kernel function flow\n\n=== Linux의 Direct I/O 동작 메커니즘, Page Cache와의 관계, 그리고 Radix Tree 모듈 분석 ===\n\n==== Direct I/O 개념 및 사용 목적 ====\n\n* Direct I/O\n: Kernel이 제공하는 page cache를 거치지 않고, 데이터 블럭들이 user-space 메모리와 storage device 간에 직접 이동할 수 있도록 하는 방식임.\n\n* Direct I/O를 수행하는 목적\n: (1) file contents에 대한 caching을 kernel보다 잘 할 수 있는 상황이거나, (2) 가까운 미래에 재사용될 일이 없다고 판단되는 data들이 kernel의 page cache 영역을 불필요하게 채우지 않게 하기 위함. (실제로 RDBMS에서 direct I/O를 많이 이용하고 있으며, Oracle이 좋은 사례임.) <ref>[http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)] &larr;((B.GOOD)) 발췌 내용: The idea behind direct I/O is that data blocks move directly between the storage device and user-space memory without going through the page cache. Developers use direct memory for either (or both) of two reasons: (1) they believe they can manage caching of file contents better than the kernel can, or (2) they want to avoid overflowing the page cache with data which is unlikely to be of use in the near future. It is a relatively little-used feature which is often combined with another obscure kernel capability: asynchronous I/O. The biggest consumers, by far, of this functionality are large relational database systems, so it is not entirely surprising that a developer currently employed by Oracle is working in this area.</ref>\n\n* 참고한 글\n:- [http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)]\n:- [http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP]\n\n==== Direct I/O 내부 메커니즘 ====\n\n일반적으로 file I/O는 address_space_operations 구조체에 의해 point되는 다음 두 function에 의해 처리된다.\n\n include/linux/fs.h:\n int (*writepage)(struct page *page, struct writeback_control *wbc);\n int (*readpage)(struct file *, struct page *);\n\n그러나 direct I/O의 경우에는 위의 두 function이 아니라 별도의 function에 의해 처리된다.\n\n include/linux/fs.h:\n ssize_t (*direct_IO)(int rw, struct kiocb *iocb, const struct iovec *iov, loff_t offset, unsigned long nr_segs);\n\n참고로, fs/block_dev.c에 정의되어 있는 address_space_operations 개체인 def_blk_aops의 경우, function pointer들이 가리키고 있는 다음과 같은 real function을 사용한다.\n\n <pre>\nfs/block_dev.c:\n\nstatic const struct address_space_operations\ndef_blk_aops = {\n        .readpage       = blkdev_readpage,\n        .writepage      = blkdev_writepage,\n        .write_begin    = blkdev_write_begin,\n        .write_end      = blkdev_write_end,\n        .writepages     = generic_writepages,\n        .releasepage    = blkdev_releasepage,\n        .direct_IO      = blkdev_direct_IO,\n        .is_dirty_writeback = buffer_check_dirty_writeback,\n};\n\nstatic int\nblkdev_writepage(struct page *page, struct writeback_control *wbc)\n{\n        return block_write_full_page(page, blkdev_get_block, wbc);\n}\n\nstatic int\nblkdev_readpage(struct file * file, struct page * page)\n{\n        return block_read_full_page(page, blkdev_get_block);\n}\n\n</pre>\n\n==== Direct I/O 사용 시 주의 사항 ====\n\n* Direct IO 수행 시 transfer되는 데이터 크기가 시스템 성능에 미치는 영향\n: Direct IO가 의미 있으려면, 적절한 크기의 데이터를 요청하는 것이 중요. 8KB보다 작은 데이터의 transfer의 경우, 큰 문제가 될 가능성은 작다. 그러나 direct IO를 목적으로 다수의 512KB 블럭 데이터를 \'locking down\'하는 것은 전반적인 시스템 성능에 부정적인 영향을 미칠 수 있으므로 주의해야 한다. \'\'\'&larr; 구체적으로 어떻게?\'\'\' Direct IO request 기간 동안, 데이터 transfer buffer는 고정된 메모리 영역에 mapping되고 locking되기 때문에 swap-out 될 수 없다는 점에 주목할 필요가 있다. 이것이 지나치면 kernel이 동작하는 스타일을 망쳐버릴 수 있다. <ref>[http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP] 발췌내용 - For direct IO to be worthwhile, a reasonable amount of data should be requested for data transfer. For transfers less than 8 KByte it is probably not worth the trouble. On the other hand \"locking down\" a multiple 512 KB blocks of data for direct IO could adversely impact overall system performance. Remember that for the duration of a direct IO request, the data transfer buffer is mapped to a fixed memory location and locked in such a way that it won\'t be swapped out. This can \"cramp the style\" of the kernel if it is overdone.</ref>\n\n==== Direct I/O와 Page Cache와의 관계 ====\n\n\n==== Direct I/O example ====\n\nThis is [http://man7.org/tlpi/code/online/dist/filebuff/direct_read.c.html filebuff/direct_read.c] (Listing 13-1, page 247), an example program file from the book The Linux Programming Interface.\n\nThe source code file is copyright 2010, Michael Kerrisk, and is licensed under the GNU Affero General Public License, version 3.\n\nThis page shows the \"distribution\" or \"book\" version of the file (why are there two versions?), or the differences between the two versions. You can switch between the views using the tabs below.\n\nIn the listing below, the names of Linux system calls and C library functions are hyperlinked to manual pages from the Linux man-pages project, and the names of functions implemented in the book are hyperlinked to the implementations of those functions.\n\n <pre>\n/* direct_read.c\n\n   Demonstrate the use of O_DIRECT to perform I/O bypassing the buffer cache\n   (\"direct I/O\").\n\n   Usage: direct_read file length [offset [alignment]]\n\n   This program is Linux-specific.\n*/\n#define _GNU_SOURCE     /* Obtain O_DIRECT definition from <fcntl.h> */\n#include <fcntl.h>\n#include <malloc.h>\n#include \"tlpi_hdr.h\"\n\nint\nmain(int argc, char *argv[])\n{\n    int fd;\n    ssize_t numRead;\n    size_t length, alignment;\n    off_t offset;\n    char *buf;\n\n    if (argc < 3 || strcmp(argv[1], \"--help\") == 0)\n        usageErr(\"%s file length [offset [alignment]]\\n\", argv[0]);\n\n    length = getLong(argv[2], GN_ANY_BASE, \"length\");\n    offset = (argc > 3) ? getLong(argv[3], GN_ANY_BASE, \"offset\") : 0;\n    alignment = (argc > 4) ? getLong(argv[4], GN_ANY_BASE, \"alignment\") : 4096;\n\n    fd = open(argv[1], O_RDONLY | O_DIRECT);\n    if (fd == -1)\n        errExit(\"open\");\n\n    /* memalign() allocates a block of memory aligned on an address that\n       is a multiple of its first argument. By specifying this argument as\n       2 * \'alignment\' and then adding \'alignment\' to the returned pointer,\n       we ensure that \'buf\' is aligned on a non-power-of-two multiple of\n       \'alignment\'. We do this to ensure that if, for example, we ask\n       for a 256-byte aligned buffer, we don\'t accidentally get\n       a buffer that is also aligned on a 512-byte boundary. */\n\n    buf = memalign(alignment * 2, length + alignment);\n    if (buf == NULL)\n        errExit(\"memalign\");\n\n    buf += alignment;\n\n    if (lseek(fd, offset, SEEK_SET) == -1)\n        errExit(\"lseek\");\n\n    numRead = read(fd, buf, length);\n    if (numRead == -1)\n        errExit(\"read\");\n    printf(\"Read %ld bytes\\n\", (long) numRead);\n\n    exit(EXIT_SUCCESS);\n}\n</pre>\n\n\n==== Red-black tree ====\n\nLinux의 lib/radix-tree.c 파일에 구현되어 있음.\n\n\n==== Radix tree ====\n\nLinux의 lib/rbtree.c 파일에 구현되어 있음.\n\n\n==== IIO (Linux Industrial I/O Subsystem) ====\n\n* IIO (Linux Industrial I/O Subsystem) <ref>https://archive.fosdem.org/2012/schedule/event/693/127_iio-a-new-subsystem.pdf (Maxime Ripard, Free Electrons, 2012-02-14)</ref>\n:- A subsystem for Analog to Digital Converters (ADCs) and related hardwares (accelerometers, light sensors, gyroscopes), but also DACs\n:- Can be used on ADCs ranging from a SoC ADC to 100M samples/sec industrial ADCs\n:- Until recently, mostly focused on user-space abstraction with no in-kernel API for other drivers\n\n{| class=\"wikitable sortable\"\n|+ [http://wiki.analog.com/software/linux/docs/iio/iio Linux Industrial I/O Subsystem]\n|-\n| IIO subsystem overview\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/iio/iio_block_view.png?w=600\" width=\"400\"/>\n|-\n| IIO ring buffer / kfifo\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/ringbuffer.png\" width=\"400\"/>\n|-\n|}\n\n== ## bNote-2013-09-23 ==\n\n=== News from JPLee ===\n\n* 심은수상무님과 정재헌상무님 석식 (9/23)\n:- 서로의 감정 움직임 이해 필요 (인지상정)\n:- 메모리사에서 필요하다고 느끼는 일들을 찾아서 할 것 (기술원 옷을 벗고 메모리사 옷을 입어라)\n:- 직급 서열이 매우 확고하게 서있음\n:- 경력사항 정성껏 잘, 눈에 쏙 들어오도록 기재할 것\n\n== ## bNote-2013-09-22 ==\n\n* [[Industry intelligence - storage]]\n\n* [[Industry intelligence - big data]]\n\n* [[Academia intelligence]]\n\n== ## bNote-2013-09-13 ==\n\n=== Flash Memory Summit 2013 ===\n* [[Industry Intelligence - Flash Memory Summit 2013]]\n\n== ## bNote-2013-09-12 ==\n\n* [[Industry intelligence - storage]]\n\n== ## bNote-2013-09-11 ==\n\n* http://admission.snu.ac.kr/graduate\n: 지원서 접수 마감: 2013-10-18 18:00 \n: TOEFL (CBT / IBT / PBT : 227 / 86 / 567)\n\n* [[Workload analysis-driven system architecture design]]\n* [[Brian Myungjune JUNG]]\n\n== ## bNote-2013-09-10 ==\n\n=== Preparing Talk 2013-09-11 ===\n\n* SHOULD get focused!!!\n: separate topics to be discussed from topics to hide (no need to mention)\n\n* Research goal\n: Devise distinguished approaches which leads to the fundamental change in the\ndistributed computing paradigm\n\n* History and future direction based on the map of \'time/area axes\'\n:- to show the direction and motivation\n:- to reveal all the topics connected organically\n:- to reveal the real capability (programming, patents, papers, ...)\n\n* Capability: programming\n:- R, Python, and shell for analysis (esp. list familiar R packages)\n::- R statistical computing framework (frequent itemset mining, association rules mining, HMM, neuralnet)\n:- C and Assembly reading for kernel development\n::- Fusion IO VSL (virtualized storage layer) analysis\n\n* Capability: standardization experience\n:- LiMo Security TF: SPEF (Security policy enforcement framework) with Motorola\n:- Good technical communication\n\n* Patents portfolio\n:- List up all the patents to reveal the technical experience\n:- Strategic patents\n\n* Paper portfolio\n:- List up all the papers to reveal the technical experience\n\n* Study plan - Virtualization, Hadoop, ARM, Workload Analysis\n: Green computing\n: Profiling\n: Bottleneck analysis\n\n\n=== Note ===\n\n----\n\n* VDI VM data backup\n\n* VDI VM access (F:)\n: \\\\75.1.240.249\\SAIT$\\brian.m.jung\n:: Microsoft Windows Network\n\n* VDI VM access (R:)\n: \\\\75.1.240.244\\sharesait72$\n:: Microsoft Windows Network\n\n <pre>\n\n# Architect // 3.27 GB\n# atlas // 13.9 GB\n# FutureOS // 6.35 GB\n~ gto // 7.11 GB\n~ Multicore // 7.27 GB\nosv // 64.9 GB\nosv/__SW_Mobility // 29.4 GB\nosv_sds // 16.0 GB\nse기획_ok // 24.8 GB\nStorage // \n~ swgto // 3.60 GB\n~ sw역량강화 // 2.27 GB\n~ 인적역량wg // 0.0503 GB\n\n</pre>\n\n* VDI VM access (--)\n: \\\\168.219.177.80\\종기원\n:: Microsoft Windows Network\n\n\n----\n\n연락처, 전화번호\n구본철 010-9190-5907 01091905907\n신현정 017-324-9294 0173249294\n\n----\n\n== ## bNote-2013-09-09 ==\n\n=== Micro server ===\n\n* http://armservers.com/2012/11/16/whats-a-little-core-like-arm-doing-in-a-place-like-this/#more-452\n\n* SeaMicro Vs. Calxeda Vs. Samsung\n* Barcelona Supercomputing Center - Samsung (Dual core A15 with Mali GPUs)\n\n* Calxeda\n: Calxeda\'s massive fabric and performance roadmap?\n\n=== SuperComputing \'12 ===\n\n* IEEE SuperComputing \'12 Salt Lake City\n: 과거에는 (Tera)Flops, Fortran이 hot topic들이었다면,\n: 요즘은 Big Data, HW acceleration, interconnect fabrics, storage , green\ncomputing 등이 hot topic들임.\n\n\n=== Letter ===\n\n장수석님. 2013-09-09\n\n<!--\n\n{ // 2013-09-09\n\n장수석님, 안녕하세요?\n\n기술원의 정명준 전문입니다.\n\n \n\n지난 주 목요일, 부회장님 말씀으로\n\n저희 팀 5명이 메모리사업부 SW개발팀으로 전격 배치되어,\n\nDS SW 연구소로 가지 못할 것 같습니다.\n\n \n\n이미 아시리라 생각합니다만,\n\n그래도 직접 말씀 드리고\n\n죄송하다는 인사를 드려야 할 것 같아서\n\n메일 드렸습니다.\n\n \n\n이번 배치로, 사업부 개발팀에서의 경험을 통해\n\n실제 제품의 메커니즘 및 현장의 생리를 이해하고 겪어볼 수 있을 것 같습니다.\n\n다만, 기술원에서 하던 연구를 더욱 심화할 수 있었던 좋은 기회를\n\nOfficial하게 살리지 못하게 된 것은 무척 아쉽습니다.\n\n(이와 관련해서는, 어떻게든 시간과 기회를 만들어서 연구를 계속 할 생각입니다.)\n\n \n\n바쁘신 중에 연락도 주시고 많이 챙겨주셨는데\n\n부응하지 못하게 되어 정말 죄송하고, 안타깝습니다.\n\n \n\n김전무님, 장수석님과 함께\n\n다시 연구할 수 있는 좋은 기회가 있기를 간절히 바라면서\n\n이만 인사 드리겠습니다.\n\n \n\n항상 즐겁고 건강하세요.\n\n정명준 드림. ^___^\n\n}\n\n-->\n\n== ## bNote-2013-09-05 ==\n\n* 목요일 있었던 권부회장님께 보고 회의에서, 권부회장님에 의해서 메모리사업부 개발팀으로 전격 변경됨\n\n* 기술원에서의 마지막 GWP 행사 (강남역 근처 와인나라 아카데미에서 와인강좌 수강, SevenSprings 강남점에서 저녁 회식)\n\n== ## bNote-2013-09-04 ==\n\n=== Large-scale machine learning framework ===\n\n: Large-scale의 분산 ML 프레임워크 조사 관련, Mahout과 Impala 내용 Quick 하게 보내드립니다.\n: 참고로, Impala가 Cloudera에 의해 만들어진 것은 맞습니다만, ML 관련된 Framework은 아닙니다. 이 점 정정합니다. (혼란을 드려 죄송합니다)\n\n==== Mahout ====\n\n: http://mahout.apache.org/\n: Apache Hadoop 기반의 Machine Learning Framework. (MapReduce 이용)\n: \'13년 7월 25일 현재 0.8 버전 릴리즈\n: Clustering, Classification, Mining 기능 제공 (K-Means, Neural Network, SVM, Naive Bayes classification, Frequent itemset mining, HMM 등 포함) <ref>https://cwiki.apache.org/confluence/display/MAHOUT/Algorithms</ref>\n:: -> Neural Network 관련, one hidden layer에 대한 back propagation 기능을 구현 중인 듯 함 (Code 상에서 확인 필요)\n\n==== Impala ====\n\n: http://www.cloudera.com/content/cloudera/en/products/cdh/impala.html\n: Apache Hadoop 상에서 구동되는 Real-time Query 엔진으로서, scalable parallel DB 기술으로 볼 수 있음. (Machine Learning과 무관)\n: Apache HBase 및 HDFS에 저장된 데이터에 대한 low-latency SQL query 기술임\n: Hadoop 스케일의 interactive한 large-scale data processing 을 가능케 함\n\n==== Multicore에서의 ML을 위한 Map-Reduce 연구 (by Stanford, NIPS \'06) ====\n\n: http://www.cs.stanford.edu/people/ang/papers/nips06-mapreducemulticore.pdf\n: K-means, SVM, Naive Bayes 등 뿐만 아니라 특히 2개의 output neuron을 갖는 3-layer NN에 대한 Back propagation에 대해서 위의 구조를 적용. (Mahout에서도 이 연구를 참고하는 것으로 보임)\n\n== ## bNote-2013-09-03 ==\n\n=== Research planning ===\n\n==== Ecosystem analysis ====\n\n* Ecosystem decomposition\n:* Device manufacturer/designer\n::- Samsung, Intel, NVIDIA, ARM, Calxeda, SeaMicro, ...\n:* Consumer product manufacturer\n::- Apple, Samsung, Sony, Huawei, ...\n:* Enterprise product manufacturer\n::- EMC, NetApp, Oracle (Appliance), IBM, HP, Dell, Cisco, ... \n:* Service provider\n::- Google (Web-based all), Amazon (eCommerce), Facebook, Twitter, ...\n:* Content provider\n::- Google (YouTube), Disney, Pixar, Sony, ...\n:* Software company\n::- Google (Android), Oracle (DB), Microsoft, Canonical, Red Hat, Cloudera, Citrix, ... \n:* Cloud company <ref>The Top 20 Infrastructure as a Service (IaaS) Vendors http://www.clouds360.com/iaas.php</ref> <ref>Research: 2012 State of Cloud Computing - InformationWeek http://reports.informationweek.com/abstract/5/8658/Cloud-Computing/research-2012-state-of-cloud-computing.html</ref> <ref>Research: Cloud Software: Where Next? http://reports.informationweek.com/abstract/7/11215/Enterprise-Software/Research:-Cloud-Software:-Where-Next?.html</ref> <ref>Research: Cloud Security and Risk Survey http://reports.informationweek.com/abstract/5/11335/Cloud-Computing/Research:-Cloud-Security-and-Risk-Survey.html</ref>\n::- Amazon (AWS), Google (Gmail, Drive), AT&T, Verizon (Terremark), Rackspace, Savvis, GoGrid, Datapipe, ...\n\n\n=== Open innovation benchmark ===\n\n* Leading companies in open innovation\n: Intel (Open Source on Intel)\n\n\n==== Intel case: Open Source on Intel ====\n\n* [http://software.intel.com/en-us/oss Open Source on Intel]\n* [http://software.intel.com/sites/campaigns/sparks/ Igniting Sparks of Innovation]\n\n\n==== Research reports ====\n\n* [How Attackers Target and Exploit Social Networking Users - InformationWeek http://reports.informationweek.com/abstract/21/11235/Security/How-Attackers-Target-and-Exploit-Social-Networking-Users.html]\n\n* [Here Comes the Internet of Things - InformationWeek http://reports.informationweek.com/abstract/83/11058/IT-Business-Strategy/Here-Comes-the-Internet-of-Things.html]\n\n* [Research: 2014 Federal Government IT Priorities - InformationWeek http://reports.informationweek.com/abstract/104/11175/Government/Research:-2014-Federal-Government-IT-Priorities.html]\n\n* [The Top 20 Infrastructure as a Service (IaaS) Vendors http://www.clouds360.com/iaas.php]\n\n* [Research: 2012 State of Cloud Computing - InformationWeek http://reports.informationweek.com/abstract/5/8658/Cloud-Computing/research-2012-state-of-cloud-computing.html]\n\n* [Research: Cloud Software: Where Next?  - InformationWeek http://reports.informationweek.com/abstract/7/11215/Enterprise-Software/Research:-Cloud-Software:-Where-Next?.html]\n\n* [Research: Cloud Security and Risk Survey  - InformationWeek http://reports.informationweek.com/abstract/5/11335/Cloud-Computing/Research:-Cloud-Security-and-Risk-Survey.html]\n\n== References ==\n\n<references/>','utf-8'),(1961,'\n\n== I/O ==\n\n=== [[Direct I/O]] ===\n\n\n== References ==\n\n<references/>','utf-8'),(1962,'\n\n== I/O ==\n\n=== Direct I/O ===\n\n== References ==\n\n<references/>','utf-8'),(1963,'\n\n== I/O ==\n\n=== Direct I/O ===\n\n==== Direct I/O 개념 및 사용 목적 ====\n\n* Direct I/O\n: Kernel이 제공하는 page cache를 거치지 않고, 데이터 블럭들이 user-space 메모리와 storage device 간에 직접 이동할 수 있도록 하는 방식임.\n\n* Direct I/O를 수행하는 목적\n: (1) file contents에 대한 caching을 kernel보다 잘 할 수 있는 상황이거나, (2) 가까운 미래에 재사용될 일이 없다고 판단되는 data들이 kernel의 page cache 영역을 불필요하게 채우지 않게 하기 위함. (실제로 RDBMS에서 direct I/O를 많이 이용하고 있으며, Oracle이 좋은 사례임.) <ref>[http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)] &larr;((B.GOOD)) 발췌 내용: The idea behind direct I/O is that data blocks move directly between the storage device and user-space memory without going through the page cache. Developers use direct memory for either (or both) of two reasons: (1) they believe they can manage caching of file contents better than the kernel can, or (2) they want to avoid overflowing the page cache with data which is unlikely to be of use in the near future. It is a relatively little-used feature which is often combined with another obscure kernel capability: asynchronous I/O. The biggest consumers, by far, of this functionality are large relational database systems, so it is not entirely surprising that a developer currently employed by Oracle is working in this area.</ref>\n\n* 참고한 글\n:- [http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)]\n:- [http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP]\n\n==== Direct I/O 내부 메커니즘 ====\n\n일반적으로 file I/O는 address_space_operations 구조체에 의해 point되는 다음 두 function에 의해 처리된다.\n\n include/linux/fs.h:\n int (*writepage)(struct page *page, struct writeback_control *wbc);\n int (*readpage)(struct file *, struct page *);\n\n그러나 direct I/O의 경우에는 위의 두 function이 아니라 별도의 function에 의해 처리된다.\n\n include/linux/fs.h:\n ssize_t (*direct_IO)(int rw, struct kiocb *iocb, const struct iovec *iov, loff_t offset, unsigned long nr_segs);\n\n참고로, fs/block_dev.c에 정의되어 있는 address_space_operations 개체인 def_blk_aops의 경우, function pointer들이 가리키고 있는 다음과 같은 real function을 사용한다.\n\n <pre>\nfs/block_dev.c:\n\nstatic const struct address_space_operations\ndef_blk_aops = {\n        .readpage       = blkdev_readpage,\n        .writepage      = blkdev_writepage,\n        .write_begin    = blkdev_write_begin,\n        .write_end      = blkdev_write_end,\n        .writepages     = generic_writepages,\n        .releasepage    = blkdev_releasepage,\n        .direct_IO      = blkdev_direct_IO,\n        .is_dirty_writeback = buffer_check_dirty_writeback,\n};\n\nstatic int\nblkdev_writepage(struct page *page, struct writeback_control *wbc)\n{\n        return block_write_full_page(page, blkdev_get_block, wbc);\n}\n\nstatic int\nblkdev_readpage(struct file * file, struct page * page)\n{\n        return block_read_full_page(page, blkdev_get_block);\n}\n\n</pre>\n\n==== Direct I/O 사용 시 주의 사항 ====\n\n* Direct IO 수행 시 transfer되는 데이터 크기가 시스템 성능에 미치는 영향\n: Direct IO가 의미 있으려면, 적절한 크기의 데이터를 요청하는 것이 중요. 8KB보다 작은 데이터의 transfer의 경우, 큰 문제가 될 가능성은 작다. 그러나 direct IO를 목적으로 다수의 512KB 블럭 데이터를 \'locking down\'하는 것은 전반적인 시스템 성능에 부정적인 영향을 미칠 수 있으므로 주의해야 한다. \'\'\'&larr; 구체적으로 어떻게?\'\'\' Direct IO request 기간 동안, 데이터 transfer buffer는 고정된 메모리 영역에 mapping되고 locking되기 때문에 swap-out 될 수 없다는 점에 주목할 필요가 있다. 이것이 지나치면 kernel이 동작하는 스타일을 망쳐버릴 수 있다. <ref>[http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP] 발췌내용 - For direct IO to be worthwhile, a reasonable amount of data should be requested for data transfer. For transfers less than 8 KByte it is probably not worth the trouble. On the other hand \"locking down\" a multiple 512 KB blocks of data for direct IO could adversely impact overall system performance. Remember that for the duration of a direct IO request, the data transfer buffer is mapped to a fixed memory location and locked in such a way that it won\'t be swapped out. This can \"cramp the style\" of the kernel if it is overdone.</ref>\n\n==== Direct I/O와 Page Cache와의 관계 ====\n\n\n==== Direct I/O example ====\n\nThis is [http://man7.org/tlpi/code/online/dist/filebuff/direct_read.c.html filebuff/direct_read.c] (Listing 13-1, page 247), an example program file from the book The Linux Programming Interface.\n\nThe source code file is copyright 2010, Michael Kerrisk, and is licensed under the GNU Affero General Public License, version 3.\n\nThis page shows the \"distribution\" or \"book\" version of the file (why are there two versions?), or the differences between the two versions. You can switch between the views using the tabs below.\n\nIn the listing below, the names of Linux system calls and C library functions are hyperlinked to manual pages from the Linux man-pages project, and the names of functions implemented in the book are hyperlinked to the implementations of those functions.\n\n <pre>\n/* direct_read.c\n\n   Demonstrate the use of O_DIRECT to perform I/O bypassing the buffer cache\n   (\"direct I/O\").\n\n   Usage: direct_read file length [offset [alignment]]\n\n   This program is Linux-specific.\n*/\n#define _GNU_SOURCE     /* Obtain O_DIRECT definition from <fcntl.h> */\n#include <fcntl.h>\n#include <malloc.h>\n#include \"tlpi_hdr.h\"\n\nint\nmain(int argc, char *argv[])\n{\n    int fd;\n    ssize_t numRead;\n    size_t length, alignment;\n    off_t offset;\n    char *buf;\n\n    if (argc < 3 || strcmp(argv[1], \"--help\") == 0)\n        usageErr(\"%s file length [offset [alignment]]\\n\", argv[0]);\n\n    length = getLong(argv[2], GN_ANY_BASE, \"length\");\n    offset = (argc > 3) ? getLong(argv[3], GN_ANY_BASE, \"offset\") : 0;\n    alignment = (argc > 4) ? getLong(argv[4], GN_ANY_BASE, \"alignment\") : 4096;\n\n    fd = open(argv[1], O_RDONLY | O_DIRECT);\n    if (fd == -1)\n        errExit(\"open\");\n\n    /* memalign() allocates a block of memory aligned on an address that\n       is a multiple of its first argument. By specifying this argument as\n       2 * \'alignment\' and then adding \'alignment\' to the returned pointer,\n       we ensure that \'buf\' is aligned on a non-power-of-two multiple of\n       \'alignment\'. We do this to ensure that if, for example, we ask\n       for a 256-byte aligned buffer, we don\'t accidentally get\n       a buffer that is also aligned on a 512-byte boundary. */\n\n    buf = memalign(alignment * 2, length + alignment);\n    if (buf == NULL)\n        errExit(\"memalign\");\n\n    buf += alignment;\n\n    if (lseek(fd, offset, SEEK_SET) == -1)\n        errExit(\"lseek\");\n\n    numRead = read(fd, buf, length);\n    if (numRead == -1)\n        errExit(\"read\");\n    printf(\"Read %ld bytes\\n\", (long) numRead);\n\n    exit(EXIT_SUCCESS);\n}\n</pre>\n\n\n==== Red-black tree ====\n\nLinux의 lib/radix-tree.c 파일에 구현되어 있음.\n\n\n==== Radix tree ====\n\nLinux의 lib/rbtree.c 파일에 구현되어 있음.\n\n\n==== IIO (Linux Industrial I/O Subsystem) ====\n\n* IIO (Linux Industrial I/O Subsystem) <ref>https://archive.fosdem.org/2012/schedule/event/693/127_iio-a-new-subsystem.pdf (Maxime Ripard, Free Electrons, 2012-02-14)</ref>\n:- A subsystem for Analog to Digital Converters (ADCs) and related hardwares (accelerometers, light sensors, gyroscopes), but also DACs\n:- Can be used on ADCs ranging from a SoC ADC to 100M samples/sec industrial ADCs\n:- Until recently, mostly focused on user-space abstraction with no in-kernel API for other drivers\n\n{| class=\"wikitable sortable\"\n|+ [http://wiki.analog.com/software/linux/docs/iio/iio Linux Industrial I/O Subsystem]\n|-\n| IIO subsystem overview\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/iio/iio_block_view.png?w=600\" width=\"400\"/>\n|-\n| IIO ring buffer / kfifo\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/ringbuffer.png\" width=\"400\"/>\n|-\n|}\n\n== References ==\n\n<references/>','utf-8'),(1964,'\n\n== I/O ==\n\n=== Direct I/O ===\n\n==== Direct I/O 개념 및 사용 목적 ====\n\n* Direct I/O\n: Kernel이 제공하는 page cache를 거치지 않고, 데이터 블럭들이 user-space 메모리와 storage device 간에 직접 이동할 수 있도록 하는 방식임.\n\n* Direct I/O를 수행하는 목적\n: (1) file contents에 대한 caching을 kernel보다 잘 할 수 있는 상황이거나, (2) 가까운 미래에 재사용될 일이 없다고 판단되는 data들이 kernel의 page cache 영역을 불필요하게 채우지 않게 하기 위함. (실제로 RDBMS에서 direct I/O를 많이 이용하고 있으며, Oracle이 좋은 사례임.) <ref>[http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)] &larr;((B.GOOD)) 발췌 내용: The idea behind direct I/O is that data blocks move directly between the storage device and user-space memory without going through the page cache. Developers use direct memory for either (or both) of two reasons: (1) they believe they can manage caching of file contents better than the kernel can, or (2) they want to avoid overflowing the page cache with data which is unlikely to be of use in the near future. It is a relatively little-used feature which is often combined with another obscure kernel capability: asynchronous I/O. The biggest consumers, by far, of this functionality are large relational database systems, so it is not entirely surprising that a developer currently employed by Oracle is working in this area.</ref>\n\n* 참고한 글\n:- [http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)]\n:- [http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP]\n\n==== Direct I/O 내부 메커니즘 ====\n\n일반적으로 file I/O는 address_space_operations 구조체에 의해 point되는 다음 두 function에 의해 처리된다.\n\n include/linux/fs.h:\n int (*writepage)(struct page *page, struct writeback_control *wbc);\n int (*readpage)(struct file *, struct page *);\n\n그러나 direct I/O의 경우에는 위의 두 function이 아니라 별도의 function에 의해 처리된다.\n\n include/linux/fs.h:\n ssize_t (*direct_IO)(int rw, struct kiocb *iocb, const struct iovec *iov, loff_t offset, unsigned long nr_segs);\n\n참고로, fs/block_dev.c에 정의되어 있는 address_space_operations 개체인 def_blk_aops의 경우, function pointer들이 가리키고 있는 다음과 같은 real function을 사용한다.\n\n <pre>\nfs/block_dev.c:\n\nstatic const struct address_space_operations\ndef_blk_aops = {\n        .readpage       = blkdev_readpage,\n        .writepage      = blkdev_writepage,\n        .write_begin    = blkdev_write_begin,\n        .write_end      = blkdev_write_end,\n        .writepages     = generic_writepages,\n        .releasepage    = blkdev_releasepage,\n        .direct_IO      = blkdev_direct_IO,\n        .is_dirty_writeback = buffer_check_dirty_writeback,\n};\n\nstatic int\nblkdev_writepage(struct page *page, struct writeback_control *wbc)\n{\n        return block_write_full_page(page, blkdev_get_block, wbc);\n}\n\nstatic int\nblkdev_readpage(struct file * file, struct page * page)\n{\n        return block_read_full_page(page, blkdev_get_block);\n}\n\n</pre>\n\n==== Direct I/O 사용 시 주의 사항 ====\n\n* Direct IO 수행 시 transfer되는 데이터 크기가 시스템 성능에 미치는 영향\n: Direct IO가 의미 있으려면, 적절한 크기의 데이터를 요청하는 것이 중요. 8KB보다 작은 데이터의 transfer의 경우, 큰 문제가 될 가능성은 작다. 그러나 direct IO를 목적으로 다수의 512KB 블럭 데이터를 \'locking down\'하는 것은 전반적인 시스템 성능에 부정적인 영향을 미칠 수 있으므로 주의해야 한다. \'\'\'&larr; 구체적으로 어떻게?\'\'\' Direct IO request 기간 동안, 데이터 transfer buffer는 고정된 메모리 영역에 mapping되고 locking되기 때문에 swap-out 될 수 없다는 점에 주목할 필요가 있다. 이것이 지나치면 kernel이 동작하는 스타일을 망쳐버릴 수 있다. <ref>[http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP] 발췌내용 - For direct IO to be worthwhile, a reasonable amount of data should be requested for data transfer. For transfers less than 8 KByte it is probably not worth the trouble. On the other hand \"locking down\" a multiple 512 KB blocks of data for direct IO could adversely impact overall system performance. Remember that for the duration of a direct IO request, the data transfer buffer is mapped to a fixed memory location and locked in such a way that it won\'t be swapped out. This can \"cramp the style\" of the kernel if it is overdone.</ref>\n\n==== Direct I/O와 Page Cache와의 관계 ====\n\n\n==== Direct I/O example ====\n\nThis is [http://man7.org/tlpi/code/online/dist/filebuff/direct_read.c.html filebuff/direct_read.c] (Listing 13-1, page 247), an example program file from the book The Linux Programming Interface.\n\nThe source code file is copyright 2010, Michael Kerrisk, and is licensed under the GNU Affero General Public License, version 3.\n\nThis page shows the \"distribution\" or \"book\" version of the file (why are there two versions?), or the differences between the two versions. You can switch between the views using the tabs below.\n\nIn the listing below, the names of Linux system calls and C library functions are hyperlinked to manual pages from the Linux man-pages project, and the names of functions implemented in the book are hyperlinked to the implementations of those functions.\n\n <pre>\n/* direct_read.c\n\n   Demonstrate the use of O_DIRECT to perform I/O bypassing the buffer cache\n   (\"direct I/O\").\n\n   Usage: direct_read file length [offset [alignment]]\n\n   This program is Linux-specific.\n*/\n#define _GNU_SOURCE     /* Obtain O_DIRECT definition from <fcntl.h> */\n#include <fcntl.h>\n#include <malloc.h>\n#include \"tlpi_hdr.h\"\n\nint\nmain(int argc, char *argv[])\n{\n    int fd;\n    ssize_t numRead;\n    size_t length, alignment;\n    off_t offset;\n    char *buf;\n\n    if (argc < 3 || strcmp(argv[1], \"--help\") == 0)\n        usageErr(\"%s file length [offset [alignment]]\\n\", argv[0]);\n\n    length = getLong(argv[2], GN_ANY_BASE, \"length\");\n    offset = (argc > 3) ? getLong(argv[3], GN_ANY_BASE, \"offset\") : 0;\n    alignment = (argc > 4) ? getLong(argv[4], GN_ANY_BASE, \"alignment\") : 4096;\n\n    fd = open(argv[1], O_RDONLY | O_DIRECT);\n    if (fd == -1)\n        errExit(\"open\");\n\n    /* memalign() allocates a block of memory aligned on an address that\n       is a multiple of its first argument. By specifying this argument as\n       2 * \'alignment\' and then adding \'alignment\' to the returned pointer,\n       we ensure that \'buf\' is aligned on a non-power-of-two multiple of\n       \'alignment\'. We do this to ensure that if, for example, we ask\n       for a 256-byte aligned buffer, we don\'t accidentally get\n       a buffer that is also aligned on a 512-byte boundary. */\n\n    buf = memalign(alignment * 2, length + alignment);\n    if (buf == NULL)\n        errExit(\"memalign\");\n\n    buf += alignment;\n\n    if (lseek(fd, offset, SEEK_SET) == -1)\n        errExit(\"lseek\");\n\n    numRead = read(fd, buf, length);\n    if (numRead == -1)\n        errExit(\"read\");\n    printf(\"Read %ld bytes\\n\", (long) numRead);\n\n    exit(EXIT_SUCCESS);\n}\n</pre>\n\n== References ==\n\n<references/>','utf-8'),(1965,'\n\n\n== Algorithm ==\n\n=== Red-black tree ===\n\nLinux의 lib/radix-tree.c 파일에 구현되어 있음.\n\n\n=== Radix tree ===\n\nLinux의 lib/rbtree.c 파일에 구현되어 있음.\n\n\n== I/O ==\n\n=== Direct I/O ===\n\n==== Direct I/O 개념 및 사용 목적 ====\n\n* Direct I/O\n: Kernel이 제공하는 page cache를 거치지 않고, 데이터 블럭들이 user-space 메모리와 storage device 간에 직접 이동할 수 있도록 하는 방식임.\n\n* Direct I/O를 수행하는 목적\n: (1) file contents에 대한 caching을 kernel보다 잘 할 수 있는 상황이거나, (2) 가까운 미래에 재사용될 일이 없다고 판단되는 data들이 kernel의 page cache 영역을 불필요하게 채우지 않게 하기 위함. (실제로 RDBMS에서 direct I/O를 많이 이용하고 있으며, Oracle이 좋은 사례임.) <ref>[http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)] &larr;((B.GOOD)) 발췌 내용: The idea behind direct I/O is that data blocks move directly between the storage device and user-space memory without going through the page cache. Developers use direct memory for either (or both) of two reasons: (1) they believe they can manage caching of file contents better than the kernel can, or (2) they want to avoid overflowing the page cache with data which is unlikely to be of use in the near future. It is a relatively little-used feature which is often combined with another obscure kernel capability: asynchronous I/O. The biggest consumers, by far, of this functionality are large relational database systems, so it is not entirely surprising that a developer currently employed by Oracle is working in this area.</ref>\n\n* 참고한 글\n:- [http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)]\n:- [http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP]\n\n==== Direct I/O 내부 메커니즘 ====\n\n일반적으로 file I/O는 address_space_operations 구조체에 의해 point되는 다음 두 function에 의해 처리된다.\n\n include/linux/fs.h:\n int (*writepage)(struct page *page, struct writeback_control *wbc);\n int (*readpage)(struct file *, struct page *);\n\n그러나 direct I/O의 경우에는 위의 두 function이 아니라 별도의 function에 의해 처리된다.\n\n include/linux/fs.h:\n ssize_t (*direct_IO)(int rw, struct kiocb *iocb, const struct iovec *iov, loff_t offset, unsigned long nr_segs);\n\n참고로, fs/block_dev.c에 정의되어 있는 address_space_operations 개체인 def_blk_aops의 경우, function pointer들이 가리키고 있는 다음과 같은 real function을 사용한다.\n\n <pre>\nfs/block_dev.c:\n\nstatic const struct address_space_operations\ndef_blk_aops = {\n        .readpage       = blkdev_readpage,\n        .writepage      = blkdev_writepage,\n        .write_begin    = blkdev_write_begin,\n        .write_end      = blkdev_write_end,\n        .writepages     = generic_writepages,\n        .releasepage    = blkdev_releasepage,\n        .direct_IO      = blkdev_direct_IO,\n        .is_dirty_writeback = buffer_check_dirty_writeback,\n};\n\nstatic int\nblkdev_writepage(struct page *page, struct writeback_control *wbc)\n{\n        return block_write_full_page(page, blkdev_get_block, wbc);\n}\n\nstatic int\nblkdev_readpage(struct file * file, struct page * page)\n{\n        return block_read_full_page(page, blkdev_get_block);\n}\n\n</pre>\n\n==== Direct I/O 사용 시 주의 사항 ====\n\n* Direct IO 수행 시 transfer되는 데이터 크기가 시스템 성능에 미치는 영향\n: Direct IO가 의미 있으려면, 적절한 크기의 데이터를 요청하는 것이 중요. 8KB보다 작은 데이터의 transfer의 경우, 큰 문제가 될 가능성은 작다. 그러나 direct IO를 목적으로 다수의 512KB 블럭 데이터를 \'locking down\'하는 것은 전반적인 시스템 성능에 부정적인 영향을 미칠 수 있으므로 주의해야 한다. \'\'\'&larr; 구체적으로 어떻게?\'\'\' Direct IO request 기간 동안, 데이터 transfer buffer는 고정된 메모리 영역에 mapping되고 locking되기 때문에 swap-out 될 수 없다는 점에 주목할 필요가 있다. 이것이 지나치면 kernel이 동작하는 스타일을 망쳐버릴 수 있다. <ref>[http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP] 발췌내용 - For direct IO to be worthwhile, a reasonable amount of data should be requested for data transfer. For transfers less than 8 KByte it is probably not worth the trouble. On the other hand \"locking down\" a multiple 512 KB blocks of data for direct IO could adversely impact overall system performance. Remember that for the duration of a direct IO request, the data transfer buffer is mapped to a fixed memory location and locked in such a way that it won\'t be swapped out. This can \"cramp the style\" of the kernel if it is overdone.</ref>\n\n==== Direct I/O와 Page Cache와의 관계 ====\n\n\n==== Direct I/O example ====\n\nThis is [http://man7.org/tlpi/code/online/dist/filebuff/direct_read.c.html filebuff/direct_read.c] (Listing 13-1, page 247), an example program file from the book The Linux Programming Interface.\n\nThe source code file is copyright 2010, Michael Kerrisk, and is licensed under the GNU Affero General Public License, version 3.\n\nThis page shows the \"distribution\" or \"book\" version of the file (why are there two versions?), or the differences between the two versions. You can switch between the views using the tabs below.\n\nIn the listing below, the names of Linux system calls and C library functions are hyperlinked to manual pages from the Linux man-pages project, and the names of functions implemented in the book are hyperlinked to the implementations of those functions.\n\n <pre>\n/* direct_read.c\n\n   Demonstrate the use of O_DIRECT to perform I/O bypassing the buffer cache\n   (\"direct I/O\").\n\n   Usage: direct_read file length [offset [alignment]]\n\n   This program is Linux-specific.\n*/\n#define _GNU_SOURCE     /* Obtain O_DIRECT definition from <fcntl.h> */\n#include <fcntl.h>\n#include <malloc.h>\n#include \"tlpi_hdr.h\"\n\nint\nmain(int argc, char *argv[])\n{\n    int fd;\n    ssize_t numRead;\n    size_t length, alignment;\n    off_t offset;\n    char *buf;\n\n    if (argc < 3 || strcmp(argv[1], \"--help\") == 0)\n        usageErr(\"%s file length [offset [alignment]]\\n\", argv[0]);\n\n    length = getLong(argv[2], GN_ANY_BASE, \"length\");\n    offset = (argc > 3) ? getLong(argv[3], GN_ANY_BASE, \"offset\") : 0;\n    alignment = (argc > 4) ? getLong(argv[4], GN_ANY_BASE, \"alignment\") : 4096;\n\n    fd = open(argv[1], O_RDONLY | O_DIRECT);\n    if (fd == -1)\n        errExit(\"open\");\n\n    /* memalign() allocates a block of memory aligned on an address that\n       is a multiple of its first argument. By specifying this argument as\n       2 * \'alignment\' and then adding \'alignment\' to the returned pointer,\n       we ensure that \'buf\' is aligned on a non-power-of-two multiple of\n       \'alignment\'. We do this to ensure that if, for example, we ask\n       for a 256-byte aligned buffer, we don\'t accidentally get\n       a buffer that is also aligned on a 512-byte boundary. */\n\n    buf = memalign(alignment * 2, length + alignment);\n    if (buf == NULL)\n        errExit(\"memalign\");\n\n    buf += alignment;\n\n    if (lseek(fd, offset, SEEK_SET) == -1)\n        errExit(\"lseek\");\n\n    numRead = read(fd, buf, length);\n    if (numRead == -1)\n        errExit(\"read\");\n    printf(\"Read %ld bytes\\n\", (long) numRead);\n\n    exit(EXIT_SUCCESS);\n}\n</pre>\n\n\n\n\n=== IIO (Linux Industrial I/O Subsystem) ===\n\n* IIO (Linux Industrial I/O Subsystem) <ref>https://archive.fosdem.org/2012/schedule/event/693/127_iio-a-new-subsystem.pdf (Maxime Ripard, Free Electrons, 2012-02-14)</ref>\n:- A subsystem for Analog to Digital Converters (ADCs) and related hardwares (accelerometers, light sensors, gyroscopes), but also DACs\n:- Can be used on ADCs ranging from a SoC ADC to 100M samples/sec industrial ADCs\n:- Until recently, mostly focused on user-space abstraction with no in-kernel API for other drivers\n\n{| class=\"wikitable sortable\"\n|+ [http://wiki.analog.com/software/linux/docs/iio/iio Linux Industrial I/O Subsystem]\n|-\n| IIO subsystem overview\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/iio/iio_block_view.png?w=600\" width=\"400\"/>\n|-\n| IIO ring buffer / kfifo\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/ringbuffer.png\" width=\"400\"/>\n|-\n|}\n\n== References ==\n\n<references/>','utf-8'),(1966,'\n\n\n== Data structure ==\n\n=== Red-black tree ===\n\nLinux의 lib/radix-tree.c 파일에 구현되어 있음.\n\n\n=== Radix tree ===\n\nLinux의 lib/rbtree.c 파일에 구현되어 있음.\n\n\n\n\n\n== I/O ==\n\n=== Page cache ===\n\n\n\n=== Direct I/O ===\n\n==== Direct I/O 개념 및 사용 목적 ====\n\n* Direct I/O\n: Kernel이 제공하는 page cache를 거치지 않고, 데이터 블럭들이 user-space 메모리와 storage device 간에 직접 이동할 수 있도록 하는 방식임.\n\n* Direct I/O를 수행하는 목적\n: (1) file contents에 대한 caching을 kernel보다 잘 할 수 있는 상황이거나, (2) 가까운 미래에 재사용될 일이 없다고 판단되는 data들이 kernel의 page cache 영역을 불필요하게 채우지 않게 하기 위함. (실제로 RDBMS에서 direct I/O를 많이 이용하고 있으며, Oracle이 좋은 사례임.) <ref>[http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)] &larr;((B.GOOD)) 발췌 내용: The idea behind direct I/O is that data blocks move directly between the storage device and user-space memory without going through the page cache. Developers use direct memory for either (or both) of two reasons: (1) they believe they can manage caching of file contents better than the kernel can, or (2) they want to avoid overflowing the page cache with data which is unlikely to be of use in the near future. It is a relatively little-used feature which is often combined with another obscure kernel capability: asynchronous I/O. The biggest consumers, by far, of this functionality are large relational database systems, so it is not entirely surprising that a developer currently employed by Oracle is working in this area.</ref>\n\n* 참고한 글\n:- [http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)]\n:- [http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP]\n\n==== Direct I/O 내부 메커니즘 ====\n\n일반적으로 file I/O는 address_space_operations 구조체에 의해 point되는 다음 두 function에 의해 처리된다.\n\n include/linux/fs.h:\n int (*writepage)(struct page *page, struct writeback_control *wbc);\n int (*readpage)(struct file *, struct page *);\n\n그러나 direct I/O의 경우에는 위의 두 function이 아니라 별도의 function에 의해 처리된다.\n\n include/linux/fs.h:\n ssize_t (*direct_IO)(int rw, struct kiocb *iocb, const struct iovec *iov, loff_t offset, unsigned long nr_segs);\n\n참고로, fs/block_dev.c에 정의되어 있는 address_space_operations 개체인 def_blk_aops의 경우, function pointer들이 가리키고 있는 다음과 같은 real function을 사용한다.\n\n <pre>\nfs/block_dev.c:\n\nstatic const struct address_space_operations\ndef_blk_aops = {\n        .readpage       = blkdev_readpage,\n        .writepage      = blkdev_writepage,\n        .write_begin    = blkdev_write_begin,\n        .write_end      = blkdev_write_end,\n        .writepages     = generic_writepages,\n        .releasepage    = blkdev_releasepage,\n        .direct_IO      = blkdev_direct_IO,\n        .is_dirty_writeback = buffer_check_dirty_writeback,\n};\n\nstatic int\nblkdev_writepage(struct page *page, struct writeback_control *wbc)\n{\n        return block_write_full_page(page, blkdev_get_block, wbc);\n}\n\nstatic int\nblkdev_readpage(struct file * file, struct page * page)\n{\n        return block_read_full_page(page, blkdev_get_block);\n}\n\n</pre>\n\n==== Direct I/O 사용 시 주의 사항 ====\n\n* Direct IO 수행 시 transfer되는 데이터 크기가 시스템 성능에 미치는 영향\n: Direct IO가 의미 있으려면, 적절한 크기의 데이터를 요청하는 것이 중요. 8KB보다 작은 데이터의 transfer의 경우, 큰 문제가 될 가능성은 작다. 그러나 direct IO를 목적으로 다수의 512KB 블럭 데이터를 \'locking down\'하는 것은 전반적인 시스템 성능에 부정적인 영향을 미칠 수 있으므로 주의해야 한다. \'\'\'&larr; 구체적으로 어떻게?\'\'\' Direct IO request 기간 동안, 데이터 transfer buffer는 고정된 메모리 영역에 mapping되고 locking되기 때문에 swap-out 될 수 없다는 점에 주목할 필요가 있다. 이것이 지나치면 kernel이 동작하는 스타일을 망쳐버릴 수 있다. <ref>[http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP] 발췌내용 - For direct IO to be worthwhile, a reasonable amount of data should be requested for data transfer. For transfers less than 8 KByte it is probably not worth the trouble. On the other hand \"locking down\" a multiple 512 KB blocks of data for direct IO could adversely impact overall system performance. Remember that for the duration of a direct IO request, the data transfer buffer is mapped to a fixed memory location and locked in such a way that it won\'t be swapped out. This can \"cramp the style\" of the kernel if it is overdone.</ref>\n\n==== Direct I/O와 Page Cache와의 관계 ====\n\n\n==== Direct I/O example ====\n\nThis is [http://man7.org/tlpi/code/online/dist/filebuff/direct_read.c.html filebuff/direct_read.c] (Listing 13-1, page 247), an example program file from the book The Linux Programming Interface.\n\nThe source code file is copyright 2010, Michael Kerrisk, and is licensed under the GNU Affero General Public License, version 3.\n\nThis page shows the \"distribution\" or \"book\" version of the file (why are there two versions?), or the differences between the two versions. You can switch between the views using the tabs below.\n\nIn the listing below, the names of Linux system calls and C library functions are hyperlinked to manual pages from the Linux man-pages project, and the names of functions implemented in the book are hyperlinked to the implementations of those functions.\n\n <pre>\n/* direct_read.c\n\n   Demonstrate the use of O_DIRECT to perform I/O bypassing the buffer cache\n   (\"direct I/O\").\n\n   Usage: direct_read file length [offset [alignment]]\n\n   This program is Linux-specific.\n*/\n#define _GNU_SOURCE     /* Obtain O_DIRECT definition from <fcntl.h> */\n#include <fcntl.h>\n#include <malloc.h>\n#include \"tlpi_hdr.h\"\n\nint\nmain(int argc, char *argv[])\n{\n    int fd;\n    ssize_t numRead;\n    size_t length, alignment;\n    off_t offset;\n    char *buf;\n\n    if (argc < 3 || strcmp(argv[1], \"--help\") == 0)\n        usageErr(\"%s file length [offset [alignment]]\\n\", argv[0]);\n\n    length = getLong(argv[2], GN_ANY_BASE, \"length\");\n    offset = (argc > 3) ? getLong(argv[3], GN_ANY_BASE, \"offset\") : 0;\n    alignment = (argc > 4) ? getLong(argv[4], GN_ANY_BASE, \"alignment\") : 4096;\n\n    fd = open(argv[1], O_RDONLY | O_DIRECT);\n    if (fd == -1)\n        errExit(\"open\");\n\n    /* memalign() allocates a block of memory aligned on an address that\n       is a multiple of its first argument. By specifying this argument as\n       2 * \'alignment\' and then adding \'alignment\' to the returned pointer,\n       we ensure that \'buf\' is aligned on a non-power-of-two multiple of\n       \'alignment\'. We do this to ensure that if, for example, we ask\n       for a 256-byte aligned buffer, we don\'t accidentally get\n       a buffer that is also aligned on a 512-byte boundary. */\n\n    buf = memalign(alignment * 2, length + alignment);\n    if (buf == NULL)\n        errExit(\"memalign\");\n\n    buf += alignment;\n\n    if (lseek(fd, offset, SEEK_SET) == -1)\n        errExit(\"lseek\");\n\n    numRead = read(fd, buf, length);\n    if (numRead == -1)\n        errExit(\"read\");\n    printf(\"Read %ld bytes\\n\", (long) numRead);\n\n    exit(EXIT_SUCCESS);\n}\n</pre>\n\n\n\n\n=== IIO (Linux Industrial I/O Subsystem) ===\n\n* IIO (Linux Industrial I/O Subsystem) <ref>https://archive.fosdem.org/2012/schedule/event/693/127_iio-a-new-subsystem.pdf (Maxime Ripard, Free Electrons, 2012-02-14)</ref>\n:- A subsystem for Analog to Digital Converters (ADCs) and related hardwares (accelerometers, light sensors, gyroscopes), but also DACs\n:- Can be used on ADCs ranging from a SoC ADC to 100M samples/sec industrial ADCs\n:- Until recently, mostly focused on user-space abstraction with no in-kernel API for other drivers\n\n{| class=\"wikitable sortable\"\n|+ [http://wiki.analog.com/software/linux/docs/iio/iio Linux Industrial I/O Subsystem]\n|-\n| IIO subsystem overview\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/iio/iio_block_view.png?w=600\" width=\"400\"/>\n|-\n| IIO ring buffer / kfifo\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/ringbuffer.png\" width=\"400\"/>\n|-\n|}\n\n== References ==\n\n<references/>','utf-8'),(1967,'\n\n\n== Data structure ==\n\n=== Red-black tree ===\n\nLinux의 lib/radix-tree.c 파일에 구현되어 있음.\n\n\nhttp://ko.wikipedia.org/wiki/%EB%A0%88%EB%93%9C-%EB%B8%94%EB%9E%99_%ED%8A%B8%EB%A6%AC\n\n\nhttp://kldp.org/node/3175\n\n\nhttp://studyinglw2.tistory.com/entry/Algorithm-2-Search-algorithm-25-Red-Black-Tree-1-1\n\n\nhttp://lovelytien.tistory.com/entry/Red-Black-Tree-%EB%B3%B5%EC%8A%B5\n\n\nhttp://wegra.org/products/search/contents/Tree-based%20Search.pdf\n\nhttp://ryujeen.tistory.com/129\n\n\nhttp://ezbeat.tistory.com/415\n\nhttp://ezbeat.tistory.com/417\n\n=== Radix tree ===\n\nLinux의 lib/rbtree.c 파일에 구현되어 있음.\n\n\n\n\n\n== I/O ==\n\n=== Page cache ===\n\n\n\n=== Direct I/O ===\n\n==== Direct I/O 개념 및 사용 목적 ====\n\n* Direct I/O\n: Kernel이 제공하는 page cache를 거치지 않고, 데이터 블럭들이 user-space 메모리와 storage device 간에 직접 이동할 수 있도록 하는 방식임.\n\n* Direct I/O를 수행하는 목적\n: (1) file contents에 대한 caching을 kernel보다 잘 할 수 있는 상황이거나, (2) 가까운 미래에 재사용될 일이 없다고 판단되는 data들이 kernel의 page cache 영역을 불필요하게 채우지 않게 하기 위함. (실제로 RDBMS에서 direct I/O를 많이 이용하고 있으며, Oracle이 좋은 사례임.) <ref>[http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)] &larr;((B.GOOD)) 발췌 내용: The idea behind direct I/O is that data blocks move directly between the storage device and user-space memory without going through the page cache. Developers use direct memory for either (or both) of two reasons: (1) they believe they can manage caching of file contents better than the kernel can, or (2) they want to avoid overflowing the page cache with data which is unlikely to be of use in the near future. It is a relatively little-used feature which is often combined with another obscure kernel capability: asynchronous I/O. The biggest consumers, by far, of this functionality are large relational database systems, so it is not entirely surprising that a developer currently employed by Oracle is working in this area.</ref>\n\n* 참고한 글\n:- [http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)]\n:- [http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP]\n\n==== Direct I/O 내부 메커니즘 ====\n\n일반적으로 file I/O는 address_space_operations 구조체에 의해 point되는 다음 두 function에 의해 처리된다.\n\n include/linux/fs.h:\n int (*writepage)(struct page *page, struct writeback_control *wbc);\n int (*readpage)(struct file *, struct page *);\n\n그러나 direct I/O의 경우에는 위의 두 function이 아니라 별도의 function에 의해 처리된다.\n\n include/linux/fs.h:\n ssize_t (*direct_IO)(int rw, struct kiocb *iocb, const struct iovec *iov, loff_t offset, unsigned long nr_segs);\n\n참고로, fs/block_dev.c에 정의되어 있는 address_space_operations 개체인 def_blk_aops의 경우, function pointer들이 가리키고 있는 다음과 같은 real function을 사용한다.\n\n <pre>\nfs/block_dev.c:\n\nstatic const struct address_space_operations\ndef_blk_aops = {\n        .readpage       = blkdev_readpage,\n        .writepage      = blkdev_writepage,\n        .write_begin    = blkdev_write_begin,\n        .write_end      = blkdev_write_end,\n        .writepages     = generic_writepages,\n        .releasepage    = blkdev_releasepage,\n        .direct_IO      = blkdev_direct_IO,\n        .is_dirty_writeback = buffer_check_dirty_writeback,\n};\n\nstatic int\nblkdev_writepage(struct page *page, struct writeback_control *wbc)\n{\n        return block_write_full_page(page, blkdev_get_block, wbc);\n}\n\nstatic int\nblkdev_readpage(struct file * file, struct page * page)\n{\n        return block_read_full_page(page, blkdev_get_block);\n}\n\n</pre>\n\n==== Direct I/O 사용 시 주의 사항 ====\n\n* Direct IO 수행 시 transfer되는 데이터 크기가 시스템 성능에 미치는 영향\n: Direct IO가 의미 있으려면, 적절한 크기의 데이터를 요청하는 것이 중요. 8KB보다 작은 데이터의 transfer의 경우, 큰 문제가 될 가능성은 작다. 그러나 direct IO를 목적으로 다수의 512KB 블럭 데이터를 \'locking down\'하는 것은 전반적인 시스템 성능에 부정적인 영향을 미칠 수 있으므로 주의해야 한다. \'\'\'&larr; 구체적으로 어떻게?\'\'\' Direct IO request 기간 동안, 데이터 transfer buffer는 고정된 메모리 영역에 mapping되고 locking되기 때문에 swap-out 될 수 없다는 점에 주목할 필요가 있다. 이것이 지나치면 kernel이 동작하는 스타일을 망쳐버릴 수 있다. <ref>[http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP] 발췌내용 - For direct IO to be worthwhile, a reasonable amount of data should be requested for data transfer. For transfers less than 8 KByte it is probably not worth the trouble. On the other hand \"locking down\" a multiple 512 KB blocks of data for direct IO could adversely impact overall system performance. Remember that for the duration of a direct IO request, the data transfer buffer is mapped to a fixed memory location and locked in such a way that it won\'t be swapped out. This can \"cramp the style\" of the kernel if it is overdone.</ref>\n\n==== Direct I/O와 Page Cache와의 관계 ====\n\n\n==== Direct I/O example ====\n\nThis is [http://man7.org/tlpi/code/online/dist/filebuff/direct_read.c.html filebuff/direct_read.c] (Listing 13-1, page 247), an example program file from the book The Linux Programming Interface.\n\nThe source code file is copyright 2010, Michael Kerrisk, and is licensed under the GNU Affero General Public License, version 3.\n\nThis page shows the \"distribution\" or \"book\" version of the file (why are there two versions?), or the differences between the two versions. You can switch between the views using the tabs below.\n\nIn the listing below, the names of Linux system calls and C library functions are hyperlinked to manual pages from the Linux man-pages project, and the names of functions implemented in the book are hyperlinked to the implementations of those functions.\n\n <pre>\n/* direct_read.c\n\n   Demonstrate the use of O_DIRECT to perform I/O bypassing the buffer cache\n   (\"direct I/O\").\n\n   Usage: direct_read file length [offset [alignment]]\n\n   This program is Linux-specific.\n*/\n#define _GNU_SOURCE     /* Obtain O_DIRECT definition from <fcntl.h> */\n#include <fcntl.h>\n#include <malloc.h>\n#include \"tlpi_hdr.h\"\n\nint\nmain(int argc, char *argv[])\n{\n    int fd;\n    ssize_t numRead;\n    size_t length, alignment;\n    off_t offset;\n    char *buf;\n\n    if (argc < 3 || strcmp(argv[1], \"--help\") == 0)\n        usageErr(\"%s file length [offset [alignment]]\\n\", argv[0]);\n\n    length = getLong(argv[2], GN_ANY_BASE, \"length\");\n    offset = (argc > 3) ? getLong(argv[3], GN_ANY_BASE, \"offset\") : 0;\n    alignment = (argc > 4) ? getLong(argv[4], GN_ANY_BASE, \"alignment\") : 4096;\n\n    fd = open(argv[1], O_RDONLY | O_DIRECT);\n    if (fd == -1)\n        errExit(\"open\");\n\n    /* memalign() allocates a block of memory aligned on an address that\n       is a multiple of its first argument. By specifying this argument as\n       2 * \'alignment\' and then adding \'alignment\' to the returned pointer,\n       we ensure that \'buf\' is aligned on a non-power-of-two multiple of\n       \'alignment\'. We do this to ensure that if, for example, we ask\n       for a 256-byte aligned buffer, we don\'t accidentally get\n       a buffer that is also aligned on a 512-byte boundary. */\n\n    buf = memalign(alignment * 2, length + alignment);\n    if (buf == NULL)\n        errExit(\"memalign\");\n\n    buf += alignment;\n\n    if (lseek(fd, offset, SEEK_SET) == -1)\n        errExit(\"lseek\");\n\n    numRead = read(fd, buf, length);\n    if (numRead == -1)\n        errExit(\"read\");\n    printf(\"Read %ld bytes\\n\", (long) numRead);\n\n    exit(EXIT_SUCCESS);\n}\n</pre>\n\n\n\n\n=== IIO (Linux Industrial I/O Subsystem) ===\n\n* IIO (Linux Industrial I/O Subsystem) <ref>https://archive.fosdem.org/2012/schedule/event/693/127_iio-a-new-subsystem.pdf (Maxime Ripard, Free Electrons, 2012-02-14)</ref>\n:- A subsystem for Analog to Digital Converters (ADCs) and related hardwares (accelerometers, light sensors, gyroscopes), but also DACs\n:- Can be used on ADCs ranging from a SoC ADC to 100M samples/sec industrial ADCs\n:- Until recently, mostly focused on user-space abstraction with no in-kernel API for other drivers\n\n{| class=\"wikitable sortable\"\n|+ [http://wiki.analog.com/software/linux/docs/iio/iio Linux Industrial I/O Subsystem]\n|-\n| IIO subsystem overview\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/iio/iio_block_view.png?w=600\" width=\"400\"/>\n|-\n| IIO ring buffer / kfifo\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/ringbuffer.png\" width=\"400\"/>\n|-\n|}\n\n== References ==\n\n<references/>','utf-8'),(1968,'#REDIRECT [[Operating systems - Linux kernel]]','utf-8'),(1969,'\n\n\n== Data structure ==\n\n=== Red-black tree ===\n\nLinux의 lib/radix-tree.c 파일에 구현되어 있음.\n\n\nhttp://ko.wikipedia.org/wiki/%EB%A0%88%EB%93%9C-%EB%B8%94%EB%9E%99_%ED%8A%B8%EB%A6%AC\n\n\nhttp://kldp.org/node/3175\n\n\nhttp://studyinglw2.tistory.com/entry/Algorithm-2-Search-algorithm-25-Red-Black-Tree-1-1\n\n\nhttp://lovelytien.tistory.com/entry/Red-Black-Tree-%EB%B3%B5%EC%8A%B5\n\n\nhttp://wegra.org/products/search/contents/Tree-based%20Search.pdf\n\nhttp://ryujeen.tistory.com/129\n\n\nhttp://ezbeat.tistory.com/415\n\nhttp://ezbeat.tistory.com/417\n\n=== Radix tree ===\n\nLinux의 lib/rbtree.c 파일에 구현되어 있음.\n\n\n\n\n\n== I/O ==\n\n=== Page cache ===\n\n\n\n=== Direct I/O ===\n\n==== Direct I/O 개념 및 사용 목적 ====\n\n* Direct I/O\n: Kernel이 제공하는 page cache를 거치지 않고, 데이터 블럭들이 user-space 메모리와 storage device 간에 직접 이동할 수 있도록 하는 방식임.\n\n* Direct I/O를 수행하는 목적\n: (1) file contents에 대한 caching을 kernel보다 잘 할 수 있는 상황이거나, (2) 가까운 미래에 재사용될 일이 없다고 판단되는 data들이 kernel의 page cache 영역을 불필요하게 채우지 않게 하기 위함. (실제로 RDBMS에서 direct I/O를 많이 이용하고 있으며, Oracle이 좋은 사례임.) <ref>[http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)] &larr;((B.GOOD)) 발췌 내용: The idea behind direct I/O is that data blocks move directly between the storage device and user-space memory without going through the page cache. Developers use direct memory for either (or both) of two reasons: (1) they believe they can manage caching of file contents better than the kernel can, or (2) they want to avoid overflowing the page cache with data which is unlikely to be of use in the near future. It is a relatively little-used feature which is often combined with another obscure kernel capability: asynchronous I/O. The biggest consumers, by far, of this functionality are large relational database systems, so it is not entirely surprising that a developer currently employed by Oracle is working in this area.</ref>\n\n* 참고한 글\n:- [http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)]\n:- [http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP]\n\n==== Direct I/O 내부 메커니즘 ====\n\n일반적으로 file I/O는 address_space_operations 구조체에 의해 point되는 다음 두 function에 의해 처리된다.\n\n include/linux/fs.h:\n int (*writepage)(struct page *page, struct writeback_control *wbc);\n int (*readpage)(struct file *, struct page *);\n\n그러나 direct I/O의 경우에는 위의 두 function이 아니라 별도의 function에 의해 처리된다.\n\n include/linux/fs.h:\n ssize_t (*direct_IO)(int rw, struct kiocb *iocb, const struct iovec *iov, loff_t offset, unsigned long nr_segs);\n\n참고로, fs/block_dev.c에 정의되어 있는 address_space_operations 개체인 def_blk_aops의 경우, function pointer들이 가리키고 있는 다음과 같은 real function을 사용한다.\n\n <pre>\nfs/block_dev.c:\n\nstatic const struct address_space_operations\ndef_blk_aops = {\n        .readpage       = blkdev_readpage,\n        .writepage      = blkdev_writepage,\n        .write_begin    = blkdev_write_begin,\n        .write_end      = blkdev_write_end,\n        .writepages     = generic_writepages,\n        .releasepage    = blkdev_releasepage,\n        .direct_IO      = blkdev_direct_IO,\n        .is_dirty_writeback = buffer_check_dirty_writeback,\n};\n\nstatic int\nblkdev_writepage(struct page *page, struct writeback_control *wbc)\n{\n        return block_write_full_page(page, blkdev_get_block, wbc);\n}\n\nstatic int\nblkdev_readpage(struct file * file, struct page * page)\n{\n        return block_read_full_page(page, blkdev_get_block);\n}\n\n</pre>\n\n==== Direct I/O 사용 시 주의 사항 ====\n\n* Direct IO 수행 시 transfer되는 데이터 크기가 시스템 성능에 미치는 영향\n: Direct IO가 의미 있으려면, 적절한 크기의 데이터를 요청하는 것이 중요. 8KB보다 작은 데이터의 transfer의 경우, 큰 문제가 될 가능성은 작다. 그러나 direct IO를 목적으로 다수의 512KB 블럭 데이터를 \'locking down\'하는 것은 전반적인 시스템 성능에 부정적인 영향을 미칠 수 있으므로 주의해야 한다. \'\'\'&larr; 구체적으로 어떻게?\'\'\' Direct IO request 기간 동안, 데이터 transfer buffer는 고정된 메모리 영역에 mapping되고 locking되기 때문에 swap-out 될 수 없다는 점에 주목할 필요가 있다. 이것이 지나치면 kernel이 동작하는 스타일을 망쳐버릴 수 있다. <ref>[http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP] 발췌내용 - For direct IO to be worthwhile, a reasonable amount of data should be requested for data transfer. For transfers less than 8 KByte it is probably not worth the trouble. On the other hand \"locking down\" a multiple 512 KB blocks of data for direct IO could adversely impact overall system performance. Remember that for the duration of a direct IO request, the data transfer buffer is mapped to a fixed memory location and locked in such a way that it won\'t be swapped out. This can \"cramp the style\" of the kernel if it is overdone.</ref>\n\n==== Direct I/O와 Page Cache와의 관계 ====\n\n\n==== Direct I/O example ====\n\nThis is [http://man7.org/tlpi/code/online/dist/filebuff/direct_read.c.html filebuff/direct_read.c] (Listing 13-1, page 247), an example program file from the book The Linux Programming Interface.\n\nThe source code file is copyright 2010, Michael Kerrisk, and is licensed under the GNU Affero General Public License, version 3.\n\nThis page shows the \"distribution\" or \"book\" version of the file (why are there two versions?), or the differences between the two versions. You can switch between the views using the tabs below.\n\nIn the listing below, the names of Linux system calls and C library functions are hyperlinked to manual pages from the Linux man-pages project, and the names of functions implemented in the book are hyperlinked to the implementations of those functions.\n\n <pre>\n/* direct_read.c\n\n   Demonstrate the use of O_DIRECT to perform I/O bypassing the buffer cache\n   (\"direct I/O\").\n\n   Usage: direct_read file length [offset [alignment]]\n\n   This program is Linux-specific.\n*/\n#define _GNU_SOURCE     /* Obtain O_DIRECT definition from <fcntl.h> */\n#include <fcntl.h>\n#include <malloc.h>\n#include \"tlpi_hdr.h\"\n\nint\nmain(int argc, char *argv[])\n{\n    int fd;\n    ssize_t numRead;\n    size_t length, alignment;\n    off_t offset;\n    char *buf;\n\n    if (argc < 3 || strcmp(argv[1], \"--help\") == 0)\n        usageErr(\"%s file length [offset [alignment]]\\n\", argv[0]);\n\n    length = getLong(argv[2], GN_ANY_BASE, \"length\");\n    offset = (argc > 3) ? getLong(argv[3], GN_ANY_BASE, \"offset\") : 0;\n    alignment = (argc > 4) ? getLong(argv[4], GN_ANY_BASE, \"alignment\") : 4096;\n\n    fd = open(argv[1], O_RDONLY | O_DIRECT);\n    if (fd == -1)\n        errExit(\"open\");\n\n    /* memalign() allocates a block of memory aligned on an address that\n       is a multiple of its first argument. By specifying this argument as\n       2 * \'alignment\' and then adding \'alignment\' to the returned pointer,\n       we ensure that \'buf\' is aligned on a non-power-of-two multiple of\n       \'alignment\'. We do this to ensure that if, for example, we ask\n       for a 256-byte aligned buffer, we don\'t accidentally get\n       a buffer that is also aligned on a 512-byte boundary. */\n\n    buf = memalign(alignment * 2, length + alignment);\n    if (buf == NULL)\n        errExit(\"memalign\");\n\n    buf += alignment;\n\n    if (lseek(fd, offset, SEEK_SET) == -1)\n        errExit(\"lseek\");\n\n    numRead = read(fd, buf, length);\n    if (numRead == -1)\n        errExit(\"read\");\n    printf(\"Read %ld bytes\\n\", (long) numRead);\n\n    exit(EXIT_SUCCESS);\n}\n</pre>\n\n\n\n\n=== IIO (Linux Industrial I/O Subsystem) ===\n\n* IIO (Linux Industrial I/O Subsystem) <ref>https://archive.fosdem.org/2012/schedule/event/693/127_iio-a-new-subsystem.pdf (Maxime Ripard, Free Electrons, 2012-02-14)</ref>\n:- A subsystem for Analog to Digital Converters (ADCs) and related hardwares (accelerometers, light sensors, gyroscopes), but also DACs\n:- Can be used on ADCs ranging from a SoC ADC to 100M samples/sec industrial ADCs\n:- Until recently, mostly focused on user-space abstraction with no in-kernel API for other drivers\n\n{| class=\"wikitable sortable\"\n|+ [http://wiki.analog.com/software/linux/docs/iio/iio Linux Industrial I/O Subsystem]\n|-\n| IIO subsystem overview\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/iio/iio_block_view.png?w=600\" width=\"400\"/>\n|-\n| IIO ring buffer / kfifo\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/ringbuffer.png\" width=\"400\"/>\n|-\n|}\n\n=== Log structured storage ===\n\n* [http://architects.dzone.com/articles/algorithm-week-log-structured Log structured storage]\n\n== References ==\n\n<references/>','utf-8'),(1970,'\n\n\n== Data structure ==\n\n=== Red-black tree ===\n\nLinux의 lib/radix-tree.c 파일에 구현되어 있음.\n\n\nhttp://ko.wikipedia.org/wiki/%EB%A0%88%EB%93%9C-%EB%B8%94%EB%9E%99_%ED%8A%B8%EB%A6%AC\n\n\nhttp://kldp.org/node/3175\n\n\nhttp://studyinglw2.tistory.com/entry/Algorithm-2-Search-algorithm-25-Red-Black-Tree-1-1\n\n\nhttp://lovelytien.tistory.com/entry/Red-Black-Tree-%EB%B3%B5%EC%8A%B5\n\n\nhttp://wegra.org/products/search/contents/Tree-based%20Search.pdf\n\nhttp://ryujeen.tistory.com/129\n\n\nhttp://ezbeat.tistory.com/415\n\nhttp://ezbeat.tistory.com/417\n\n=== Radix tree ===\n\nLinux의 lib/rbtree.c 파일에 구현되어 있음.\n\n\n\n\n\n== I/O ==\n\n=== Direct I/O ===\n\n==== Direct I/O 개념 및 사용 목적 ====\n\n* Direct I/O\n: Kernel이 제공하는 page cache를 거치지 않고, 데이터 블럭들이 user-space 메모리와 storage device 간에 직접 이동할 수 있도록 하는 방식임.\n\n* Direct I/O를 수행하는 목적\n: (1) file contents에 대한 caching을 kernel보다 잘 할 수 있는 상황이거나, (2) 가까운 미래에 재사용될 일이 없다고 판단되는 data들이 kernel의 page cache 영역을 불필요하게 채우지 않게 하기 위함. (실제로 RDBMS에서 direct I/O를 많이 이용하고 있으며, Oracle이 좋은 사례임.) <ref>[http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)] &larr;((B.GOOD)) 발췌 내용: The idea behind direct I/O is that data blocks move directly between the storage device and user-space memory without going through the page cache. Developers use direct memory for either (or both) of two reasons: (1) they believe they can manage caching of file contents better than the kernel can, or (2) they want to avoid overflowing the page cache with data which is unlikely to be of use in the near future. It is a relatively little-used feature which is often combined with another obscure kernel capability: asynchronous I/O. The biggest consumers, by far, of this functionality are large relational database systems, so it is not entirely surprising that a developer currently employed by Oracle is working in this area.</ref>\n\n* 참고한 글\n:- [http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)]\n:- [http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP]\n\n==== Direct I/O 내부 메커니즘 ====\n\n일반적으로 file I/O는 address_space_operations 구조체에 의해 point되는 다음 두 function에 의해 처리된다.\n\n include/linux/fs.h:\n int (*writepage)(struct page *page, struct writeback_control *wbc);\n int (*readpage)(struct file *, struct page *);\n\n그러나 direct I/O의 경우에는 위의 두 function이 아니라 별도의 function에 의해 처리된다.\n\n include/linux/fs.h:\n ssize_t (*direct_IO)(int rw, struct kiocb *iocb, const struct iovec *iov, loff_t offset, unsigned long nr_segs);\n\n참고로, fs/block_dev.c에 정의되어 있는 address_space_operations 개체인 def_blk_aops의 경우, function pointer들이 가리키고 있는 다음과 같은 real function을 사용한다.\n\n <pre>\nfs/block_dev.c:\n\nstatic const struct address_space_operations\ndef_blk_aops = {\n        .readpage       = blkdev_readpage,\n        .writepage      = blkdev_writepage,\n        .write_begin    = blkdev_write_begin,\n        .write_end      = blkdev_write_end,\n        .writepages     = generic_writepages,\n        .releasepage    = blkdev_releasepage,\n        .direct_IO      = blkdev_direct_IO,\n        .is_dirty_writeback = buffer_check_dirty_writeback,\n};\n\nstatic int\nblkdev_writepage(struct page *page, struct writeback_control *wbc)\n{\n        return block_write_full_page(page, blkdev_get_block, wbc);\n}\n\nstatic int\nblkdev_readpage(struct file * file, struct page * page)\n{\n        return block_read_full_page(page, blkdev_get_block);\n}\n\n</pre>\n\n==== Direct I/O 사용 시 주의 사항 ====\n\n* Direct IO 수행 시 transfer되는 데이터 크기가 시스템 성능에 미치는 영향\n: Direct IO가 의미 있으려면, 적절한 크기의 데이터를 요청하는 것이 중요. 8KB보다 작은 데이터의 transfer의 경우, 큰 문제가 될 가능성은 작다. 그러나 direct IO를 목적으로 다수의 512KB 블럭 데이터를 \'locking down\'하는 것은 전반적인 시스템 성능에 부정적인 영향을 미칠 수 있으므로 주의해야 한다. \'\'\'&larr; 구체적으로 어떻게?\'\'\' Direct IO request 기간 동안, 데이터 transfer buffer는 고정된 메모리 영역에 mapping되고 locking되기 때문에 swap-out 될 수 없다는 점에 주목할 필요가 있다. 이것이 지나치면 kernel이 동작하는 스타일을 망쳐버릴 수 있다. <ref>[http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP] 발췌내용 - For direct IO to be worthwhile, a reasonable amount of data should be requested for data transfer. For transfers less than 8 KByte it is probably not worth the trouble. On the other hand \"locking down\" a multiple 512 KB blocks of data for direct IO could adversely impact overall system performance. Remember that for the duration of a direct IO request, the data transfer buffer is mapped to a fixed memory location and locked in such a way that it won\'t be swapped out. This can \"cramp the style\" of the kernel if it is overdone.</ref>\n\n==== Direct I/O와 Page Cache와의 관계 ====\n\n\n==== Direct I/O example ====\n\nThis is [http://man7.org/tlpi/code/online/dist/filebuff/direct_read.c.html filebuff/direct_read.c] (Listing 13-1, page 247), an example program file from the book The Linux Programming Interface.\n\nThe source code file is copyright 2010, Michael Kerrisk, and is licensed under the GNU Affero General Public License, version 3.\n\nThis page shows the \"distribution\" or \"book\" version of the file (why are there two versions?), or the differences between the two versions. You can switch between the views using the tabs below.\n\nIn the listing below, the names of Linux system calls and C library functions are hyperlinked to manual pages from the Linux man-pages project, and the names of functions implemented in the book are hyperlinked to the implementations of those functions.\n\n <pre>\n/* direct_read.c\n\n   Demonstrate the use of O_DIRECT to perform I/O bypassing the buffer cache\n   (\"direct I/O\").\n\n   Usage: direct_read file length [offset [alignment]]\n\n   This program is Linux-specific.\n*/\n#define _GNU_SOURCE     /* Obtain O_DIRECT definition from <fcntl.h> */\n#include <fcntl.h>\n#include <malloc.h>\n#include \"tlpi_hdr.h\"\n\nint\nmain(int argc, char *argv[])\n{\n    int fd;\n    ssize_t numRead;\n    size_t length, alignment;\n    off_t offset;\n    char *buf;\n\n    if (argc < 3 || strcmp(argv[1], \"--help\") == 0)\n        usageErr(\"%s file length [offset [alignment]]\\n\", argv[0]);\n\n    length = getLong(argv[2], GN_ANY_BASE, \"length\");\n    offset = (argc > 3) ? getLong(argv[3], GN_ANY_BASE, \"offset\") : 0;\n    alignment = (argc > 4) ? getLong(argv[4], GN_ANY_BASE, \"alignment\") : 4096;\n\n    fd = open(argv[1], O_RDONLY | O_DIRECT);\n    if (fd == -1)\n        errExit(\"open\");\n\n    /* memalign() allocates a block of memory aligned on an address that\n       is a multiple of its first argument. By specifying this argument as\n       2 * \'alignment\' and then adding \'alignment\' to the returned pointer,\n       we ensure that \'buf\' is aligned on a non-power-of-two multiple of\n       \'alignment\'. We do this to ensure that if, for example, we ask\n       for a 256-byte aligned buffer, we don\'t accidentally get\n       a buffer that is also aligned on a 512-byte boundary. */\n\n    buf = memalign(alignment * 2, length + alignment);\n    if (buf == NULL)\n        errExit(\"memalign\");\n\n    buf += alignment;\n\n    if (lseek(fd, offset, SEEK_SET) == -1)\n        errExit(\"lseek\");\n\n    numRead = read(fd, buf, length);\n    if (numRead == -1)\n        errExit(\"read\");\n    printf(\"Read %ld bytes\\n\", (long) numRead);\n\n    exit(EXIT_SUCCESS);\n}\n</pre>\n\n\n\n\n=== IIO (Linux Industrial I/O Subsystem) ===\n\n* IIO (Linux Industrial I/O Subsystem) <ref>https://archive.fosdem.org/2012/schedule/event/693/127_iio-a-new-subsystem.pdf (Maxime Ripard, Free Electrons, 2012-02-14)</ref>\n:- A subsystem for Analog to Digital Converters (ADCs) and related hardwares (accelerometers, light sensors, gyroscopes), but also DACs\n:- Can be used on ADCs ranging from a SoC ADC to 100M samples/sec industrial ADCs\n:- Until recently, mostly focused on user-space abstraction with no in-kernel API for other drivers\n\n{| class=\"wikitable sortable\"\n|+ [http://wiki.analog.com/software/linux/docs/iio/iio Linux Industrial I/O Subsystem]\n|-\n| IIO subsystem overview\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/iio/iio_block_view.png?w=600\" width=\"400\"/>\n|-\n| IIO ring buffer / kfifo\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/ringbuffer.png\" width=\"400\"/>\n|-\n|}\n\n=== Log structured storage ===\n\n* [http://architects.dzone.com/articles/algorithm-week-log-structured Log structured storage]\n\n== References ==\n\n<references/>','utf-8'),(1971,'\n\n\n== Data structure ==\n\n=== Red-black tree ===\n\nLinux의 lib/radix-tree.c 파일에 구현되어 있음.\n\n\nhttp://ko.wikipedia.org/wiki/%EB%A0%88%EB%93%9C-%EB%B8%94%EB%9E%99_%ED%8A%B8%EB%A6%AC\n\n\nhttp://kldp.org/node/3175\n\n\nhttp://studyinglw2.tistory.com/entry/Algorithm-2-Search-algorithm-25-Red-Black-Tree-1-1\n\n\nhttp://lovelytien.tistory.com/entry/Red-Black-Tree-%EB%B3%B5%EC%8A%B5\n\n\nhttp://wegra.org/products/search/contents/Tree-based%20Search.pdf\n\nhttp://ryujeen.tistory.com/129\n\n\nhttp://ezbeat.tistory.com/415\n\nhttp://ezbeat.tistory.com/417\n\n=== Radix tree ===\n\nLinux의 lib/rbtree.c 파일에 구현되어 있음.\n\n\n\n\n\n== I/O ==\n\n=== Direct I/O ===\n\n==== Direct I/O 개념 및 사용 목적 ====\n\n* Direct I/O\n: Kernel이 제공하는 page cache를 거치지 않고, 데이터 블럭들이 user-space 메모리와 storage device 간에 직접 이동할 수 있도록 하는 방식임.\n\n* Direct I/O를 수행하는 목적\n: (1) file contents에 대한 caching을 kernel보다 잘 할 수 있는 상황이거나, (2) 가까운 미래에 재사용될 일이 없다고 판단되는 data들이 kernel의 page cache 영역을 불필요하게 채우지 않게 하기 위함. (실제로 RDBMS에서 direct I/O를 많이 이용하고 있으며, Oracle이 좋은 사례임.) <ref>[http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)] &larr;((B.GOOD)) 발췌 내용: The idea behind direct I/O is that data blocks move directly between the storage device and user-space memory without going through the page cache. Developers use direct memory for either (or both) of two reasons: (1) they believe they can manage caching of file contents better than the kernel can, or (2) they want to avoid overflowing the page cache with data which is unlikely to be of use in the near future. It is a relatively little-used feature which is often combined with another obscure kernel capability: asynchronous I/O. The biggest consumers, by far, of this functionality are large relational database systems, so it is not entirely surprising that a developer currently employed by Oracle is working in this area.</ref>\n\n* 참고한 글\n:- [http://lwn.net/Articles/348719/ Page-based direct I/O (Jonathan Corbet, LWN.net, 2009-08-25)]\n:- [http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP]\n\n==== Direct I/O 내부 메커니즘 ====\n\n일반적으로 file I/O는 address_space_operations 구조체에 의해 point되는 다음 두 function에 의해 처리된다.\n\n include/linux/fs.h:\n int (*writepage)(struct page *page, struct writeback_control *wbc);\n int (*readpage)(struct file *, struct page *);\n\n그러나 direct I/O의 경우에는 위의 두 function이 아니라 별도의 function에 의해 처리된다.\n\n include/linux/fs.h:\n ssize_t (*direct_IO)(int rw, struct kiocb *iocb, const struct iovec *iov, loff_t offset, unsigned long nr_segs);\n\n참고로, fs/block_dev.c에 정의되어 있는 address_space_operations 개체인 def_blk_aops의 경우, function pointer들이 가리키고 있는 다음과 같은 real function을 사용한다.\n\n <pre>\nfs/block_dev.c:\n\nstatic const struct address_space_operations\ndef_blk_aops = {\n        .readpage       = blkdev_readpage,\n        .writepage      = blkdev_writepage,\n        .write_begin    = blkdev_write_begin,\n        .write_end      = blkdev_write_end,\n        .writepages     = generic_writepages,\n        .releasepage    = blkdev_releasepage,\n        .direct_IO      = blkdev_direct_IO,\n        .is_dirty_writeback = buffer_check_dirty_writeback,\n};\n\nstatic int\nblkdev_writepage(struct page *page, struct writeback_control *wbc)\n{\n        return block_write_full_page(page, blkdev_get_block, wbc);\n}\n\nstatic int\nblkdev_readpage(struct file * file, struct page * page)\n{\n        return block_read_full_page(page, blkdev_get_block);\n}\n\n</pre>\n\n==== Direct I/O 사용 시 주의 사항 ====\n\n* Direct IO 수행 시 transfer되는 데이터 크기가 시스템 성능에 미치는 영향\n: Direct IO가 의미 있으려면, 적절한 크기의 데이터를 요청하는 것이 중요. 8KB보다 작은 데이터의 transfer의 경우, 큰 문제가 될 가능성은 작다. 그러나 direct IO를 목적으로 다수의 512KB 블럭 데이터를 \'locking down\'하는 것은 전반적인 시스템 성능에 부정적인 영향을 미칠 수 있으므로 주의해야 한다. \'\'\'&larr; 구체적으로 어떻게?\'\'\' Direct IO request 기간 동안, 데이터 transfer buffer는 고정된 메모리 영역에 mapping되고 locking되기 때문에 swap-out 될 수 없다는 점에 주목할 필요가 있다. 이것이 지나치면 kernel이 동작하는 스타일을 망쳐버릴 수 있다. <ref>[http://www.tldp.org/HOWTO/SCSI-Generic-HOWTO/dio.html Chapter 9. Direct and Mmap-ed IO - The Linux SCSI Generic (sg) HOWTO - TLDP] 발췌내용 - For direct IO to be worthwhile, a reasonable amount of data should be requested for data transfer. For transfers less than 8 KByte it is probably not worth the trouble. On the other hand \"locking down\" a multiple 512 KB blocks of data for direct IO could adversely impact overall system performance. Remember that for the duration of a direct IO request, the data transfer buffer is mapped to a fixed memory location and locked in such a way that it won\'t be swapped out. This can \"cramp the style\" of the kernel if it is overdone.</ref>\n\n==== Direct I/O와 Page Cache와의 관계 ====\n\n\n==== Direct I/O example ====\n\nThis is [http://man7.org/tlpi/code/online/dist/filebuff/direct_read.c.html filebuff/direct_read.c] (Listing 13-1, page 247), an example program file from the book The Linux Programming Interface.\n\nThe source code file is copyright 2010, Michael Kerrisk, and is licensed under the GNU Affero General Public License, version 3.\n\nThis page shows the \"distribution\" or \"book\" version of the file (why are there two versions?), or the differences between the two versions. You can switch between the views using the tabs below.\n\nIn the listing below, the names of Linux system calls and C library functions are hyperlinked to manual pages from the Linux man-pages project, and the names of functions implemented in the book are hyperlinked to the implementations of those functions.\n\n <pre>\n/* direct_read.c\n\n   Demonstrate the use of O_DIRECT to perform I/O bypassing the buffer cache\n   (\"direct I/O\").\n\n   Usage: direct_read file length [offset [alignment]]\n\n   This program is Linux-specific.\n*/\n#define _GNU_SOURCE     /* Obtain O_DIRECT definition from <fcntl.h> */\n#include <fcntl.h>\n#include <malloc.h>\n#include \"tlpi_hdr.h\"\n\nint\nmain(int argc, char *argv[])\n{\n    int fd;\n    ssize_t numRead;\n    size_t length, alignment;\n    off_t offset;\n    char *buf;\n\n    if (argc < 3 || strcmp(argv[1], \"--help\") == 0)\n        usageErr(\"%s file length [offset [alignment]]\\n\", argv[0]);\n\n    length = getLong(argv[2], GN_ANY_BASE, \"length\");\n    offset = (argc > 3) ? getLong(argv[3], GN_ANY_BASE, \"offset\") : 0;\n    alignment = (argc > 4) ? getLong(argv[4], GN_ANY_BASE, \"alignment\") : 4096;\n\n    fd = open(argv[1], O_RDONLY | O_DIRECT);\n    if (fd == -1)\n        errExit(\"open\");\n\n    /* memalign() allocates a block of memory aligned on an address that\n       is a multiple of its first argument. By specifying this argument as\n       2 * \'alignment\' and then adding \'alignment\' to the returned pointer,\n       we ensure that \'buf\' is aligned on a non-power-of-two multiple of\n       \'alignment\'. We do this to ensure that if, for example, we ask\n       for a 256-byte aligned buffer, we don\'t accidentally get\n       a buffer that is also aligned on a 512-byte boundary. */\n\n    buf = memalign(alignment * 2, length + alignment);\n    if (buf == NULL)\n        errExit(\"memalign\");\n\n    buf += alignment;\n\n    if (lseek(fd, offset, SEEK_SET) == -1)\n        errExit(\"lseek\");\n\n    numRead = read(fd, buf, length);\n    if (numRead == -1)\n        errExit(\"read\");\n    printf(\"Read %ld bytes\\n\", (long) numRead);\n\n    exit(EXIT_SUCCESS);\n}\n</pre>\n\n\n\n\n=== IIO (Linux Industrial I/O Subsystem) ===\n\n* IIO (Linux Industrial I/O Subsystem) <ref>https://archive.fosdem.org/2012/schedule/event/693/127_iio-a-new-subsystem.pdf (Maxime Ripard, Free Electrons, 2012-02-14)</ref>\n:- A subsystem for Analog to Digital Converters (ADCs) and related hardwares (accelerometers, light sensors, gyroscopes), but also DACs\n:- Can be used on ADCs ranging from a SoC ADC to 100M samples/sec industrial ADCs\n:- Until recently, mostly focused on user-space abstraction with no in-kernel API for other drivers\n\n{| class=\"wikitable sortable\"\n|+ [http://wiki.analog.com/software/linux/docs/iio/iio Linux Industrial I/O Subsystem]\n|-\n| IIO subsystem overview\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/iio/iio_block_view.png?w=600\" width=\"400\"/>\n|-\n| IIO ring buffer / kfifo\n| <img src=\"http://wiki.analog.com/_media/software/linux/docs/ringbuffer.png\" width=\"400\"/>\n|-\n|}\n\n=== Log structured storage ===\n\n* [http://architects.dzone.com/articles/algorithm-week-log-structured Log structured storage]\n\n=== Page cache ===\n\n== References ==\n\n<references/>','utf-8'),(1972,'\n\n* http://www.flashmemorysummit.com/English/Collaterals/Proceedings/2013/20130812_PreConfD_Marks.pdf\n\n* http://www.flashmemorysummit.com/English/Conference/Proceedings_Chrono.html','utf-8'),(1973,'\n\n== ## bNote-2013-09-25 ==\n\n=== Task plan ===\n\n* Linux kernel investigating (analyzing/debugging/profiling) practice\n:- Ftrace, printk, ... in detail\n:- Kernel 내 특정 함수를 Ftraceable하게 만들고 싶다면 어떻게?\n:- Kernel 내 특정 operation chain에 대한 performance profiling을 하고 싶다면?\n\n* Caching/Tiering module\n: Get experienced on manipulation\n: Analyze the kernel function flow\n\n* Analysis of various caching algorithms\n: Build a comparison table\n: MQ, ARC, LRU, LFU, 2Q, ...\n\n* Revisit block I/O flow\n: Analyze kernel function flow\n\n<strike>\n* 이사 어떻게 해야 하는지 확인\n* 재직증명서 관련 문의\n* 아버지 함자 보내드리기\n</strike>\n\n== ## bNote-2013-09-24 ==\n\n=== Task plan ===\n\n* Linux kernel investigating (analyzing/debugging/profiling) practice\n:- Ftrace, printk, ... in detail\n:- Kernel 내 특정 함수를 Ftraceable하게 만들고 싶다면 어떻게?\n:- Kernel 내 특정 operation chain에 대한 performance profiling을 하고 싶다면?\n\n* Caching/Tiering module\n: Get experienced on manipulation\n: Analyze the kernel function flow\n\n* Analysis of various caching algorithms\n: Build a comparison table\n: MQ, ARC, LRU, LFU, 2Q, ...\n\n* Revisit block I/O flow\n: Analyze kernel function flow\n\n=== Linux의 Direct I/O 동작 메커니즘, Page Cache와의 관계, 그리고 Radix Tree 모듈 분석 ===\n\n* [[Operating systems - Linux kernel]]\n\n== ## bNote-2013-09-23 ==\n\n=== News from JPLee ===\n\n* 심은수상무님과 정재헌상무님 석식 (9/23)\n:- 서로의 감정 움직임 이해 필요 (인지상정)\n:- 메모리사에서 필요하다고 느끼는 일들을 찾아서 할 것 (기술원 옷을 벗고 메모리사 옷을 입어라)\n:- 직급 서열이 매우 확고하게 서있음\n:- 경력사항 정성껏 잘, 눈에 쏙 들어오도록 기재할 것\n\n== ## bNote-2013-09-22 ==\n\n* [[Industry intelligence - storage]]\n\n* [[Industry intelligence - big data]]\n\n* [[Academia intelligence]]\n\n== ## bNote-2013-09-13 ==\n\n=== Flash Memory Summit 2013 ===\n* [[Industry Intelligence - Flash Memory Summit 2013]]\n\n== ## bNote-2013-09-12 ==\n\n* [[Industry intelligence - storage]]\n\n== ## bNote-2013-09-11 ==\n\n* http://admission.snu.ac.kr/graduate\n: 지원서 접수 마감: 2013-10-18 18:00 \n: TOEFL (CBT / IBT / PBT : 227 / 86 / 567)\n\n* [[Workload analysis-driven system architecture design]]\n* [[Brian Myungjune JUNG]]\n\n== ## bNote-2013-09-10 ==\n\n=== Preparing Talk 2013-09-11 ===\n\n* SHOULD get focused!!!\n: separate topics to be discussed from topics to hide (no need to mention)\n\n* Research goal\n: Devise distinguished approaches which leads to the fundamental change in the\ndistributed computing paradigm\n\n* History and future direction based on the map of \'time/area axes\'\n:- to show the direction and motivation\n:- to reveal all the topics connected organically\n:- to reveal the real capability (programming, patents, papers, ...)\n\n* Capability: programming\n:- R, Python, and shell for analysis (esp. list familiar R packages)\n::- R statistical computing framework (frequent itemset mining, association rules mining, HMM, neuralnet)\n:- C and Assembly reading for kernel development\n::- Fusion IO VSL (virtualized storage layer) analysis\n\n* Capability: standardization experience\n:- LiMo Security TF: SPEF (Security policy enforcement framework) with Motorola\n:- Good technical communication\n\n* Patents portfolio\n:- List up all the patents to reveal the technical experience\n:- Strategic patents\n\n* Paper portfolio\n:- List up all the papers to reveal the technical experience\n\n* Study plan - Virtualization, Hadoop, ARM, Workload Analysis\n: Green computing\n: Profiling\n: Bottleneck analysis\n\n\n=== Note ===\n\n----\n\n* VDI VM data backup\n\n* VDI VM access (F:)\n: \\\\75.1.240.249\\SAIT$\\brian.m.jung\n:: Microsoft Windows Network\n\n* VDI VM access (R:)\n: \\\\75.1.240.244\\sharesait72$\n:: Microsoft Windows Network\n\n <pre>\n\n# Architect // 3.27 GB\n# atlas // 13.9 GB\n# FutureOS // 6.35 GB\n~ gto // 7.11 GB\n~ Multicore // 7.27 GB\nosv // 64.9 GB\nosv/__SW_Mobility // 29.4 GB\nosv_sds // 16.0 GB\nse기획_ok // 24.8 GB\nStorage // \n~ swgto // 3.60 GB\n~ sw역량강화 // 2.27 GB\n~ 인적역량wg // 0.0503 GB\n\n</pre>\n\n* VDI VM access (--)\n: \\\\168.219.177.80\\종기원\n:: Microsoft Windows Network\n\n\n----\n\n연락처, 전화번호\n구본철 010-9190-5907 01091905907\n신현정 017-324-9294 0173249294\n\n----\n\n== ## bNote-2013-09-09 ==\n\n=== Micro server ===\n\n* http://armservers.com/2012/11/16/whats-a-little-core-like-arm-doing-in-a-place-like-this/#more-452\n\n* SeaMicro Vs. Calxeda Vs. Samsung\n* Barcelona Supercomputing Center - Samsung (Dual core A15 with Mali GPUs)\n\n* Calxeda\n: Calxeda\'s massive fabric and performance roadmap?\n\n=== SuperComputing \'12 ===\n\n* IEEE SuperComputing \'12 Salt Lake City\n: 과거에는 (Tera)Flops, Fortran이 hot topic들이었다면,\n: 요즘은 Big Data, HW acceleration, interconnect fabrics, storage , green\ncomputing 등이 hot topic들임.\n\n\n=== Letter ===\n\n장수석님. 2013-09-09\n\n<!--\n\n{ // 2013-09-09\n\n장수석님, 안녕하세요?\n\n기술원의 정명준 전문입니다.\n\n \n\n지난 주 목요일, 부회장님 말씀으로\n\n저희 팀 5명이 메모리사업부 SW개발팀으로 전격 배치되어,\n\nDS SW 연구소로 가지 못할 것 같습니다.\n\n \n\n이미 아시리라 생각합니다만,\n\n그래도 직접 말씀 드리고\n\n죄송하다는 인사를 드려야 할 것 같아서\n\n메일 드렸습니다.\n\n \n\n이번 배치로, 사업부 개발팀에서의 경험을 통해\n\n실제 제품의 메커니즘 및 현장의 생리를 이해하고 겪어볼 수 있을 것 같습니다.\n\n다만, 기술원에서 하던 연구를 더욱 심화할 수 있었던 좋은 기회를\n\nOfficial하게 살리지 못하게 된 것은 무척 아쉽습니다.\n\n(이와 관련해서는, 어떻게든 시간과 기회를 만들어서 연구를 계속 할 생각입니다.)\n\n \n\n바쁘신 중에 연락도 주시고 많이 챙겨주셨는데\n\n부응하지 못하게 되어 정말 죄송하고, 안타깝습니다.\n\n \n\n김전무님, 장수석님과 함께\n\n다시 연구할 수 있는 좋은 기회가 있기를 간절히 바라면서\n\n이만 인사 드리겠습니다.\n\n \n\n항상 즐겁고 건강하세요.\n\n정명준 드림. ^___^\n\n}\n\n-->\n\n== ## bNote-2013-09-05 ==\n\n* 목요일 있었던 권부회장님께 보고 회의에서, 권부회장님에 의해서 메모리사업부 개발팀으로 전격 변경됨\n\n* 기술원에서의 마지막 GWP 행사 (강남역 근처 와인나라 아카데미에서 와인강좌 수강, SevenSprings 강남점에서 저녁 회식)\n\n== ## bNote-2013-09-04 ==\n\n=== Large-scale machine learning framework ===\n\n: Large-scale의 분산 ML 프레임워크 조사 관련, Mahout과 Impala 내용 Quick 하게 보내드립니다.\n: 참고로, Impala가 Cloudera에 의해 만들어진 것은 맞습니다만, ML 관련된 Framework은 아닙니다. 이 점 정정합니다. (혼란을 드려 죄송합니다)\n\n==== Mahout ====\n\n: http://mahout.apache.org/\n: Apache Hadoop 기반의 Machine Learning Framework. (MapReduce 이용)\n: \'13년 7월 25일 현재 0.8 버전 릴리즈\n: Clustering, Classification, Mining 기능 제공 (K-Means, Neural Network, SVM, Naive Bayes classification, Frequent itemset mining, HMM 등 포함) <ref>https://cwiki.apache.org/confluence/display/MAHOUT/Algorithms</ref>\n:: -> Neural Network 관련, one hidden layer에 대한 back propagation 기능을 구현 중인 듯 함 (Code 상에서 확인 필요)\n\n==== Impala ====\n\n: http://www.cloudera.com/content/cloudera/en/products/cdh/impala.html\n: Apache Hadoop 상에서 구동되는 Real-time Query 엔진으로서, scalable parallel DB 기술으로 볼 수 있음. (Machine Learning과 무관)\n: Apache HBase 및 HDFS에 저장된 데이터에 대한 low-latency SQL query 기술임\n: Hadoop 스케일의 interactive한 large-scale data processing 을 가능케 함\n\n==== Multicore에서의 ML을 위한 Map-Reduce 연구 (by Stanford, NIPS \'06) ====\n\n: http://www.cs.stanford.edu/people/ang/papers/nips06-mapreducemulticore.pdf\n: K-means, SVM, Naive Bayes 등 뿐만 아니라 특히 2개의 output neuron을 갖는 3-layer NN에 대한 Back propagation에 대해서 위의 구조를 적용. (Mahout에서도 이 연구를 참고하는 것으로 보임)\n\n== ## bNote-2013-09-03 ==\n\n=== Research planning ===\n\n==== Ecosystem analysis ====\n\n* Ecosystem decomposition\n:* Device manufacturer/designer\n::- Samsung, Intel, NVIDIA, ARM, Calxeda, SeaMicro, ...\n:* Consumer product manufacturer\n::- Apple, Samsung, Sony, Huawei, ...\n:* Enterprise product manufacturer\n::- EMC, NetApp, Oracle (Appliance), IBM, HP, Dell, Cisco, ... \n:* Service provider\n::- Google (Web-based all), Amazon (eCommerce), Facebook, Twitter, ...\n:* Content provider\n::- Google (YouTube), Disney, Pixar, Sony, ...\n:* Software company\n::- Google (Android), Oracle (DB), Microsoft, Canonical, Red Hat, Cloudera, Citrix, ... \n:* Cloud company <ref>The Top 20 Infrastructure as a Service (IaaS) Vendors http://www.clouds360.com/iaas.php</ref> <ref>Research: 2012 State of Cloud Computing - InformationWeek http://reports.informationweek.com/abstract/5/8658/Cloud-Computing/research-2012-state-of-cloud-computing.html</ref> <ref>Research: Cloud Software: Where Next? http://reports.informationweek.com/abstract/7/11215/Enterprise-Software/Research:-Cloud-Software:-Where-Next?.html</ref> <ref>Research: Cloud Security and Risk Survey http://reports.informationweek.com/abstract/5/11335/Cloud-Computing/Research:-Cloud-Security-and-Risk-Survey.html</ref>\n::- Amazon (AWS), Google (Gmail, Drive), AT&T, Verizon (Terremark), Rackspace, Savvis, GoGrid, Datapipe, ...\n\n\n=== Open innovation benchmark ===\n\n* Leading companies in open innovation\n: Intel (Open Source on Intel)\n\n\n==== Intel case: Open Source on Intel ====\n\n* [http://software.intel.com/en-us/oss Open Source on Intel]\n* [http://software.intel.com/sites/campaigns/sparks/ Igniting Sparks of Innovation]\n\n\n==== Research reports ====\n\n* [How Attackers Target and Exploit Social Networking Users - InformationWeek http://reports.informationweek.com/abstract/21/11235/Security/How-Attackers-Target-and-Exploit-Social-Networking-Users.html]\n\n* [Here Comes the Internet of Things - InformationWeek http://reports.informationweek.com/abstract/83/11058/IT-Business-Strategy/Here-Comes-the-Internet-of-Things.html]\n\n* [Research: 2014 Federal Government IT Priorities - InformationWeek http://reports.informationweek.com/abstract/104/11175/Government/Research:-2014-Federal-Government-IT-Priorities.html]\n\n* [The Top 20 Infrastructure as a Service (IaaS) Vendors http://www.clouds360.com/iaas.php]\n\n* [Research: 2012 State of Cloud Computing - InformationWeek http://reports.informationweek.com/abstract/5/8658/Cloud-Computing/research-2012-state-of-cloud-computing.html]\n\n* [Research: Cloud Software: Where Next?  - InformationWeek http://reports.informationweek.com/abstract/7/11215/Enterprise-Software/Research:-Cloud-Software:-Where-Next?.html]\n\n* [Research: Cloud Security and Risk Survey  - InformationWeek http://reports.informationweek.com/abstract/5/11335/Cloud-Computing/Research:-Cloud-Security-and-Risk-Survey.html]\n\n== References ==\n\n<references/>','utf-8');
/*!40000 ALTER TABLE `radiohead_text` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `radiohead_transcache`
--

DROP TABLE IF EXISTS `radiohead_transcache`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
