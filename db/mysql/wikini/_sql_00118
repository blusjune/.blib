INSERT INTO `mw_text` VALUES (1920,'== ## bNote-2013-04-26 ==\n\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 msec // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 msec // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5\n:- Seek Average, Write (ms): <9.5\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1921,'== ## bNote-2013-04-26 ==\n\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 msec // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 msec // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1922,'== ## bNote-2013-04-26 ==\n\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~100 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~100 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1923,'== ## bNote-2013-04-26 ==\n\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1924,'== ## bNote-2013-04-26 ==\n\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\n \n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n \n\n \n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI SDN]\n\n\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1925,'== ## bNote-2013-04-26 ==\n\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI SDN]\n\n\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1926,'== ## bNote-2013-04-26 ==\n\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1927,'== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1928,'== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1929,'== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n\n\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1930,'== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8');
INSERT INTO `mw_text` VALUES (1931,'== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1932,'== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\nblusjune@radiohead:[hdd_test] $ l\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1933,'== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1934,'== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1935,'== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1936,'== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n <pre>\n$ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1 \n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:31:38 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     41462       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 9.64722\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 96.4722\nblusjune__iops                   : 10365\nblusjune__throughput (bytes/sec) : 42457810\n==================================================\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1937,'== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n <pre>\n$ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1 \n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:31:38 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     41462       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 9.64722\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 96.4722\nblusjune__iops                   : 10365\nblusjune__throughput (bytes/sec) : 42457810\n==================================================\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1938,'== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n <pre>\n$ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1 \n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:31:38 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     41462       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 9.64722\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 96.4722\nblusjune__iops                   : 10365\nblusjune__throughput (bytes/sec) : 42457810\n==================================================\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdd)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n <pre>\n $ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:25:26 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2123       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 188.403\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1884.03\nblusjune__iops                   : 530\nblusjune__throughput (bytes/sec) : 2174068\n==================================================\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1939,'== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n <pre>\n$ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1 \n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:31:38 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     41462       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 9.64722\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 96.4722\nblusjune__iops                   : 10365\nblusjune__throughput (bytes/sec) : 42457810\n==================================================\n</pre>\n\n\n\n\n* Performance Benchmark (Random Write, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:35:44 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                         0  960635                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-write)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 0.416391\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 4.16391\nblusjune__iops                   : 240158\nblusjune__throughput (bytes/sec) : 983690602\n==================================================\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdd)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n <pre>\n $ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:25:26 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2123       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 188.403\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1884.03\nblusjune__iops                   : 530\nblusjune__throughput (bytes/sec) : 2174068\n==================================================\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8');
INSERT INTO `mw_text` VALUES (1940,'== ## bNote-2013-05-02 ==\n\n=== R (r_stat) 3D plot ===\n\n* [http://www.statmethods.net/graphs/scatterplot.html Simple Scatterplot // Quick-R]\n* [http://www.r-bloggers.com/turning-your-data-into-a-3d-chart/ Turning your data into a 3d chart // R-bloggers]\n* [http://www.ejwagenmakers.com/misc/Plotting_3d_in_R.pdf R graph gallery // Compilation by Eric Lecoutre // 2003-12-12]\n\n\n\n\n== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n <pre>\n$ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1 \n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:31:38 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     41462       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 9.64722\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 96.4722\nblusjune__iops                   : 10365\nblusjune__throughput (bytes/sec) : 42457810\n==================================================\n</pre>\n\n\n\n\n* Performance Benchmark (Random Write, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:35:44 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                         0  960635                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-write)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 0.416391\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 4.16391\nblusjune__iops                   : 240158\nblusjune__throughput (bytes/sec) : 983690602\n==================================================\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdd)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n <pre>\n $ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:25:26 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2123       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 188.403\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1884.03\nblusjune__iops                   : 530\nblusjune__throughput (bytes/sec) : 2174068\n==================================================\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1941,'== ## bNote-2013-05-02 ==\n\n=== R (r_stat) 3D plot ===\n\n* [http://www.statmethods.net/graphs/scatterplot.html Simple Scatterplot // Quick-R]\n* [http://www.r-bloggers.com/turning-your-data-into-a-3d-chart/ Turning your data into a 3d chart // R-bloggers]\n* [http://www.ejwagenmakers.com/misc/Plotting_3d_in_R.pdf R graph gallery // Compilation by Eric Lecoutre // 2003-12-12]\n\n\n\n\n== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n* [http://www.computerweekly.com/news/2240179705/ID7-buy-takes-Fusion-io-deeper-into-software-defined-storage ID7 buy takes Fusion-IO deeper into software-defined storage]\n\n* [http://searchstorage.techtarget.com/opinion/Software-defined-storage-Is-hardware-obsolete Software-defined Storage: Is Hardware Obsolete? // SearchStorage.techtarget.com]\n\n* [http://www.storagereview.com/fusionio_acquires_id7_developers_of_scst Fusion-IO Acquires ID7, Developers of SCST (SCSI Target Subsystem)]\n\n* [http://www.theregister.co.uk/2013/04/09/blind_spot/ Mutant Array Upstarts Feast on EMC, NetApp\'s Leavings -- Nimble, Tegile, Tintri -- SSD/HDD Hybrid Array Startups re-inventing the hybrid array with new software]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n <pre>\n$ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1 \n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:31:38 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     41462       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 9.64722\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 96.4722\nblusjune__iops                   : 10365\nblusjune__throughput (bytes/sec) : 42457810\n==================================================\n</pre>\n\n\n\n\n* Performance Benchmark (Random Write, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:35:44 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                         0  960635                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-write)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 0.416391\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 4.16391\nblusjune__iops                   : 240158\nblusjune__throughput (bytes/sec) : 983690602\n==================================================\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdd)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n <pre>\n $ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:25:26 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2123       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 188.403\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1884.03\nblusjune__iops                   : 530\nblusjune__throughput (bytes/sec) : 2174068\n==================================================\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1942,'== ## bNote-2013-05-02 ==\n\n=== R (r_stat) 3D plot ===\n\n* [http://www.statmethods.net/graphs/scatterplot.html Simple Scatterplot // Quick-R]\n* [http://www.r-bloggers.com/turning-your-data-into-a-3d-chart/ Turning your data into a 3d chart // R-bloggers]\n* [http://www.ejwagenmakers.com/misc/Plotting_3d_in_R.pdf R graph gallery // Compilation by Eric Lecoutre // 2003-12-12]\n\n\n\n\n== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n* [http://www.computerweekly.com/news/2240179705/ID7-buy-takes-Fusion-io-deeper-into-software-defined-storage ID7 buy takes Fusion-IO deeper into software-defined storage]\n\n* [http://searchstorage.techtarget.com/opinion/Software-defined-storage-Is-hardware-obsolete Software-defined Storage: Is Hardware Obsolete? // SearchStorage.techtarget.com]\n\n* [http://www.storagereview.com/fusionio_acquires_id7_developers_of_scst Fusion-IO Acquires ID7, Developers of SCST (SCSI Target Subsystem)]\n\n* [http://www.theregister.co.uk/2013/04/09/blind_spot/ Mutant Array Upstarts Feast on EMC, NetApp\'s Leavings -- Nimble, Tegile, Tintri -- SSD/HDD Hybrid Array Startups re-inventing the hybrid array with new software]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n <pre>\n$ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1 \n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:31:38 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     41462       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 9.64722\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 96.4722\nblusjune__iops                   : 10365\nblusjune__throughput (bytes/sec) : 42457810\n==================================================\n</pre>\n\n\n\n\n* Performance Benchmark (Random Write, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:35:44 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                         0  960635                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-write)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 0.416391\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 4.16391\nblusjune__iops                   : 240158\nblusjune__throughput (bytes/sec) : 983690602\n==================================================\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdd)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n <pre>\n $ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:25:26 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2123       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 188.403\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1884.03\nblusjune__iops                   : 530\nblusjune__throughput (bytes/sec) : 2174068\n==================================================\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/LaplacesDemon.pdf Package \'LaplacesDemon\']\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1943,'== ## bNote-2013-05-07 ==\n\n=== dirtifying 843t with iometer ===\n\n\n==== Test environment ====\n* NCQ: enabled (queue_depth = 31)\n* 메모리사 IOmeter 설정\n:- No. of outstanding I/Os: 32 개\n:- 4KB random writes, 1-hour\n* Partitioning: \n: 480GB 크기의 843T를 약 240GB 크기를 갖는 2개의 partition으로 나누어\n: Partition 1을 Iometer (메모리사 설정 이용)로 dirtyfing하여 100% (240GB) 채워놓고,\n: Partition 2를 Iometer (메모리사 설정 이용)로 dirtifying하면서 동시에 성능 metric 측정.\n* File system에 의한 효과 비교\n: raw block interface에 대해서 iometer를 실행하는 경우 ........ (case 1)\n: ext4 file system에 대해서 iometer를 실행하는 경우 ........... (case 2)\n:* case 1에서는, IO size가 4KB 그대로 block device에 떨어지므로, latency 특성은 case 2보다 좋음.\n\n\n\n\n\n== ## bNote-2013-05-02 ==\n\n=== R (r_stat) 3D plot ===\n\n* [http://www.statmethods.net/graphs/scatterplot.html Simple Scatterplot // Quick-R]\n* [http://www.r-bloggers.com/turning-your-data-into-a-3d-chart/ Turning your data into a 3d chart // R-bloggers]\n* [http://www.ejwagenmakers.com/misc/Plotting_3d_in_R.pdf R graph gallery // Compilation by Eric Lecoutre // 2003-12-12]\n\n== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n* [http://www.computerweekly.com/news/2240179705/ID7-buy-takes-Fusion-io-deeper-into-software-defined-storage ID7 buy takes Fusion-IO deeper into software-defined storage]\n\n* [http://searchstorage.techtarget.com/opinion/Software-defined-storage-Is-hardware-obsolete Software-defined Storage: Is Hardware Obsolete? // SearchStorage.techtarget.com]\n\n* [http://www.storagereview.com/fusionio_acquires_id7_developers_of_scst Fusion-IO Acquires ID7, Developers of SCST (SCSI Target Subsystem)]\n\n* [http://www.theregister.co.uk/2013/04/09/blind_spot/ Mutant Array Upstarts Feast on EMC, NetApp\'s Leavings -- Nimble, Tegile, Tintri -- SSD/HDD Hybrid Array Startups re-inventing the hybrid array with new software]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n <pre>\n$ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1 \n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:31:38 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     41462       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 9.64722\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 96.4722\nblusjune__iops                   : 10365\nblusjune__throughput (bytes/sec) : 42457810\n==================================================\n</pre>\n\n\n\n\n* Performance Benchmark (Random Write, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:35:44 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                         0  960635                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-write)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 0.416391\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 4.16391\nblusjune__iops                   : 240158\nblusjune__throughput (bytes/sec) : 983690602\n==================================================\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdd)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n <pre>\n $ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:25:26 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2123       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 188.403\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1884.03\nblusjune__iops                   : 530\nblusjune__throughput (bytes/sec) : 2174068\n==================================================\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/LaplacesDemon.pdf Package \'LaplacesDemon\']\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1944,'== ## bNote-2013-05-07 ==\n\n=== dirtifying 843t with iometer ===\n\n\n==== Test environment ====\n* NCQ: enabled (queue_depth = 31)\n* 메모리사 IOmeter 설정\n:- No. of outstanding I/Os: 32 개\n:- 4KB random writes, 1-hour\n* Partitioning: \n: 480GB 크기의 843T를 약 240GB 크기를 갖는 2개의 partition으로 나누어\n: Partition 1을 Iometer (메모리사 설정 이용)로 dirtyfing하여 100% (240GB) 채워놓고,\n: Partition 2를 Iometer (메모리사 설정 이용)로 dirtifying하면서 동시에 성능 metric 측정.\n* File system에 의한 효과 비교\n: raw block interface에 대해서 iometer를 실행하는 경우 ........ (case 1)\n: ext4 file system에 대해서 iometer를 실행하는 경우 ........... (case 2)\n:* case 1에서는, IO size가 4KB 그대로 block device에 떨어지므로, latency 특성은 case 2보다 좋음.\n\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     0.00    0.00  908.00     0.00  3632.00     8.00     1.99    2.19    0.00    2.19   1.10  99.60\n</pre>\n\n\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     9.00    0.00  221.00     0.00 112172.00  1015.13     1.00    4.54    0.00    4.54   4.51  99.60\n</pre>\n\n== ## bNote-2013-05-02 ==\n\n=== R (r_stat) 3D plot ===\n\n* [http://www.statmethods.net/graphs/scatterplot.html Simple Scatterplot // Quick-R]\n* [http://www.r-bloggers.com/turning-your-data-into-a-3d-chart/ Turning your data into a 3d chart // R-bloggers]\n* [http://www.ejwagenmakers.com/misc/Plotting_3d_in_R.pdf R graph gallery // Compilation by Eric Lecoutre // 2003-12-12]\n\n== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n* [http://www.computerweekly.com/news/2240179705/ID7-buy-takes-Fusion-io-deeper-into-software-defined-storage ID7 buy takes Fusion-IO deeper into software-defined storage]\n\n* [http://searchstorage.techtarget.com/opinion/Software-defined-storage-Is-hardware-obsolete Software-defined Storage: Is Hardware Obsolete? // SearchStorage.techtarget.com]\n\n* [http://www.storagereview.com/fusionio_acquires_id7_developers_of_scst Fusion-IO Acquires ID7, Developers of SCST (SCSI Target Subsystem)]\n\n* [http://www.theregister.co.uk/2013/04/09/blind_spot/ Mutant Array Upstarts Feast on EMC, NetApp\'s Leavings -- Nimble, Tegile, Tintri -- SSD/HDD Hybrid Array Startups re-inventing the hybrid array with new software]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n <pre>\n$ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1 \n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:31:38 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     41462       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 9.64722\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 96.4722\nblusjune__iops                   : 10365\nblusjune__throughput (bytes/sec) : 42457810\n==================================================\n</pre>\n\n\n\n\n* Performance Benchmark (Random Write, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:35:44 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                         0  960635                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-write)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 0.416391\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 4.16391\nblusjune__iops                   : 240158\nblusjune__throughput (bytes/sec) : 983690602\n==================================================\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdd)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n <pre>\n $ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:25:26 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2123       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 188.403\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1884.03\nblusjune__iops                   : 530\nblusjune__throughput (bytes/sec) : 2174068\n==================================================\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/LaplacesDemon.pdf Package \'LaplacesDemon\']\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1945,'== ## bNote-2013-05-07 ==\n\n=== dirtifying 843t with iometer ===\n\n\n==== Test environment ====\n\n* 메모리사 IOmeter 설정\n:- No. of outstanding I/Os: 32 개\n:- 4KB random writes, 1-hour\n\n* Partitioning: \n: 480GB 크기의 843T를 약 240GB 크기를 갖는 2개의 partition으로 나누어\n: Partition 1을 Iometer로 dirtyfing하여 100% (240GB) 채워놓고,\n: Partition 2를 Iometer로 dirtifying하면서 동시에 성능 metric 측정.\n\n* NCQ: enabled (queue_depth = 31)\n\n* 현재까지의 실험 진행 상황\n: uFLIP에 의한 dirtyfing은 취소 (480GB짜리 SSD에 대해서, uFLIP에 의한 dirtifying은 너무 느려서 중간에 취소하였음)\n: iometer에 의한 dirtifying 진행 중 (메모리사 설정 이용)\n\n* 지금까지 확인된 내용 (iostat 명령어를 이용하여 확인하였음)\n: latency를 높이는 쪽으로 가기 위해서는 file system을 bypass하여 raw block layer를 바로 이용하는 것이 좋지만, throughput을 높이는 방향으로 가기 위해서는 file system (ext4)에서 I/O를 handling하는 방식을 참고할 필요가 있겠다는 생각이 들었음.\n\n* I/O to block layer (bypassing file system)\n: Write IOPS = 908.00 (iosize: 4KB)\n: Write Throughput = 3,632.00 KB/s\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     0.00    0.00  908.00     0.00  3632.00     8.00     1.99    2.19    0.00    2.19   1.10  99.60\n</pre>\n\n\n* I/O through the file system (ext4)\n: Write IOPS = 221.00 (iosize: about 1,015KB)\n: Write Throughput = 112,172.00 KB/s\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     9.00    0.00  221.00     0.00 112172.00  1015.13     1.00    4.54    0.00    4.54   4.51  99.60\n</pre>\n\n== ## bNote-2013-05-02 ==\n\n=== R (r_stat) 3D plot ===\n\n* [http://www.statmethods.net/graphs/scatterplot.html Simple Scatterplot // Quick-R]\n* [http://www.r-bloggers.com/turning-your-data-into-a-3d-chart/ Turning your data into a 3d chart // R-bloggers]\n* [http://www.ejwagenmakers.com/misc/Plotting_3d_in_R.pdf R graph gallery // Compilation by Eric Lecoutre // 2003-12-12]\n\n== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n* [http://www.computerweekly.com/news/2240179705/ID7-buy-takes-Fusion-io-deeper-into-software-defined-storage ID7 buy takes Fusion-IO deeper into software-defined storage]\n\n* [http://searchstorage.techtarget.com/opinion/Software-defined-storage-Is-hardware-obsolete Software-defined Storage: Is Hardware Obsolete? // SearchStorage.techtarget.com]\n\n* [http://www.storagereview.com/fusionio_acquires_id7_developers_of_scst Fusion-IO Acquires ID7, Developers of SCST (SCSI Target Subsystem)]\n\n* [http://www.theregister.co.uk/2013/04/09/blind_spot/ Mutant Array Upstarts Feast on EMC, NetApp\'s Leavings -- Nimble, Tegile, Tintri -- SSD/HDD Hybrid Array Startups re-inventing the hybrid array with new software]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n <pre>\n$ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1 \n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:31:38 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     41462       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 9.64722\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 96.4722\nblusjune__iops                   : 10365\nblusjune__throughput (bytes/sec) : 42457810\n==================================================\n</pre>\n\n\n\n\n* Performance Benchmark (Random Write, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:35:44 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                         0  960635                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-write)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 0.416391\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 4.16391\nblusjune__iops                   : 240158\nblusjune__throughput (bytes/sec) : 983690602\n==================================================\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdd)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n <pre>\n $ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:25:26 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2123       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 188.403\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1884.03\nblusjune__iops                   : 530\nblusjune__throughput (bytes/sec) : 2174068\n==================================================\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/LaplacesDemon.pdf Package \'LaplacesDemon\']\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1946,'== ## bNote-2013-05-07 ==\n\n=== dirtifying 843t with iometer ===\n\n\n==== Test environment ====\n\n* 메모리사 IOmeter 설정\n:- No. of outstanding I/Os: 32 개\n:- 4KB random writes, 1-hour\n\n* Partitioning: \n: 480GB 크기의 843T를 약 240GB 크기를 갖는 2개의 partition으로 나누어\n: Partition 1을 Iometer로 dirtyfing하여 100% (240GB) 채워놓고,\n: Partition 2를 Iometer로 dirtifying하면서 동시에 성능 metric 측정.\n\n* NCQ: enabled (queue_depth = 31)\n\n* 현재까지의 실험 진행 상황\n: uFLIP에 의한 dirtyfing은 취소 (480GB짜리 SSD에 대해서, uFLIP에 의한 dirtifying은 너무 느려서 중간에 취소하였음)\n: iometer에 의한 dirtifying 진행 중 (메모리사 설정 이용)\n\n* 지금까지 확인된 내용 (iostat 명령어를 이용하여 확인하였음)\n: latency를 높이는 쪽으로 가기 위해서는 file system을 bypass하여 raw block layer를 바로 이용하는 것이 좋지만, throughput을 높이는 방향으로 가기 위해서는 file system (ext4)에서 I/O를 handling하는 방식을 참고할 필요가 있겠다는 생각이 들었음.\n: iometer가 발생시키는 I/O workload가 file system을 통과하게 되면, 4KB 단위 I/O들이 상당히 merge되어 throughput 값이 높아지는 효과 발생 (file vs. raw = 112,171KB/s vs. 3,632KB/s), 그러나 예상되는 바처럼 latency특성은 저하됨 (file vs. raw = 221.00 writes/sec vs. 908.00 writes/sec)\n\n\n* I/O through the file system (ext4)\n: Write IOPS = 221.00 (iosize: about 1,015KB)\n: Write Throughput = 112,172.00 KB/s\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     9.00    0.00  221.00     0.00 112172.00  1015.13     1.00    4.54    0.00    4.54   4.51  99.60\n</pre>\n\n\n* I/O to block layer (bypassing file system)\n: Write IOPS = 908.00 (iosize: 4KB)\n: Write Throughput = 3,632.00 KB/s\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     0.00    0.00  908.00     0.00  3632.00     8.00     1.99    2.19    0.00    2.19   1.10  99.60\n</pre>\n\n== ## bNote-2013-05-02 ==\n\n=== R (r_stat) 3D plot ===\n\n* [http://www.statmethods.net/graphs/scatterplot.html Simple Scatterplot // Quick-R]\n* [http://www.r-bloggers.com/turning-your-data-into-a-3d-chart/ Turning your data into a 3d chart // R-bloggers]\n* [http://www.ejwagenmakers.com/misc/Plotting_3d_in_R.pdf R graph gallery // Compilation by Eric Lecoutre // 2003-12-12]\n\n== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n* [http://www.computerweekly.com/news/2240179705/ID7-buy-takes-Fusion-io-deeper-into-software-defined-storage ID7 buy takes Fusion-IO deeper into software-defined storage]\n\n* [http://searchstorage.techtarget.com/opinion/Software-defined-storage-Is-hardware-obsolete Software-defined Storage: Is Hardware Obsolete? // SearchStorage.techtarget.com]\n\n* [http://www.storagereview.com/fusionio_acquires_id7_developers_of_scst Fusion-IO Acquires ID7, Developers of SCST (SCSI Target Subsystem)]\n\n* [http://www.theregister.co.uk/2013/04/09/blind_spot/ Mutant Array Upstarts Feast on EMC, NetApp\'s Leavings -- Nimble, Tegile, Tintri -- SSD/HDD Hybrid Array Startups re-inventing the hybrid array with new software]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n <pre>\n$ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1 \n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:31:38 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     41462       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 9.64722\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 96.4722\nblusjune__iops                   : 10365\nblusjune__throughput (bytes/sec) : 42457810\n==================================================\n</pre>\n\n\n\n\n* Performance Benchmark (Random Write, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:35:44 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                         0  960635                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-write)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 0.416391\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 4.16391\nblusjune__iops                   : 240158\nblusjune__throughput (bytes/sec) : 983690602\n==================================================\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdd)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n <pre>\n $ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:25:26 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2123       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 188.403\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1884.03\nblusjune__iops                   : 530\nblusjune__throughput (bytes/sec) : 2174068\n==================================================\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/LaplacesDemon.pdf Package \'LaplacesDemon\']\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1947,'== ## bNote-2013-05-07 ==\n\n=== dirtifying 843t with iometer ===\n\n\n==== Test environment ====\n\n* 메모리사 IOmeter 설정\n:- No. of outstanding I/Os: 32 개\n:- 4KB random writes, 1-hour\n\n* Partitioning: \n: 480GB 크기의 843T를 약 240GB 크기를 갖는 2개의 partition으로 나누어\n: Partition 1을 Iometer로 dirtyfing하여 100% (240GB) 채워놓고,\n: Partition 2를 Iometer로 dirtifying하면서 동시에 성능 metric 측정.\n\n* NCQ: enabled (queue_depth = 31)\n\n* 현재까지의 실험 진행 상황\n: uFLIP에 의한 dirtyfing은 취소 (480GB짜리 SSD에 대해서, uFLIP에 의한 dirtifying은 너무 느려서 중간에 취소하였음)\n: iometer에 의한 dirtifying 진행 중 (메모리사 설정 이용)\n\n* 지금까지 확인된 내용 (iostat 명령어를 이용하여 확인하였음)\n: latency를 높이는 쪽으로 가기 위해서는 file system을 bypass하여 raw block layer를 바로 이용하는 것이 좋지만, throughput을 높이는 방향으로 가기 위해서는 file system (ext4)에서 I/O를 handling하는 방식을 참고할 필요가 있겠다는 생각이 들었음.\n: iometer가 발생시키는 I/O workload가 file system을 통과하게 되면, 4KB 단위 I/O들이 상당히 merge되어 throughput 값이 높아지는 효과 발생 (file vs. raw = 112,171KB/s vs. 3,632KB/s), 그러나 예상되는 바처럼 latency특성은 저하됨 (file vs. raw = 221.00 writes/sec vs. 908.00 writes/sec)\n\n\n* I/O through the file system (ext4 - measured by iostat at initial-mid time)\n: Write IOPS = 221.00 (iosize: about 1,015KB)\n: Write Throughput = 112,172.00 KB/s\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     9.00    0.00  221.00     0.00 112172.00  1015.13     1.00    4.54    0.00    4.54   4.51  99.60\n</pre>\n\n* I/O through the file system (ext4 - measured by iometer at final time)\n: Total I/Os per Second: 439.97\n: Total MBs per Second: 1.72\n: Average I/O Response Time (ms): 290.9243\n: Maximum I/O Response Time (ms): 1791.3428\n\n\n* I/O to block layer (bypassing file system)\n: Write IOPS = 908.00 (iosize: 4KB)\n: Write Throughput = 3,632.00 KB/s\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     0.00    0.00  908.00     0.00  3632.00     8.00     1.99    2.19    0.00    2.19   1.10  99.60\n</pre>\n\n== ## bNote-2013-05-02 ==\n\n=== R (r_stat) 3D plot ===\n\n* [http://www.statmethods.net/graphs/scatterplot.html Simple Scatterplot // Quick-R]\n* [http://www.r-bloggers.com/turning-your-data-into-a-3d-chart/ Turning your data into a 3d chart // R-bloggers]\n* [http://www.ejwagenmakers.com/misc/Plotting_3d_in_R.pdf R graph gallery // Compilation by Eric Lecoutre // 2003-12-12]\n\n== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n* [http://www.computerweekly.com/news/2240179705/ID7-buy-takes-Fusion-io-deeper-into-software-defined-storage ID7 buy takes Fusion-IO deeper into software-defined storage]\n\n* [http://searchstorage.techtarget.com/opinion/Software-defined-storage-Is-hardware-obsolete Software-defined Storage: Is Hardware Obsolete? // SearchStorage.techtarget.com]\n\n* [http://www.storagereview.com/fusionio_acquires_id7_developers_of_scst Fusion-IO Acquires ID7, Developers of SCST (SCSI Target Subsystem)]\n\n* [http://www.theregister.co.uk/2013/04/09/blind_spot/ Mutant Array Upstarts Feast on EMC, NetApp\'s Leavings -- Nimble, Tegile, Tintri -- SSD/HDD Hybrid Array Startups re-inventing the hybrid array with new software]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n <pre>\n$ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1 \n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:31:38 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     41462       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 9.64722\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 96.4722\nblusjune__iops                   : 10365\nblusjune__throughput (bytes/sec) : 42457810\n==================================================\n</pre>\n\n\n\n\n* Performance Benchmark (Random Write, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:35:44 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                         0  960635                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-write)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 0.416391\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 4.16391\nblusjune__iops                   : 240158\nblusjune__throughput (bytes/sec) : 983690602\n==================================================\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdd)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n <pre>\n $ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:25:26 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2123       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 188.403\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1884.03\nblusjune__iops                   : 530\nblusjune__throughput (bytes/sec) : 2174068\n==================================================\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/LaplacesDemon.pdf Package \'LaplacesDemon\']\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8');
INSERT INTO `mw_text` VALUES (1948,'== ## bNote-2013-05-07 ==\n\n=== dirtifying 843t with iometer ===\n\n\n==== Test environment ====\n\n* 메모리사 IOmeter 설정\n:- No. of outstanding I/Os: 32 개\n:- 4KB random writes, 1-hour\n\n* Partitioning: \n: 480GB 크기의 843T를 약 240GB 크기를 갖는 2개의 partition으로 나누어\n: Partition 1을 Iometer로 dirtyfing하여 100% (240GB) 채워놓고,\n: Partition 2를 Iometer로 dirtifying하면서 동시에 성능 metric 측정.\n\n* NCQ: enabled (queue_depth = 31)\n\n* 현재까지의 실험 진행 상황\n: uFLIP에 의한 dirtyfing은 취소 (480GB짜리 SSD에 대해서, uFLIP에 의한 dirtifying은 너무 느려서 중간에 취소하였음)\n: iometer에 의한 dirtifying 진행 중 (메모리사 설정 이용)\n\n* 지금까지 확인된 내용 (iostat 명령어를 이용하여 확인하였음)\n: latency를 높이는 쪽으로 가기 위해서는 file system을 bypass하여 raw block layer를 바로 이용하는 것이 좋지만, throughput을 높이는 방향으로 가기 위해서는 file system (ext4)에서 I/O를 handling하는 방식을 참고할 필요가 있겠다는 생각이 들었음.\n: iometer가 발생시키는 I/O workload가 file system을 통과하게 되면, 4KB 단위 I/O들이 상당히 merge되어 throughput 값이 높아지는 효과 발생 (file vs. raw = 112,171KB/s vs. 3,632KB/s), 그러나 예상되는 바처럼 latency특성은 저하됨 (file vs. raw = 221.00 writes/sec vs. 908.00 writes/sec)\n\n\n* I/O through the file system (ext4 - measured by iostat at initial-mid time)\n: Write IOPS = 221.00 (iosize: about 1,015KB)\n: Write Throughput = 112,172.00 KB/s\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     9.00    0.00  221.00     0.00 112172.00  1015.13     1.00    4.54    0.00    4.54   4.51  99.60\n</pre>\n\n\n* I/O through the file system (ext4 - measured by iostat at final time)\n: Write IOPS = 523.00 (iosize: about 8KB)\n: Write Throughput = 2092 KB/s\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     0.00    0.00  523.00     0.00  2092.00     8.00     0.98    1.88    0.00    1.88   1.88  98.40\n</pre>\n\n\n* I/O through the file system (ext4 - measured by iometer at final time)\n: Total I/Os per Second: 439.97\n: Total MBs per Second: 1.72\n: Average I/O Response Time (ms): 290.9243\n: Maximum I/O Response Time (ms): 1791.3428\n\n\n* I/O to block layer (bypassing file system)\n: Write IOPS = 908.00 (iosize: 4KB)\n: Write Throughput = 3,632.00 KB/s\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     0.00    0.00  908.00     0.00  3632.00     8.00     1.99    2.19    0.00    2.19   1.10  99.60\n</pre>\n\n== ## bNote-2013-05-02 ==\n\n=== R (r_stat) 3D plot ===\n\n* [http://www.statmethods.net/graphs/scatterplot.html Simple Scatterplot // Quick-R]\n* [http://www.r-bloggers.com/turning-your-data-into-a-3d-chart/ Turning your data into a 3d chart // R-bloggers]\n* [http://www.ejwagenmakers.com/misc/Plotting_3d_in_R.pdf R graph gallery // Compilation by Eric Lecoutre // 2003-12-12]\n\n== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n* [http://www.computerweekly.com/news/2240179705/ID7-buy-takes-Fusion-io-deeper-into-software-defined-storage ID7 buy takes Fusion-IO deeper into software-defined storage]\n\n* [http://searchstorage.techtarget.com/opinion/Software-defined-storage-Is-hardware-obsolete Software-defined Storage: Is Hardware Obsolete? // SearchStorage.techtarget.com]\n\n* [http://www.storagereview.com/fusionio_acquires_id7_developers_of_scst Fusion-IO Acquires ID7, Developers of SCST (SCSI Target Subsystem)]\n\n* [http://www.theregister.co.uk/2013/04/09/blind_spot/ Mutant Array Upstarts Feast on EMC, NetApp\'s Leavings -- Nimble, Tegile, Tintri -- SSD/HDD Hybrid Array Startups re-inventing the hybrid array with new software]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n <pre>\n$ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1 \n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:31:38 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     41462       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 9.64722\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 96.4722\nblusjune__iops                   : 10365\nblusjune__throughput (bytes/sec) : 42457810\n==================================================\n</pre>\n\n\n\n\n* Performance Benchmark (Random Write, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:35:44 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                         0  960635                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-write)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 0.416391\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 4.16391\nblusjune__iops                   : 240158\nblusjune__throughput (bytes/sec) : 983690602\n==================================================\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdd)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n <pre>\n $ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:25:26 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2123       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 188.403\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1884.03\nblusjune__iops                   : 530\nblusjune__throughput (bytes/sec) : 2174068\n==================================================\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/LaplacesDemon.pdf Package \'LaplacesDemon\']\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1949,'== ## bNote-2013-05-07 ==\n\n=== dirtifying 843t with iometer ===\n\n\n==== Test environment ====\n\n* 메모리사 IOmeter 설정\n:- No. of outstanding I/Os: 32 개\n:- 4KB random writes, 1-hour\n\n* Partitioning: \n: 480GB 크기의 843T를 약 240GB 크기를 갖는 2개의 partition으로 나누어\n: Partition 1을 Iometer로 dirtyfing하여 100% (240GB) 채워놓고,\n: Partition 2를 Iometer로 dirtifying하면서 동시에 성능 metric 측정.\n\n* NCQ: enabled (queue_depth = 31)\n\n* 현재까지의 실험 진행 상황\n: uFLIP에 의한 dirtyfing은 취소 (480GB짜리 SSD에 대해서, uFLIP에 의한 dirtifying은 너무 느려서 중간에 취소하였음)\n: iometer에 의한 dirtifying 진행 중 (메모리사 설정 이용)\n\n* 지금까지 확인된 내용 (iostat 명령어를 이용하여 확인하였음)\n: latency를 높이는 쪽으로 가기 위해서는 file system을 bypass하여 raw block layer를 바로 이용하는 것이 좋지만, throughput을 높이는 방향으로 가기 위해서는 file system (ext4)에서 I/O를 handling하는 방식을 참고할 필요가 있겠다는 생각이 들었음.\n: iometer가 발생시키는 I/O workload가 file system을 통과하게 되면, 4KB 단위 I/O들이 상당히 merge되어 throughput 값이 높아지는 효과 발생 (file vs. raw = 112,171KB/s vs. 3,632KB/s), 그러나 예상되는 바처럼 latency특성은 저하됨 (file vs. raw = 221.00 writes/sec vs. 908.00 writes/sec)\n\n\n----\n* I/O through the file system (ext4 - measured by iostat at initial-mid time)\n: Write IOPS = 221.00 (iosize: about 1,015KB)\n: Write Throughput = 112,172.00 KB/s\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     9.00    0.00  221.00     0.00 112172.00  1015.13     1.00    4.54    0.00    4.54   4.51  99.60\n</pre>\n\n\n* I/O through the file system (ext4 - measured by iostat at final time)\n: Write IOPS = 523.00 (iosize: about 8KB)\n: Write Throughput = 2092 KB/s\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     0.00    0.00  523.00     0.00  2092.00     8.00     0.98    1.88    0.00    1.88   1.88  98.40\n</pre>\n\n\n* I/O through the file system (ext4 - measured by iometer at final time)\n: Total I/Os per Second: 439.97\n: Total MBs per Second: 1.72\n: Average I/O Response Time (ms): 290.9243\n: Maximum I/O Response Time (ms): 1791.3428\n\n\n----\n* I/O to block layer (bypassing file system)\n: Write IOPS = 908.00 (iosize: 4KB)\n: Write Throughput = 3,632.00 KB/s\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     0.00    0.00  908.00     0.00  3632.00     8.00     1.99    2.19    0.00    2.19   1.10  99.60\n</pre>\n\n== ## bNote-2013-05-02 ==\n\n=== R (r_stat) 3D plot ===\n\n* [http://www.statmethods.net/graphs/scatterplot.html Simple Scatterplot // Quick-R]\n* [http://www.r-bloggers.com/turning-your-data-into-a-3d-chart/ Turning your data into a 3d chart // R-bloggers]\n* [http://www.ejwagenmakers.com/misc/Plotting_3d_in_R.pdf R graph gallery // Compilation by Eric Lecoutre // 2003-12-12]\n\n== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n* [http://www.computerweekly.com/news/2240179705/ID7-buy-takes-Fusion-io-deeper-into-software-defined-storage ID7 buy takes Fusion-IO deeper into software-defined storage]\n\n* [http://searchstorage.techtarget.com/opinion/Software-defined-storage-Is-hardware-obsolete Software-defined Storage: Is Hardware Obsolete? // SearchStorage.techtarget.com]\n\n* [http://www.storagereview.com/fusionio_acquires_id7_developers_of_scst Fusion-IO Acquires ID7, Developers of SCST (SCSI Target Subsystem)]\n\n* [http://www.theregister.co.uk/2013/04/09/blind_spot/ Mutant Array Upstarts Feast on EMC, NetApp\'s Leavings -- Nimble, Tegile, Tintri -- SSD/HDD Hybrid Array Startups re-inventing the hybrid array with new software]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n <pre>\n$ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1 \n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:31:38 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     41462       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 9.64722\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 96.4722\nblusjune__iops                   : 10365\nblusjune__throughput (bytes/sec) : 42457810\n==================================================\n</pre>\n\n\n\n\n* Performance Benchmark (Random Write, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:35:44 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                         0  960635                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-write)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 0.416391\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 4.16391\nblusjune__iops                   : 240158\nblusjune__throughput (bytes/sec) : 983690602\n==================================================\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdd)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n <pre>\n $ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:25:26 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2123       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 188.403\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1884.03\nblusjune__iops                   : 530\nblusjune__throughput (bytes/sec) : 2174068\n==================================================\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/LaplacesDemon.pdf Package \'LaplacesDemon\']\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1950,'== ## bNote-2013-05-07 ==\n\n=== dirtifying 843t with iometer ===\n\n\n==== Test environment ====\n\n* 메모리사 IOmeter 설정\n:- No. of outstanding I/Os: 32 개\n:- 4KB random writes, 1-hour\n\n* Partitioning: \n: 480GB 크기의 843T를 약 240GB 크기를 갖는 2개의 partition으로 나누어\n: Partition 1을 Iometer로 dirtyfing하여 100% (240GB) 채워놓고,\n: Partition 2를 Iometer로 dirtifying하면서 동시에 성능 metric 측정.\n\n* NCQ: enabled (queue_depth = 31)\n\n* 현재까지의 실험 진행 상황\n: uFLIP에 의한 dirtyfing은 취소 (480GB짜리 SSD에 대해서, uFLIP에 의한 dirtifying은 너무 느려서 중간에 취소하였음)\n: iometer에 의한 dirtifying 진행 중 (메모리사 설정 이용)\n\n* 지금까지 확인된 내용 (iostat 명령어를 이용하여 확인하였음)\n: latency를 높이는 쪽으로 가기 위해서는 file system을 bypass하여 raw block layer를 바로 이용하는 것이 좋지만, throughput을 높이는 방향으로 가기 위해서는 file system (ext4)에서 I/O를 handling하는 방식을 참고할 필요가 있겠다는 생각이 들었음.\n: iometer가 발생시키는 I/O workload가 file system을 통과하게 되면, 4KB 단위 I/O들이 상당히 merge되어 throughput 값이 높아지는 효과 발생 (file vs. raw = 112,171KB/s vs. 3,632KB/s), 그러나 예상되는 바처럼 latency특성은 저하됨 (file vs. raw = 221.00 writes/sec vs. 908.00 writes/sec)\n\n\n----\n* iostat-20130507_141457-oio32.log\n\n* I/O through the file system (ext4 - measured by iostat at initial-mid time)\n: Write IOPS = 221.00 (iosize: about 1,015KB)\n: Write Throughput = 112,172.00 KB/s\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     9.00    0.00  221.00     0.00 112172.00  1015.13     1.00    4.54    0.00    4.54   4.51  99.60\n</pre>\n\n\n* I/O through the file system (ext4 - measured by iostat at final time)\n: Write IOPS = 523.00 (iosize: about 8KB)\n: Write Throughput = 2092 KB/s\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     0.00    0.00  523.00     0.00  2092.00     8.00     0.98    1.88    0.00    1.88   1.88  98.40\n</pre>\n\n\n* I/O through the file system (ext4 - measured by iometer at final time)\n: Total I/Os per Second: 439.97\n: Total MBs per Second: 1.72\n: Average I/O Response Time (ms): 290.9243\n: Maximum I/O Response Time (ms): 1791.3428\n\n\n----\n* I/O to block layer (bypassing file system)\n: Write IOPS = 908.00 (iosize: 4KB)\n: Write Throughput = 3,632.00 KB/s\n <pre>\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nsdd1              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00\nsdd2              0.00     0.00    0.00  908.00     0.00  3632.00     8.00     1.99    2.19    0.00    2.19   1.10  99.60\n</pre>\n\n== ## bNote-2013-05-02 ==\n\n=== R (r_stat) 3D plot ===\n\n* [http://www.statmethods.net/graphs/scatterplot.html Simple Scatterplot // Quick-R]\n* [http://www.r-bloggers.com/turning-your-data-into-a-3d-chart/ Turning your data into a 3d chart // R-bloggers]\n* [http://www.ejwagenmakers.com/misc/Plotting_3d_in_R.pdf R graph gallery // Compilation by Eric Lecoutre // 2003-12-12]\n\n== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n* [http://www.computerweekly.com/news/2240179705/ID7-buy-takes-Fusion-io-deeper-into-software-defined-storage ID7 buy takes Fusion-IO deeper into software-defined storage]\n\n* [http://searchstorage.techtarget.com/opinion/Software-defined-storage-Is-hardware-obsolete Software-defined Storage: Is Hardware Obsolete? // SearchStorage.techtarget.com]\n\n* [http://www.storagereview.com/fusionio_acquires_id7_developers_of_scst Fusion-IO Acquires ID7, Developers of SCST (SCSI Target Subsystem)]\n\n* [http://www.theregister.co.uk/2013/04/09/blind_spot/ Mutant Array Upstarts Feast on EMC, NetApp\'s Leavings -- Nimble, Tegile, Tintri -- SSD/HDD Hybrid Array Startups re-inventing the hybrid array with new software]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 830 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance Benchmark (Random Read, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 09:20:02 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/ssd_test/400m.1\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     45213       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 8.84687\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 88.4687\nblusjune__iops                   : 11303\nblusjune__throughput (bytes/sec) : 46298866\n==================================================\nreal    0m8.912s\nuser    0m0.072s\nsys     0m2.072s\n</pre>\n\n <pre>\n$ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1 \n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:31:38 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                     41462       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 9.64722\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 96.4722\nblusjune__iops                   : 10365\nblusjune__throughput (bytes/sec) : 42457810\n==================================================\n</pre>\n\n\n\n\n* Performance Benchmark (Random Write, SSD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdf)\n\n <pre>\n$ iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:35:44 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+W -w -s 400000 -r 4 -f /x/bmt_iozone/test/ssd_test/400m.3\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                         0  960635                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-write)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 0.416391\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 4.16391\nblusjune__iops                   : 240158\nblusjune__throughput (bytes/sec) : 983690602\n==================================================\n</pre>\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n* Performance Benchmark (Random Read, HDD, echo 3 > /proc/sys/vm/drop_caches, hdparm -W0 /dev/sdd)\n <pre>\n$ time iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Iozone: Performance Test of File I/O\n                Version $Revision: 3.398 $ -- blusjune 20130502_023327\n                Compiled for 6          Build: linux-AMD64\n\n                Build: linux-AMD64\n\n        Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n                     Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n                     Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n                     Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n                     Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n                     Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n                     Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n                     Ben England.\n\n        Run began: Thu May  2 08:24:47 2013\n\n        Setting no_unlink\n        File size set to 400000 KB\n        Record Size 4 KB\n        Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/iozone/test/hdd_test/400m\n        Output is in Kbytes/sec\n        Time Resolution = 0.000001 seconds.\n        Processor cache size set to 1024 Kbytes.\n        Processor cache line size set to 32 bytes.\n        File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2116       0                                             \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 189.019\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1890.19\nblusjune__iops                   : 529\nblusjune__throughput (bytes/sec) : 2166974\n==================================================\nreal    3m9.229s\nuser    0m0.120s\nsys     0m3.208s\n</pre>\n\n <pre>\n $ iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Iozone: Performance Test of File I/O\n	        Version $Revision: 3.398 $ -- blusjune 20130502_110038\n		Compiled for 6		Build: linux-AMD64 \n\n		Build: linux-AMD64 \n\n	Contributors:William Norcott, Don Capps, Isom Crawford, Kirby Collins\n	             Al Slater, Scott Rhine, Mike Wisner, Ken Goss\n	             Steve Landherr, Brad Smith, Mark Kelly, Dr. Alain CYR,\n	             Randy Dunlap, Mark Montague, Dan Million, Gavin Brebner,\n	             Jean-Marc Zucconi, Jeff Blomberg, Benny Halevy, Dave Boone,\n	             Erik Habbinga, Kris Strecker, Walter Wong, Joshua Root,\n	             Fabrice Bacchella, Zhenghua Xue, Qin Li, Darren Sawyer.\n	             Ben England.\n\n	Run began: Thu May  2 11:25:26 2013\n\n	Setting no_unlink\n	File size set to 400000 KB\n	Record Size 4 KB\n	Command line used: iozone -i 2 -+R -w -s 400000 -r 4 -f /x/bmt_iozone/test/hdd_test/400m.1\n	Output is in Kbytes/sec\n	Time Resolution = 0.000001 seconds.\n	Processor cache size set to 1024 Kbytes.\n	Processor cache line size set to 32 bytes.\n	File stride size set to 17 * record size.\n                                                            random  random    bkwd   record   stride                                   \n              KB  reclen   write rewrite    read    reread    read   write    read  rewrite     read   fwrite frewrite   fread  freread\n          400000       4                                      2123       0                                                                                              \n\niozone test complete.\n\n==================================================\nblusjune performance metrics (random-read)\n==================================================\nblusjune__file_size (bytes)      : 409600000\nblusjune__record_size (bytes)    : 4096\nblusjune__time_elapsed (secs)    : 188.403\nblusjune__num_of_ios             : 100000\n--------------------------------------------------\nblusjune__latency_per_io (usecs) : 1884.03\nblusjune__iops                   : 530\nblusjune__throughput (bytes/sec) : 2174068\n==================================================\n</pre>\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/LaplacesDemon.pdf Package \'LaplacesDemon\']\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1951,'== PATENT-BRIAN-2013-001 ==\n\n=== # RAM-SSD Hybrid Page Cache Architecture ===\n\n[[Bnote patidea 2013-001]]\n\n== PATENT-BRIAN-2013-002 ==\n=== # Low-computation-overhead and Memory-efficient Periodicity Detection Method ===\n[[Bnote patidea 2013-002]]\n\n== PATENT-BRIAN-2013-003 ==\n\n=== 맵리듀스 작업의 병목 탐지 및 원인 분석을 위한 모니터링 프레임워크 기술 (A monitoring framework for detecting and analyzing execution bottlenecks of MapReduce jobs) ===\n\n[[Bnote patidea 2013-003]]\n\n=== # 요약 ===\n\n* 본 발명은 Hadoop MapReduce 기반의 분산 병렬 시스템의 성능 향상을 위해 이용할 수 있는 맵리듀스 작업의 병목 탐지 및 원인 분석을 위한 모니터링 프레임워크 기술에 대한 것임.\n\n\n\n* \"MapReduce의 병목 탐지 및 원인 분석을 위한 모니터링 프레임워크\" 로서,\n: 시스템 리소스 사용량, Hadoop 상태 정보, I/O 패턴, Straggler 정보 등의\n: 다계층 정보 모니터링 및 학습을 통해 주요 병목 요인을 자동 판별케 함\n\n\n* 맵리듀스 작업에서 병목 탐지 및 자동적인 원인 분석을 위한 모니터링 프레임워크 기술로서,\n: 맵리듀스 각 노드의 시스템 리소스 사용량, Hadoop 상태 정보, I/O 패턴, Straggler 정보 등의 모니터링 및 학습을 통해,\n: Straggler 태스크 탐지 시 해당 태스크의 실시간 모니터링 정보를 기존 학습 결과와 연계 분석하여,\n: 성능 저하와 깊은 연관을 보이는 요소를 판단케 하는 방법 및 시스템 구조.\n\n\n* Question\n: 연계 분석 시, 실시간 분석이 가능한지? 어느 정도의 데이터에 대해 시간이 얼마나 걸렸는지?\n\n=== # 발명의 이용분야 ===\n\n* Hadoop MapReduce 기반의 분산 병렬 시스템 (Enterprise, Cloud 등 Data Center)\n\n\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* 본 발명이 속하는 기술 분야는 맵리듀스 작업을 위한 성능 모니터링 기술이다. 대용량 데이터 처리를 위한 맵리듀스 작업에서는 대량의 컴퓨팅 리소스를 이용하여 신속하게 작업을 처리하기 위해 하나의 작업을 다수의 태스크로 나누어 실행하게 된다. 이 때, 하나의 태스크라도 느려지게 되면 그를 제외한 태스크들이 해당 태스크의 수행 완료 시까지 대기해야 하므로 지연 태스크를 탐지해내는 일은 맵리듀스 작업의 효율성을 위해 매우 중요하다. \n\n* 기존의 모니터링 기술은 CPU나 메모리와 같은 리소스 사용량을 모니터링하여 병목 노드를 탐지해냈다. 그러나 이는 일반적이고 개략적인 정보로서, 이 정보만으로 맵리듀스 작업에서의 병목을 일으키는 태스크를 탐지해내고 원인을 분석해내기에는 정확도가 매우 떨어진다. 따라서 본 발명은 기존 기술과의 차별화를 위해 모니터링 대상을 다각적으로 분석하여 확장함으로써 병목 원인 분석 및 병목 태스크 탐지의 정확도를 향상시켰다.\n\n=== # 본 발명의 특징 / 효과 ===\n\n* 발명 기술에서는 맵리듀스 작업을 실행중인 각 노드에 대해 리소스 사용량, 하둡 설정 값, 그리고 I/O 특성의 계층적 정보를 모니터링한다. 지연되는 태스크가 발생하면 해당 태스크의 I/O 특성을 추출한 후, 리소스 사용량 및 하둡 설정 값과 같은 상위 수준의 정보와 연계 분석하여 병목 원인 정보를 사용자에게 제공한다.\n\n* 모든 단계의 모니터링 및 분석 정보를 자동화하여 사용자에게 제공하기 위해서는 계층적 정보들 중 성능 저하와 깊은 연관을 보이는 특정 리소스를 탐지하는 것이 중요하다. 즉, 병목이 발생한 노드의 리소스 사용률, 병목을 일으킨 작업의 하둡 환경, 그리고 병목을 일으킨 태스크의 I/O 특성 정보는기계 학습 기법을 통해 병목이 발생한 것으로 예측되는 태스크를 탐지할 수 있으며, 기계에 의해 자동적으로 사용자에게 제공되는 메커니즘을 구성할 수 있다. 이 때의 메커니즘은 I/O intensive한 곳을 알아내기 위해 전체 모니터링 parameter들 중에서 비정상적인 결과를 나타내는 리소스 특성을 효과적으로 선정할 수 있어야 한다. 사용자들은 이러한 분석 결과를 통해 하둡 설정을 변경하는 것이 효율적일지 혹은 리소스가 충분한 다른 노드에서 실행시키는 것이 효율적일지 결정할 수 있게 된다.\n\n=== # 대표 청구항 ===\n\n\n* 맵리듀스 작업에서 병목 탐지 및 자동적인 원인 분석을 위한 모니터링 프레임워크 기술로서,\n: 맵리듀스 작업을 실행중인 각 노드에 대해 리소스 사용량, 하둡 설정 값, 그리고 I/O 특성의 계층적 정보를 모니터링하여, 지연되는 태스크가 발생하면 자동적으로 해당 태스크의 I/O 특성을 추출한 후, 리소스 사용량 및 하둡 설정 값과 같은 상위 수준의 정보와 연계하여 분석하여 성능 저하와 깊은 연관을 보이는 요소를 탐지할 수 있게 하는 방법 및 시스템 구조\n\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n\n* 특허 검색 결과\n: Hadoop MapReduce I/O bottleneck\n: 44 results @ Google Patent Search\n\n\n* 논문 검색 결과\n:* MROrchestrator: A Fine-grained Resource Orchestration Framework for Hadoop MapReduce (IEEE ICCC 2012)\n::- [http://www.cse.psu.edu/research/publications/tech-reports/2012/CSE%20-12-001.pdf Paper @ psu.edu]\n::- [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6253482 Paper @ IEEE Xplore]\n \n:* Predicting Execution Bottlenecks in Map-Reduce Clusters (HotCloud 2012)\n::- [https://www.usenix.org/conference/hotcloud12/predicting-execution-bottlenecks-map-reduce-clusters Paper home @ USENIX HotCloud 2012]\n\n:* Theius: A Streaming Visualization Suite for Hadoop Clusters\n::- [https://wiki.engr.illinois.edu/download/attachments/195766887/JAR-3rd.pdf?version=1&modificationDate=1336558393000 Paper @ illinois.edu]\n\n=== # Memo / Questions ===\n\n\n==== References ====\n\n* [https://www.usenix.org/conference/hotcloud12/predicting-execution-bottlenecks-map-reduce-clusters Predicting Execution Bottlenecks in Map-Reduce Clusters, Yahoo! Labs, USENIX HotCloud 2012]\n\n* [http://www.nagios.org/ Nagios - Industry Standard in IT Infrastructure Monitoring]\n\n* [http://en.wikipedia.org/wiki/Comparison_of_network_monitoring_systems Comparison of network monitoring systems]\n\n* [http://blogs.msdn.com/b/ntdebugging/archive/2008/04/03/windows-performance-toolkit-xperf.aspx Windows Performance Toolkit - Xperf]\n\n* [http://sqlvelocity.typepad.com/blog/2011/06/windows-io-tracing.html Windows I/O Tracing (2011-06-22)]\n\n==== 발명자 인적사항 ====\n\n <pre>\n성명: 엄현상 \n주민번호: 690721-1051717\n소속기관: 서울대학교\n소속부서: 컴퓨터공학부\n국적: 대한민국\n핸드폰번호: 016-232-4667\n유선전화번호: 02-880-6755\n이메일: hseom@cse.snu.ac.kr\n주소: 서울시 관악구 관악로 1, (봉천동 서울대교수아파트) 122H동 103호\n\n성명: 조인순 (Jo, Insoon)\n주민번호: 750608-2029511\n소속기관: 서울대학교\n소속부서: 컴퓨터공학부\n국적: 대한민국\n핸드폰번호: 010-5131-7886\n유선전화번호: x\n이메일: insoonjo@gmail.com\n주소: 서울시 관악구 낙성대동 162-12 206호\n\n성명: 성민영 (Sung, Minyoung)\n주민번호: 871114-2079919\n소속기관: 서울대학교\n소속부서: 컴퓨터공학부\n국적: 대한민국\n핸드폰번호: 010-4724-5304\n유선전화번호: 02-876-2159\n이메일: eunice.sung87@gmail.com\n주소: 서울시 송파구 방이1동 대림아파트 6동 901호\n\n</pre>\n\n\n\n== PATENT-BRIAN-2013-004 ==\n\n<!-- === Straggler-immune Data/Task Placement in the Distributed Environment === -->\n\n=== Straggler-immune Data Placement in the Distributed Environment (HDFS?) ===\n\n\n\n\n=== Memo ===\n\n* title candidates\n: outlier(straggler, failure, ...)-immune data placement for distributed file system\n: straggler-immune data placement in the distributed file system (DFS)\n\n\n* Assumptions // 환경\n: replica management가 있는 DFS 환경\n: replica management algorithm 변경 가능\n: MapReduce/HDFS처럼 data가 있는 곳에 computation을 보내는 구조\n: DFS 위에서 Hadoop MapReduce처럼 분산 병렬 처리를 수행하는 환경\n\n* Assumptions // Failure Characteristics \n: straggler 발생과 task의 type 간의 연관성이 있음\n: {task type, node} tuple이 \n\nHDFS 및 MapReduce 환경에서,\n\n\n특정 node와 특정 task type의 조합과 straggler 발생 빈도 간에 연관 관계가 있을 수 있을까?\n\n\n즉 straggler가 발생했던 case를 관찰했을 때,\nnode 정보만으로는 패턴 (혹은 straggler 발생과의 연관성)이 보이지 않고,\ntask type 정보만으로도 패턴 (혹은 straggler 발생과의 연관성)이 보이지 않지만,\nnode 정보와 task type 정보를 같이 고려했을 때 straggler 발생 빈도/확률과 연관성을 볼 수 있었다면?\n\n\n\n\n* Bottleneck History Record (BHR) based approach\n: do not throw away the bottleneck experience (history). KEEP IT to use the knowledge for later use.\n\n* Replica management\n: at the very first time to place the data\nDistributed File Systems\n\n\n\n=== # 요약 ===\n\n\n=== # 발명의 이용분야 ===\n\n* Hadoop MapReduce/HDFS 혹은 이와 유사한 분산 처리 시스템이 구동되는 Enterprise 데이터 분석 클러스터.\n* Hadoop MapReduce/HDFS 혹은 이와 유사한 분산 처리 시스템이 구동되는 Public Cloud 데이터센터\n\n\n----\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* Hadoop의 기본 DFS인 HDFS (Hadoop Distributed File System)은 replica management를 수행하고 있음.\n\n\n* HDFS에서의 replica management는 3-copy replica 구성 시, 다음 몇 가지 원칙에 의해 data를 분배하고 있음.\n:- 하나의 node에 동일 block이 두 개 이상 존재하지 않는다\n:- 하나의 rack에 동일 block이 세 개 이상 존재하지 않는다\n:- 첫 번째 replica는 client가 구동하고 있는 node에 배치\n:- 두 번째 replica는 첫 번째 replica가 있던 node가 속하지 않은 다른 rack의 임의의 node에 배치\n:- 세 번째 replica는 두 번째 replica가 배치된 rack 내의 다른 node에 배치\n:- 1st-2nd-3rd replica 배치는 순차적으로 실행\n\n\n* Yahoo!의 Hadoop Cluster에서 10개월간 구동된 17만개의 MapReduce job들을 분석한 연구에 따르면 약 3% 정도의 Job들이 fail되었으며, 각 task의 특성과 failure 발생과 연관성이 있음을 확인할 수 있다. (예를 들어, MapReduce 전체 failure의 80% 이상이 map task에서 발생하였으며, map task failure의 36%는 array indexing error에 의한 것이었음. 그리고 reduce task 의 23%는 I/O exception에 의한 것이었음)  이러한 failure 및 straggler로 인해 task restart가 많이 발생하고 있으며, 이는 MapReduce/HDFS 성능을 저하시키는 주요 요인임.\n\n\n* 현존 Hadoop MapReduce/HDFS 시스템에서는 straggler가 발생했다고 판단되면, 해당 task를 drop 시키고 새로운 node에서 task가 실행될 수 있도록 하고 있음. 즉, 이미 발생한 straggler에 대해서는 speculative execution을 수행하고 있지만 여전히 한계점은 존재함. (1) speculative execution을 위해 필요한 additional data copy overhead 존재. (2) 새로운 execution node를 찾는다 하더라도 그 node가 straggler-free한 node인지 보장할 수 없기 때문에, 제2, 제3의 straggler가 발생할 가능성 존재. (3) additional copy를 하려고 하더라도 이미 task들이 tight하게 많이 구동되고 있는 상황에서, 여유 execution slot을 가지고 있는 적절한 node를 바로 찾지 못할 수 있으며, 이렇게 기다리는 것 자체가 job completion time을 증가시키는 부정적인 효과가 있음.\n\n\n----\n\n=== # 본 발명의 특징 / 효과 ===\n\n\n* 특징\n:- 기존처럼 straggler가 발생한 후에 대응하기 보다는 (사후 대응), HDFS에 처음 data가 놓여질 때부터 straggler-immune node에 배치될 수 있도록 하는 사전 대응 방식을 특징으로 하고 있음.\n:- {node, task-type, bottleneck-risk-score} tuple로 구성되는 Bottleneck History Record (BHR) 정보에 기반하여 해당 task-type에 대해 bottleneck-risk-score 값이 가장 작은 node에 replica data를 배치하는 방식임\n:- {node, task-type}에 대한 bottleneck-risk-score 정보는 JobTracker에 추가되는 Bottleneck History Record Manager 모듈에 의해 update됨\n:- 참고로, 기존 HDFS에서의 data placement (replica management 시)에서는 이러한 straggler-immune data placement는 고려되어 있지 않음.\n\n\n* 기대 효과\n:- speculative execution을 위한 data copy overhead 감소\n:- 제2, 제3의 straggler / failure 발생 확률 감소\n:- 결과적으로, Hadoop MapReduce Job의 성능 향상 효과\n\n\n* 구현의 용이성\n:- Apache Jira HDFS-385에서 언급된 pluggable interface를 이용 시, 본 발명에서 제안하는 data placement 알고리즘을 HDFS의 block placement algorithm으로 추가하기가 용이함.\n\n\n* 침해 적발의 용이성\n:- namenode에서 수집하는 데이터들을 관찰하거나, HDFS-385 interface를 통해 오가는 데이터들을 관찰하였을 때, node, task-type, failure rate 정보를 namenode가 (혹은 pluggable data placement module이) 읽어들이고, 그 중 가장 failure rate 값이 낮은 하나의 node가 replica data를 저장하기 위한 datanode로 선택된다면, 본 특허를 침해한 것으로 판단 가능.\n\n\n----\n\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n\n\n* 기존처럼 straggler가 발생한 후에 대응하기 보다는 (사후 대응), HDFS에 처음 data가 놓여질 때부터 straggler-immune node에 배치될 수 있도록 하는 사전 대응 방식을 특징으로 하고 있음.\n\n\n* {node, task-type, failure rate} tuple 정보에 기반하여 해당 task-type에 대해 failure rate이 최소화 될 수 있는 node에 replica data를 배치하는 방식임\n\n\n==== 시스템 구성 요소 ====\n\n\n==== 처리 절차 ====\n\n\n==== 예상 효과 ====\n\n* Anomaly (straggler, failed task) 발생 자체를 줄임으로써, Straggler 혹은 Failed Task로 인해 야기되는 추가 처리 비용을 감소시킬 수 있음.\n\n* Straggler의 경우, speculative execution으로 야기되는 additional data copy overhead 감소 (사라지거나 감소됨) 효과를 기대할 수 있음. 특히, HDFS block size가 큰 경우 (처리 해야 할 data는 크지만, node의 수가 적은 경우, 64MB 이상으로 tuning하여 사용하는 경우가 많이 있음 - 그런데, 실제로 이렇게 tuning하면 어떤 장점/효과가 얼만큼 생기나?) additional data copy로 인한 overhead가 그만큼 커지게 되므로, 이 경우 straggler 발생 확률을 낮춤으로써 얻는 이득 역시 그만큼 커지게 됨.\n\n* Failed task의 경우, 상황에 따라서 두 가지 처리 옵션이 있다. 첫 번째 옵션은 failure가 발생했던 해당 node에서 task를 재시작하는 방법이며, 두 번째 옵션은 다른 node에서 task를 재시작하는 방법임.\n\n* Task failure의 원인이 해당 node의 H/W 혹은 S/W에 문제가 있는 것이 아니었다면 첫 번째 옵션을 택할 수 있다. 물론 H/W 혹은 시스템 S/W 결함이 아니었다는 것을 알수 있었어야 한다. 그러나 해당 node의 H/W 혹은 S/W에 문제가 있다는 것을 알고 있는데, 당장 다른 node의 execution slot도 여유가 없는 상황이라면, execution slot이 생길 때까지 좀 더 기다렸다가 재시작을 해야 한다. 이때, 기다려야만 하는 경우라면, 그만큼 job 처리 속도의 저하로 이어진다. 다른 노드에서 재시작을 하게 되더라도, 역시 additional data copy가 필요하며, 이로 인한 overhead는 피할 수 없다.\n\n\n----\n\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n\n* Google patent search (2 results, no relevant result)\n (HDFS OR \"hadoop distributed file system\") (((block replica) OR data) placement) (straggler OR fail*)\n\n* Google patent search (2 results, no relevant result)\n (HDFS OR \"hadoop distributed file system\") (((block replica) OR data) placement) bottleneck\n\n* Google patent search (5 results)\n HDFS block replica placement\n:- [http://www.google.com/patents/EP2288998A2?cl=en Directed placement of data in a redundant data storage system]\n:: Filed 9 Apr 2009 - Published 2 Mar 2011, John Howe - Omneon, Inc.\n\n\n\n* 검색식\n: mapreduce straggler (\"historical record\" OR \"history\")\n: 2건\n\n:* System and Method for Analyzing Data Records\n:: [http://www.google.com/patents/US20120215787 www.google.com/patents/US20120215787]\n:: App. - Filed 28 Feb 2012 - Published 23 Aug 2012 - Jeffrey Dean - Dean Jeffrey, Dorward Sean M, Ghemawat Sanjay, Pike Robert C, Quinlan Sean\n\n:* Scalable user clustering based on set similarity\n:: [http://www.google.com/patents/US7962529 www.google.com/patents/US7962529]\n:: Grant - Filed 6 May 2010 - Issued 14 Jun 2011 - Mayur Datar - Google Inc.\n\n=== # Memo / Questions ===\n\n==== References ====\n\n\n\n* Google search\n map reduce straggler study\n\n:- [http://static.usenix.org/event/osdi08/tech/full_papers/zaharia/zaharia_html/ Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]\n:: Matei Zaharia, Andy Konwinski, Anthony D. Joseph, Randy Katz, Ion Stoica // University of California, Berkeley\n\n:- [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CDAQFjAA&url=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2FUM%2Fpeople%2Fsrikanth%2Fdata%2FCombating%2520Outliers%2520in%2520Map-Reduce.web.pptx&ei=pq1iUer9NK6eiAfN2IHYBQ&usg=AFQjCNEOOEtTE2_nVb6f2qQN09OpoLcS5A&sig2=HakGM53pMqVB1y2PqhQZJQ Combating Outliers in Map-Reduce - Microsoft Research]\n:: Srikanth Kandula, Ganesh Ananthanarayanan, Albert Greenberg, Ion Stoica, Yi Lu, Bikas Saha, Ed Harris\n\n\n* Google search\n map reduce straggler study once relationship\n\n:- [http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]\n:: Soila Kavulya, Jiaqi Tan, Rajeev Gandhi and Priya Narasimhan. Carnegie Mellon Univ., Pittsburgh, PA, USA\n:: [http://www.pdl.cs.cmu.edu/PDL-FTP/associated/CMU-PDL-09-107.pdf Another Version, CMU-PDL-09-107 December 2009]\n:: [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster, CCGrid 2010]]\n\n:- [http://cseweb.ucsd.edu/~vahdat/papers/themis_socc12.pdf Themis: An I/O-Efﬁcient MapReduce // SOCC 2012]\n\n\n\n\n<br/>\n\n== PATENT-BRIAN-2013-007 ==\n\n=== data와 IO insight을 packaging 하는 기술 ===\n\n: 해당 [[data에 대한 IO pattern/insight 정보]]를 data와 함께 packaging하여 (마치 object-oriented manner) 같이 이동되게 함으로써, replication, migration, (node 간 tiering?) 등 분산 환경에서 data가 여러 노드로 이동하는 경우에도 해당 data에 대한 처리가 최적으로 이루어질 수 있도록 하는 기술\n: data에 대한 IO insight 정보로서 다음 정보가 포함될 수 있다\n\n:* data access patterns:\n::- 어떤 application이 얼마나 자주 이 data를 access하는지? (이 data를 access하는 application에 대한 정보가 없으면 insight가 잘못 적용될 수도 있을지도 모른다 - Hadoop 같은 경우는 어떻게 MapReduce Application 정보를 알 수 있을까? 혹시 MapReduce application에 대한 정보가 Hadoop layer에 가려지는 것은 아닐까? JobTracker/TaskTracker를 고려해야 할까?)\n::- 이 데이터(파일?)는 Rd(Read)-intensive 인가? Wr(write)-intensive인가?\n::- 이 데이터는 RRd(random read) / RWr(random write) / SRd(sequential read) / SWr(sequential write) 중 어느 것이 dominant한가? 혹은 Mix 되어 있다면 그 비율은 어떻게 되는가?\n\n:* data간 access pattern 연관성\n::- 이 data가 access되고 나면 어느 정도 확률로 어떤 다른 data가 access되는지?\n::- 어떤 data가 access되고 나면 어느 정도 확률로 이 data가 access되는지?\n\n:* data hot/cold history\n::- 이 data가 hot한 적이 얼마나 자주 있었나?\n::- 이 data가 hot한 시기가 어떤 패턴을 가지고 나타나는가?\n::- 한 번 hot하고 나면 이후에도 다시 hot할 가능성이 높은가?\n\n== PATENT-BRIAN-2013-005 ==\n\n=== IOWA based Proactive Data Placement 자체 특허 ===\n\n: 다양한 정보/Insight을 기반으로 Proactive하게 Data를 Placement하는 기술\n:: (Caching/Tiering in Local Case, Data Replication/Migration in Distributed Case)\n\n\n: 여기에, ML (혹은 HML까지도?)을 적용한다는 아이디어를 추가하자\n:: ML 기반의 IO Prediction\n::: ML을 통해서 예측을 한다면, 어떤어떤 정보들로부터, 어떤 예측을 해야하는 걸까?\n::: Fine-grained prediction이 말이 되는 소리인가?\n::: Coarse-grained prediction을 한다면 어느 스케일까지 fine/coarse-grained 해져야할까?\n\n\n:: ML 기반의 IO Insight (Data Placement를 위한 Macroscopic Guideline)\n::: ML을 통해서 최적의 배치를 할 수도 있는 것일까?\n:::: 가능함. 예를 들어, \"이러이러한 sign/indication을 보이는 data는 언제쯤 어떤 형태의 IO 양상을 보일 확률이 __%임\" 같은 형태의 insight이 있다면, \"이런 data는 현재 local system 뿐만 아니라 networked system의 상태도 같이 고려하여 어디에 위치시켜두는 것이 적당\" 하다는 식의 data placement를 \"proactive 하게\" 할 수 있겠음.\n::: IO Insight의 요건:\n::::# indication, as simple as possible\n::::# indication, as specific as possible\n::::# indication, efficiently traversable - corresponding indication case node들을 쉽게, 효과적으로 traversing하면서 최종 insight leaf에 도달 (Huffman code? Radix tree?)\n::::# indication, easily extensible - indication 추가 시에 변경되는 부분이 최소화될 수 있어야 함\n::: UCB study같은 형태로 나오는 것이 최선일까? 그런 형태/내용 외의 다른 것도 얻어낼 수 있을까?\n\n\n: HML이 도움이 되는 이유는 무엇일까?\n:: 굳이 HML이 아니더라도 ML 만으로도 잘 할 수 있는 범위는 어디까지일까?\n\n\n* Y1 = Proactive Data Placement\n* Y2 = Data-system-optimal Placement\n\n: Y1.x1 = 어느 address의 데이터(들)이\n:: Y1.x1.1 = 그 데이터들은 sequential access가 가능한 형태로 배열되어 있는가? (만약 그렇다면 굳이 cache시킬 필요가 있을까? 혹시 있는 건 아닐까? 정말 없을까? Sequential read하는 경우 SSD case와 HDD case를 비교해볼 필요 있음)\n:: Y1.x1.2 = 그 데이터들이 access되고 나면, ___%의 확률로 따라서 access되는 데이터들도 있지 않을까? (그렇다면, 그 놈들도 연달아서 미리 loading?)\n: Y1.x2 = 앞으로 얼마 후에\n: Y1.x3 = Access될 것인가?\n:: Y1.x3.1 = Read일까? Write일까?\n:: Y1.x3.2 = 그 얼마 후 Access되고 나서 몇 번을 더 Access될까? (이것을 알 수 있을까?)\n\n\n* X1 = IO Access Pattern\n* X2 = IO 유발자 정보\n\n\n\n\n\n\n\nproactive data placement (caching/tiering)를 위해서, layer abstraction 혹은 virtualization이 필요하지는 않을까?\n- 예를 들어, IBM의 GPFS에서 AFM (Active File Management)을 구현할 때, data의 lifecycle 및 next use에 의거한 automatic data transfer를 위해서, 기존에는 없었던 새로운 component 혹은 새로운 layer가 필요하지는 않았을까? [1][2]\n- proactive data placement 입장에서는, next IO use를 예측하거나, user/process context를 이해한다는 측면에서, 오히려 block layer보다는 file system layer에서 바라보는 것이 더욱 적절한 것은 아닐까?\nRead cache, write cache colocation을 하면 어떨까?\nadvanced tiering: access pattern-aware optimal placement (APOP)\n\n== PATENT-BRIAN-2013-006 ==\n\n=== SSD Retention Time Controlling for Caching/Tiering 특허 ===\n\n* Caching-optimal SSD Retention Time Control\n* SSD Retention Time Controlling for Caching\n\nCache-I/O의 특성에 맞도록 SSD Retention Time을 Control하는 기술.\n\n== PATENT-BRIAN-2013-XXX ==\n\n=== State Machine based Macro IO Prediction ===\n\n== PATENT-BRIAN-2013-00X ==\n\n=== Coarse-grained Spatial Locality Based SSD Cache I/O ===\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* DRAM Cache의 부족한 용량을 극복하기 위한 솔루션으로 SSD Cache가 도입되고 있음. 기본 원리는 자주 액세스되는 디스크 블록을 SSD에 Caching함으로써 HDD의 느린 I/O 속도를 극복하도록 하는 것임.\n* 그러나 블록 레이어에 구현되는 SSD Cache의 경우, Kernel에서 관리하는 Page Cache에 의해 이미 Hot data가 Serve되고 있기 때문에, Hit Ratio를 높이기에 근본적인 한계점을 가지고 있음.\n* 한편, kernel에서 관리되는 기존 Page Cache는 다음과 같은 한계점을 가지고 있음. (1) SSD 혹은 HDD에 비해 비싼 스토리지인 RAM 기반이기 때문에 다른 스토리지에 비해 작은 용량을 가지고 있는 경우가 일반적이므로 cache로 사용할 수 있는 공간의 제약이 큼. (2) 시스템에서 사용되지 않고 있는 idle RAM 영역을 이용하기 때문에, 시스템에서 구동되는 프로세스들이 요구하는 RAM 요구량이 많아지게 되면, 그만큼 page cache가 버려지게 되며 그만큼 시스템 I/O 성능의 저하가 발생하게 됨. 또한 이로 인해 성능의 편차가 불규칙하다는 단점 또한 근본적으로 가지고 있음.\n* 한편, SSD를 이용하는 page cache가 기존에 시도된 적이 있으나 매 page access 시마다 SSD에 page를 저장하는 메커니즘으로서 (synchronous I/O) NAND flash와 RAM I/O 특성 차이로 인해 기인하는 근본적인 성능적 한계점을 가지고 있음.\n\n<br/>\n\n\n=== # 본 발명의 특징 / 효과 ===\n\n\n=== # 대표 청구항 ===\n\n* (page tiering 기반의 hybrid cache에서) spatial locality에 기반한 효율적인 page cache I/O 방법\n** 고속이면서도 자원 효율적으로 spatial locality 패턴을 파악하는 방법\n***(range size를 동적으로, 혹은 서로 다르게 할 수 있는 방법은 필요 없을까?)\n\n* page chunk handling 방법\n** [host side] spatial-locality가 있는 page들이 가급적 page chunk 단위로 묶이도록 하는 방법\n** [host side] SSD 내부의 parallelism을 극대화할 수 있도록 page chunk 크기를 정하는 방법 (i.e., channel_# x erase_block_size)\n** [host side / ssd side] tier-2 page cache에 저장된 특정 page가 access될 때, 그 page가 속한 page chunk의 데이터를 같이 pre-loading 하는 방법\n*** 해당 page chunk에 대한 status update하는 것이 필요할까?\n\n* page chunk eviction 방법\n** [ssd side] tier-2 page cache에서 page chunk를 eviction 시키기 전에, page chunk 중에서 popular 한 page는 SSD에서 evict하기 전에 RAM에 올리는 것\n\n\n=== # 기술 상세 ===\n\n=== # 선행 기술 ===\n\n다음 검색식\n (Spatial locality based I/O SSD cache)\n으로 1건의 미국 공개/등록 문건을 검색할 수 있었으나,\n본 발명과 유사한 spatial locality based I/O for SSD cache 관련 선행 기술은 발견하지 못하였음.\n\n유사한 주제를 다루는 논문으로\n __\n이 있었음.\n\n그러나 __ 측면에서 본 발명과 상이함.\n\n<br/>\n\n\n=== # 침해 적발 ===\n\n== PATENT-BRIAN-2013-00X ==\nContent Repeatability-Aware SSD Cache Management\n\n=== 대표 청구항 ===\n\n== PATENT-BRIAN-2013-00X ==\n=== Likely Zone Based Page Pre-placement ===\n\n\n* periodicity의 특성을 이용해 pre-placement하는 개념도 추가할 수 있을까?\n\n* associated-likely-zone 기반의 page pre-placement (to RAM)\n\n* page cache tiering의 방향이 RAM으로부터 SSD로 가는 경우는 page eviction 시 class-2에 해당하는 page들을 SSD로 저장하는 경우임. page cache tiering의 방향이 SSD로부터 RAM으로 가는 경우는 class-1의 “currently-hot”한 page들과 매칭되는 associated-likely-zone이 존재하고, 동시에 현재 시스템에 page cache로 사용할 수 있는 RAM의 여유 공간이 존재할 때, SSD에 저장되어 있었던 해당 associated-likely-zone을 RAM에 미리 올리는 경우임. page cache로 사용할 수 있는 RAM의 여유 공간보다 associated-likely-zone의 크기가 큰 경우에는 RAM의 여유 공간 만큼만 우선적으로 RAM에 올려짐.\n\n* 이때, associated-likely-zone 중에서 우선적으로 RAM에 올려져야 할 영역을 결정하는 방법으로써, “currently-hot”한 현재 data와 지리적으로 가까운 영역의 data를 우선적으로 선택하는 방법, associated-likely-zone의 data들 중에서 access frequency가 높았던 data들을 우선적으로 선택하는 방법 등을 사용할 수 있다. 이에 대한 구체적인 방식은 본 특허와 개별적으로 구현될 수 있으므로, 별도의 특허에서 다루어진다.\n\n* associated-likely-zone은 과거의 access 패턴에 기반하여 서로 비슷한 시간대에 access되었던 data들의 set으로 구성한다. 여기서 ‘서로 비슷한 시간대’라는 개념은 window 2의 window size에 의해 결정된다.\n\n* 특정 address arange가 LZ인지, ULZ인지 구분하는 방법?\nLZ (Likely Zone)와 ULZ (Unlikely Zone)을 선정하는 방법:\naccess되는 page를 보면, 해당되는 inode정보와 이를 access한 process 정보를 알 수 있다. inode 정보를 보면, 이 page가 어떤 파일에 연결되어있는지를 알 수 있다. 이렇게 되면 그 파일이 걸쳐있는 address space 정보 (LBA range)를 알 수 있으며, 이는 likely zone의 일부로 마킹될 수 있다. 여기서 해당 파일 전체를 likely zone으로 할 것인지 해당 파일의 일부를 likely zone으로 할 것인지는 별도의 likely zone determinition rule에 의해 결정된다. 그리고 likely zone으로 마킹된 영역을 언제 class-2 t2 page cache media (e.g., SSD)에 loading할 것인지, loading한다면 likely zone 영역의 데이터들을 어떤 순서로 읽어들일지는 likely-zond loading rule에 의거하여 결정된다. LZ과 ULZ를 선정하는 빈도/시기는\n\n== PATENT-BRIAN-2013-00X ==\n\n* 하나 이상의 SSD를 Page Cache Media로 사용하는 경우, (1) SSD array manager와 연계하여 보다 효율적인 caching I/O를 달성하는 방법 (RACS 기반의 기존 SAVL을 그대로 이용하되 interfacing에 관련된 내용), 혹은 (2) 복수개의 SSD를 caching I/O에 맞도록 coordination하는 방법 (RACS 기반의 기존 SAVL에 추가적으로 caching I/O를 잘 handling할 수 있도록 하는 최적화된 I/O management 방법)\n\n\n* 복수 개의 SSD를 tier-2 page cache media로 사용하는 경우, SSD 1에 free space가 부족한데, 그 SSD 내에 cache되어 있는 page chunk들이 계속 caching해둘만한 가치가 있는 경우, page chunk migration (between SSDs)을 수행한다. 이때, tier-1 page cache 내의 page node 내의 page data location field 값은 update한다. (이때, 누가 migration을 initiation하는 것이 적절할까? host의 hybrid page cache manager? 혹은 activie SSD? 아무래도 SATA 기반의 SSD를 사용하는 경우에는 전자가 좀 더 현실적일 것으로 보임)\n\n\n* tier-2 page cache의 eviction threshold period를 두어서 RAM page cache 경우보다는 길겠지만 tier-2 page cache의 총량이 허용할 수 있는 page 용량을 감안하여 계산된 time period 동안 access 실적이 없으면 tier-2 page cache 중에서도 evictable flag를 set하게 되는데, 이때 복수개의 SSD를 tier-2 page cache media로 사용하는 경우, 전체 SSD 가용 용량을 합산해야 한다.\n\n== PATENT-BRIAN-2013-00X ==\nMultiple I/O Queue Handling for SSD Cache\n\n\n[청구항]\n\n== PATENT-BRIAN-2013-00X ==\npage chunk I/O handling mechanism for multi-tenancy SSD page cache\n\n\n[요약]\n물리적인 SSD 하나가 통째로 page cache로 사용되는 경우에는 SSD 전체를 위와 같이 나누어 사용하면 되겠으나, 하나의 SSD를 page cache media와 다른 용도로 같이 사용해야 하는 경우를 위한 구조 및 방법은 별도의 특허에서 기술하는 것으로 함. page cache media로 사용되는 공간과 다른 목적으로 사용될 공간을 별도의 partition으로 잡고, page cache media로 동작하기 위한 partition을 다시 meta 정보 영역과 page data 영역으로 slice하여 사용함. 이때, SSD는 page cache media로 partitioning된 영역에 해당하는 I/O에 대해서는 병렬성과 page chunk lookup table의 단순성을 극대화 할 수 있게 설계된 page chunk I/O 방식으로 처리할 수 있도록 하는 것이 필요함.\n\n[청구항]\n\n\n== PATENT-BRIAN-2013-00X ==\n\n=== # I/O Pattern-optimal Data Placement for Tiering ===\n\n* Automatic tiering 시, 단순히 hot data들을 fast media에 가져다 놓고 마는 것이 아니라, IO bottleneck이 미연에 방지될 수 있도록 data의 access pattern을 aware해서 차별적으로 배치하는 방법\n예) (a) random-read-intensive 한 data들, (b) sequential-write-intensive한 data들을 다른 방식으로 배치 (tiering)\n\n\n* 이에 필요한 data access pattern 모니터링/분석 방법\n데이터 수집 및 분석 시 PCIe 카드 엔진 활용 가능?\nNIC 이나 DMA를 통해서 data move가 일어나는 경우, PCIe 카드 등을 통해서 IO stream 분석\n\n\n* 이를 위해 필요한 system architecture 구조\n기본적으로 하나 이상의 SSD와 하나 이상의 HDD, 그리고 PCIe 카드, DRAM 일부 사용 방식, Tiering Mapping Table 구조, ...\n\n\n=== # 발명의 이용분야 ===\n=== # 배경 / 기존 기술의 문제점 ===\n=== # 본 발명의 특징 / 효과 ===\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n=== # Memo / Questions ===\n\n\n<br/>\n\n\n\n== Patent pool ==\n\n=== (Tiering-based?) Proactive Data Placement ===\n* 핵심 아이디어\n: \"proactive\" 하게 data를 배치시킨다는 것 자체!\n: Local node 내에서의 vertical tiering 뿐만 아니라 분산 node들 간의 horizontal tiering도 염두에 둘 것\n\n* 경쟁 기술과의 차별화\n: EMC의 FAST 기술이 안고 있는 근본적인 한계점은 무엇일까?\n: data access 패턴의 hot/cold 만 분류해서 hot은 fast tier에, cold는 slow tier에 두는 것이 전부인가? 아니면 그것 외에 뭔가가 더 있는가?\n: 어떻게 보면 기존의 automated storage tiering은 naive proactive placement로 볼 수도 있다. (과거에 자주 access되었던 data가 앞으로도 자주 access될 것이라고 믿고 data를 이동시키는 것이므로. 그러나 근거가 부족함)\n:: 이러한 naive proactive placement 방식으로 야기되는 단점이 있다. 만약 과거에는 자주 access되었는데 마침 tiering되고 난 후에 자주 access되지 않게 되면, 괜히 SSD의 wear-out만 유발시킨 결과가 된다. 다음 tiering 주기가 돌아오기 전 까지는 계속 느린 media에서 I/O가 serve되기 때문에 그만큼 pain이 된다.\n:: 물론 read에 대해서는 cache를 적극 활용함으로써 첫 access 시에만 slow media access로 인한 penalty를 얻고 이후에는 cache가 제공하는 수준의 성능을 얻을 수 있게 된다.\n:: 그러나 write에 대해서는 문제가 다르다. HDD의 경우 sequential write 경우에는 큰 문제가 되지 않는다. 그러나 random write 특성을 가지고 있으며, 게다가 write-intensive한 I/O라면? 그런데 random write이면서 write-intensive한 경우, write되는 address range가 생각보다 넓지 않다면 어떻게 될까? 즉 특정 구간 특정 데이터에 대한 update가 빈번한 것을 의미한다.\n:: write address range가 N개의 4KB 블럭으로 이루어져 있고, Storage System 내에 물리적인 Disk 갯수가 M개 존재한다고 가정하자. 만약 M이 N보다 적절하게 커서 RAID 10을 하건, RAID 5 등으로 이루어져 있건 간데, N개의 4KB 블럭을 각각 별도의 HDD로 분산 시킴으로써 random write을 random write이 아닌 것처럼 보이게 할 수 있다면? 예를 들어 VNX 5300 처럼 SAN 박스 하나 내에 HDD가 125개가 들어있고, random하고 intensive한 write pattern이 오고 있고, write access range가 125개 이하의 address 내에서 반복되고 있다면, 매번 도달하는 random write request를 마치 RAID 0로 striping 하듯이 계속 다른 HDD로 보냄으로써 I/O de-randomization을 할 수 있을 것이다. 여기서 좀 더 나아가서 하나의 request에 대해서 HDD가 완벽하게 처리하는 데에 걸리는 시간이 10ms 이고, 매 random I/O가 도달하는 평균 시간은 (평균 가지고 되려나? 아무튼 이것은 조금 뒤에 다시 생각해보자) 1ms 라고 한다면, 이론적으로 10번의 random I/O가 지난 다음, 11번째의 random I/O가 올 때에는 처음에 write했던 HDD에다가 다시 write을 해도 된다. 즉, 그 HDD에서 직전의 I/O가 끝나기를 기다리고 있지 않아도 된다는 것이다. 그러나 이러한 방식은 나중에 scatter했던 I/O들을 다시 불러모으려고 할 때 contribution한 HDD가 다른 I/O를 serving하고 있지 않을 수 있어야 최고의 성능을 낼 수 있게 된다. 즉, HDD cluster 구성을 상당히 dynamic하게 가져갈 수 있다면 어떨까? 이러한 dynamic clustering이 정말 최고의 효과를 낼 수 있는 workload case로는 어떤 것이 있을까? data placement를 함에 있어서 결국은 어딘가에 써야 할 것이고, (slow tier로 마크된 HDD들 array에다가 data를 쓴다고 그냥 푸대접하면서 써버릴 것이 아니다) slow tier에다가 쓸 때에도 나중에 어떻게 read되고 다시 write 될 지를 고려한다면, workload 특성에 따라서 concurrent I/O의 갯수 및 address range 크기가 다를 수 있는데, 그것을 aware해서 write을 해둔다면, 비록 slow-tier에다가 write했지만, 그리 slow하지만은 않은 성능을 내게 할 수 도 있을 것이다. 이것은 proactive data placement에 대한 이야기가 아니다. proactive와는 별개로, automated storage tiering을 함에 있어서 workload characteristics를 고려한 data placement에 대한 이야기이다.\n\n\n\n\n서로 독립적인 I/O stream의 갯수가 100개 라면 (즉 100개의 process가 I/O를 쏟아내고 있는 경우), 그리고 I/O queue의 크기가 N_Q라면, 어떻게 이러한 문제를 해결할 수 있을까?  \n\n  \n:: write에 대해서는 \n:: write-intensive하다는 것의 정의는? 이러한 경우에는 in-memory write caching (OS가 허용하는 범위의 delayed write을 최대한 활용)을 이용하되 transaction 기반으 atomicity를 보장함으로써 문제를 부분적으로 해결할 수 있다. transaction으로 묶여질 수 있는 여러 번의 I/O request (write)가 끝나기 전까지는 commit되지 않은 것으로 치는 것임. Fusion IO의 atomic write은 이를 어떻게 해결하는지? \n\n만약 write commit이 매우 중요한 민감한 데이터에 대해서는 어떻게 해야할까? 그리고 SSD-internal memory buffer를 이용해서\n: SAN 장비 내에서의 HDD와 SSD 간의 tiering만 되는 것일까? (vertical tiering within local node)\n: SAN 장비 간의 tiering이 되기 위해서는 어떤 것이 더 필요할까? EMC에서 이미 그러한 기술/솔루션을 가지고 있지는 않을까? (horizontal tiering between boxes)\n\n* 다양한 사례\n: 기존에 이미 생성되어 있던 data를 미래 access 예측에 따라 위치 변동을 시키는 경우\n: Tiering을 한다고 했을 때, access 빈도에 따라서 fast tier / slow tier 간 이동시키는 것이 전부일까? 그런 것 말고 다른 차원의 tiering은 없을까?\n: 새롭게 write되려는 data를 처음부터 어디에 배치시키는 것이 좋을까?\n\n* Placement 접근 방식\n: Tiering으로 한정?\n: Tiering과 Caching과의 결합 방식? (Caching engine에게 hint를 주는 방식)\n\n* I/O Prediction 결과를 받아서 proactive하게 data를 tiering 시키는 방법 및 아키텍쳐\n* Key questions\n:- 기존엔 proactive tiering이 없었나?\n:- 만약 없었다면 어떤 어떤 부분들을 청구항으로 넣어야 할까?\n:- 만약 있었다면 어떤 차별화가 필요할까?\n\n=== I/O Workload Analyzer Engine ===\n* I/O Trace 및 다양한 시스템 정보를 기반으로 I/O를 prediction하는 방법 및 구조\n* \n\n\n== Disclosure of Invention :: Template ==\n\n<!--\n== PATENT-BRIAN-2013-00X ==\n-->\n\n=== # RAM-SSD Hybrid Page Cache Architecture ===\n=== # 발명의 이용분야 ===\n=== # 배경 / 기존 기술의 문제점 ===\n=== # 본 발명의 특징 / 효과 ===\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n=== # Memo / Questions ===','utf-8'),(1952,'\n=== # 요약 ===\n\n* 본 발명은 Hadoop MapReduce 기반의 분산 병렬 시스템의 성능 향상을 위해 이용할 수 있는 맵리듀스 작업의 병목 탐지 및 원인 분석을 위한 모니터링 프레임워크 기술에 대한 것임.\n\n\n\n* \"MapReduce의 병목 탐지 및 원인 분석을 위한 모니터링 프레임워크\" 로서,\n: 시스템 리소스 사용량, Hadoop 상태 정보, I/O 패턴, Straggler 정보 등의\n: 다계층 정보 모니터링 및 학습을 통해 주요 병목 요인을 자동 판별케 함\n\n\n* 맵리듀스 작업에서 병목 탐지 및 자동적인 원인 분석을 위한 모니터링 프레임워크 기술로서,\n: 맵리듀스 각 노드의 시스템 리소스 사용량, Hadoop 상태 정보, I/O 패턴, Straggler 정보 등의 모니터링 및 학습을 통해,\n: Straggler 태스크 탐지 시 해당 태스크의 실시간 모니터링 정보를 기존 학습 결과와 연계 분석하여,\n: 성능 저하와 깊은 연관을 보이는 요소를 판단케 하는 방법 및 시스템 구조.\n\n\n* Question\n: 연계 분석 시, 실시간 분석이 가능한지? 어느 정도의 데이터에 대해 시간이 얼마나 걸렸는지?\n\n=== # 발명의 이용분야 ===\n\n* Hadoop MapReduce 기반의 분산 병렬 시스템 (Enterprise, Cloud 등 Data Center)\n\n\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* 본 발명이 속하는 기술 분야는 맵리듀스 작업을 위한 성능 모니터링 기술이다. 대용량 데이터 처리를 위한 맵리듀스 작업에서는 대량의 컴퓨팅 리소스를 이용하여 신속하게 작업을 처리하기 위해 하나의 작업을 다수의 태스크로 나누어 실행하게 된다. 이 때, 하나의 태스크라도 느려지게 되면 그를 제외한 태스크들이 해당 태스크의 수행 완료 시까지 대기해야 하므로 지연 태스크를 탐지해내는 일은 맵리듀스 작업의 효율성을 위해 매우 중요하다. \n\n* 기존의 모니터링 기술은 CPU나 메모리와 같은 리소스 사용량을 모니터링하여 병목 노드를 탐지해냈다. 그러나 이는 일반적이고 개략적인 정보로서, 이 정보만으로 맵리듀스 작업에서의 병목을 일으키는 태스크를 탐지해내고 원인을 분석해내기에는 정확도가 매우 떨어진다. 따라서 본 발명은 기존 기술과의 차별화를 위해 모니터링 대상을 다각적으로 분석하여 확장함으로써 병목 원인 분석 및 병목 태스크 탐지의 정확도를 향상시켰다.\n\n=== # 본 발명의 특징 / 효과 ===\n\n* 발명 기술에서는 맵리듀스 작업을 실행중인 각 노드에 대해 리소스 사용량, 하둡 설정 값, 그리고 I/O 특성의 계층적 정보를 모니터링한다. 지연되는 태스크가 발생하면 해당 태스크의 I/O 특성을 추출한 후, 리소스 사용량 및 하둡 설정 값과 같은 상위 수준의 정보와 연계 분석하여 병목 원인 정보를 사용자에게 제공한다.\n\n* 모든 단계의 모니터링 및 분석 정보를 자동화하여 사용자에게 제공하기 위해서는 계층적 정보들 중 성능 저하와 깊은 연관을 보이는 특정 리소스를 탐지하는 것이 중요하다. 즉, 병목이 발생한 노드의 리소스 사용률, 병목을 일으킨 작업의 하둡 환경, 그리고 병목을 일으킨 태스크의 I/O 특성 정보는기계 학습 기법을 통해 병목이 발생한 것으로 예측되는 태스크를 탐지할 수 있으며, 기계에 의해 자동적으로 사용자에게 제공되는 메커니즘을 구성할 수 있다. 이 때의 메커니즘은 I/O intensive한 곳을 알아내기 위해 전체 모니터링 parameter들 중에서 비정상적인 결과를 나타내는 리소스 특성을 효과적으로 선정할 수 있어야 한다. 사용자들은 이러한 분석 결과를 통해 하둡 설정을 변경하는 것이 효율적일지 혹은 리소스가 충분한 다른 노드에서 실행시키는 것이 효율적일지 결정할 수 있게 된다.\n\n=== # 대표 청구항 ===\n\n\n* 맵리듀스 작업에서 병목 탐지 및 자동적인 원인 분석을 위한 모니터링 프레임워크 기술로서,\n: 맵리듀스 작업을 실행중인 각 노드에 대해 리소스 사용량, 하둡 설정 값, 그리고 I/O 특성의 계층적 정보를 모니터링하여, 지연되는 태스크가 발생하면 자동적으로 해당 태스크의 I/O 특성을 추출한 후, 리소스 사용량 및 하둡 설정 값과 같은 상위 수준의 정보와 연계하여 분석하여 성능 저하와 깊은 연관을 보이는 요소를 탐지할 수 있게 하는 방법 및 시스템 구조\n\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n\n* 특허 검색 결과\n: Hadoop MapReduce I/O bottleneck\n: 44 results @ Google Patent Search\n\n\n* 논문 검색 결과\n:* MROrchestrator: A Fine-grained Resource Orchestration Framework for Hadoop MapReduce (IEEE ICCC 2012)\n::- [http://www.cse.psu.edu/research/publications/tech-reports/2012/CSE%20-12-001.pdf Paper @ psu.edu]\n::- [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6253482 Paper @ IEEE Xplore]\n \n:* Predicting Execution Bottlenecks in Map-Reduce Clusters (HotCloud 2012)\n::- [https://www.usenix.org/conference/hotcloud12/predicting-execution-bottlenecks-map-reduce-clusters Paper home @ USENIX HotCloud 2012]\n\n:* Theius: A Streaming Visualization Suite for Hadoop Clusters\n::- [https://wiki.engr.illinois.edu/download/attachments/195766887/JAR-3rd.pdf?version=1&modificationDate=1336558393000 Paper @ illinois.edu]\n\n=== # Memo / Questions ===\n\n\n==== References ====\n\n* [https://www.usenix.org/conference/hotcloud12/predicting-execution-bottlenecks-map-reduce-clusters Predicting Execution Bottlenecks in Map-Reduce Clusters, Yahoo! Labs, USENIX HotCloud 2012]\n\n* [http://www.nagios.org/ Nagios - Industry Standard in IT Infrastructure Monitoring]\n\n* [http://en.wikipedia.org/wiki/Comparison_of_network_monitoring_systems Comparison of network monitoring systems]\n\n* [http://blogs.msdn.com/b/ntdebugging/archive/2008/04/03/windows-performance-toolkit-xperf.aspx Windows Performance Toolkit - Xperf]\n\n* [http://sqlvelocity.typepad.com/blog/2011/06/windows-io-tracing.html Windows I/O Tracing (2011-06-22)]\n\n==== 발명자 인적사항 ====\n\n <pre>\n성명: 엄현상 \n주민번호: 690721-1051717\n소속기관: 서울대학교\n소속부서: 컴퓨터공학부\n국적: 대한민국\n핸드폰번호: 016-232-4667\n유선전화번호: 02-880-6755\n이메일: hseom@cse.snu.ac.kr\n주소: 서울시 관악구 관악로 1, (봉천동 서울대교수아파트) 122H동 103호\n\n성명: 조인순 (Jo, Insoon)\n주민번호: 750608-2029511\n소속기관: 서울대학교\n소속부서: 컴퓨터공학부\n국적: 대한민국\n핸드폰번호: 010-5131-7886\n유선전화번호: x\n이메일: insoonjo@gmail.com\n주소: 서울시 관악구 낙성대동 162-12 206호\n\n성명: 성민영 (Sung, Minyoung)\n주민번호: 871114-2079919\n소속기관: 서울대학교\n소속부서: 컴퓨터공학부\n국적: 대한민국\n핸드폰번호: 010-4724-5304\n유선전화번호: 02-876-2159\n이메일: eunice.sung87@gmail.com\n주소: 서울시 송파구 방이1동 대림아파트 6동 901호\n\n</pre>','utf-8'),(1953,'== PATENT-BRIAN-2013-001 ==\n\n=== # RAM-SSD Hybrid Page Cache Architecture ===\n\n[[Bnote patidea 2013-001]]\n\n== PATENT-BRIAN-2013-002 ==\n=== # Low-computation-overhead and Memory-efficient Periodicity Detection Method ===\n[[Bnote patidea 2013-002]]\n\n== PATENT-BRIAN-2013-003 ==\n\n=== 맵리듀스 작업의 병목 탐지 및 원인 분석을 위한 모니터링 프레임워크 기술 (A monitoring framework for detecting and analyzing execution bottlenecks of MapReduce jobs) ===\n\n[[Bnote patidea 2013-003]]\n\n== PATENT-BRIAN-2013-004 ==\n\n<!-- === Straggler-immune Data/Task Placement in the Distributed Environment === -->\n\n=== Straggler-immune Data Placement in the Distributed Environment (HDFS?) ===\n\n\n\n\n=== Memo ===\n\n* title candidates\n: outlier(straggler, failure, ...)-immune data placement for distributed file system\n: straggler-immune data placement in the distributed file system (DFS)\n\n\n* Assumptions // 환경\n: replica management가 있는 DFS 환경\n: replica management algorithm 변경 가능\n: MapReduce/HDFS처럼 data가 있는 곳에 computation을 보내는 구조\n: DFS 위에서 Hadoop MapReduce처럼 분산 병렬 처리를 수행하는 환경\n\n* Assumptions // Failure Characteristics \n: straggler 발생과 task의 type 간의 연관성이 있음\n: {task type, node} tuple이 \n\nHDFS 및 MapReduce 환경에서,\n\n\n특정 node와 특정 task type의 조합과 straggler 발생 빈도 간에 연관 관계가 있을 수 있을까?\n\n\n즉 straggler가 발생했던 case를 관찰했을 때,\nnode 정보만으로는 패턴 (혹은 straggler 발생과의 연관성)이 보이지 않고,\ntask type 정보만으로도 패턴 (혹은 straggler 발생과의 연관성)이 보이지 않지만,\nnode 정보와 task type 정보를 같이 고려했을 때 straggler 발생 빈도/확률과 연관성을 볼 수 있었다면?\n\n\n\n\n* Bottleneck History Record (BHR) based approach\n: do not throw away the bottleneck experience (history). KEEP IT to use the knowledge for later use.\n\n* Replica management\n: at the very first time to place the data\nDistributed File Systems\n\n\n\n=== # 요약 ===\n\n\n=== # 발명의 이용분야 ===\n\n* Hadoop MapReduce/HDFS 혹은 이와 유사한 분산 처리 시스템이 구동되는 Enterprise 데이터 분석 클러스터.\n* Hadoop MapReduce/HDFS 혹은 이와 유사한 분산 처리 시스템이 구동되는 Public Cloud 데이터센터\n\n\n----\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* Hadoop의 기본 DFS인 HDFS (Hadoop Distributed File System)은 replica management를 수행하고 있음.\n\n\n* HDFS에서의 replica management는 3-copy replica 구성 시, 다음 몇 가지 원칙에 의해 data를 분배하고 있음.\n:- 하나의 node에 동일 block이 두 개 이상 존재하지 않는다\n:- 하나의 rack에 동일 block이 세 개 이상 존재하지 않는다\n:- 첫 번째 replica는 client가 구동하고 있는 node에 배치\n:- 두 번째 replica는 첫 번째 replica가 있던 node가 속하지 않은 다른 rack의 임의의 node에 배치\n:- 세 번째 replica는 두 번째 replica가 배치된 rack 내의 다른 node에 배치\n:- 1st-2nd-3rd replica 배치는 순차적으로 실행\n\n\n* Yahoo!의 Hadoop Cluster에서 10개월간 구동된 17만개의 MapReduce job들을 분석한 연구에 따르면 약 3% 정도의 Job들이 fail되었으며, 각 task의 특성과 failure 발생과 연관성이 있음을 확인할 수 있다. (예를 들어, MapReduce 전체 failure의 80% 이상이 map task에서 발생하였으며, map task failure의 36%는 array indexing error에 의한 것이었음. 그리고 reduce task 의 23%는 I/O exception에 의한 것이었음)  이러한 failure 및 straggler로 인해 task restart가 많이 발생하고 있으며, 이는 MapReduce/HDFS 성능을 저하시키는 주요 요인임.\n\n\n* 현존 Hadoop MapReduce/HDFS 시스템에서는 straggler가 발생했다고 판단되면, 해당 task를 drop 시키고 새로운 node에서 task가 실행될 수 있도록 하고 있음. 즉, 이미 발생한 straggler에 대해서는 speculative execution을 수행하고 있지만 여전히 한계점은 존재함. (1) speculative execution을 위해 필요한 additional data copy overhead 존재. (2) 새로운 execution node를 찾는다 하더라도 그 node가 straggler-free한 node인지 보장할 수 없기 때문에, 제2, 제3의 straggler가 발생할 가능성 존재. (3) additional copy를 하려고 하더라도 이미 task들이 tight하게 많이 구동되고 있는 상황에서, 여유 execution slot을 가지고 있는 적절한 node를 바로 찾지 못할 수 있으며, 이렇게 기다리는 것 자체가 job completion time을 증가시키는 부정적인 효과가 있음.\n\n\n----\n\n=== # 본 발명의 특징 / 효과 ===\n\n\n* 특징\n:- 기존처럼 straggler가 발생한 후에 대응하기 보다는 (사후 대응), HDFS에 처음 data가 놓여질 때부터 straggler-immune node에 배치될 수 있도록 하는 사전 대응 방식을 특징으로 하고 있음.\n:- {node, task-type, bottleneck-risk-score} tuple로 구성되는 Bottleneck History Record (BHR) 정보에 기반하여 해당 task-type에 대해 bottleneck-risk-score 값이 가장 작은 node에 replica data를 배치하는 방식임\n:- {node, task-type}에 대한 bottleneck-risk-score 정보는 JobTracker에 추가되는 Bottleneck History Record Manager 모듈에 의해 update됨\n:- 참고로, 기존 HDFS에서의 data placement (replica management 시)에서는 이러한 straggler-immune data placement는 고려되어 있지 않음.\n\n\n* 기대 효과\n:- speculative execution을 위한 data copy overhead 감소\n:- 제2, 제3의 straggler / failure 발생 확률 감소\n:- 결과적으로, Hadoop MapReduce Job의 성능 향상 효과\n\n\n* 구현의 용이성\n:- Apache Jira HDFS-385에서 언급된 pluggable interface를 이용 시, 본 발명에서 제안하는 data placement 알고리즘을 HDFS의 block placement algorithm으로 추가하기가 용이함.\n\n\n* 침해 적발의 용이성\n:- namenode에서 수집하는 데이터들을 관찰하거나, HDFS-385 interface를 통해 오가는 데이터들을 관찰하였을 때, node, task-type, failure rate 정보를 namenode가 (혹은 pluggable data placement module이) 읽어들이고, 그 중 가장 failure rate 값이 낮은 하나의 node가 replica data를 저장하기 위한 datanode로 선택된다면, 본 특허를 침해한 것으로 판단 가능.\n\n\n----\n\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n\n\n* 기존처럼 straggler가 발생한 후에 대응하기 보다는 (사후 대응), HDFS에 처음 data가 놓여질 때부터 straggler-immune node에 배치될 수 있도록 하는 사전 대응 방식을 특징으로 하고 있음.\n\n\n* {node, task-type, failure rate} tuple 정보에 기반하여 해당 task-type에 대해 failure rate이 최소화 될 수 있는 node에 replica data를 배치하는 방식임\n\n\n==== 시스템 구성 요소 ====\n\n\n==== 처리 절차 ====\n\n\n==== 예상 효과 ====\n\n* Anomaly (straggler, failed task) 발생 자체를 줄임으로써, Straggler 혹은 Failed Task로 인해 야기되는 추가 처리 비용을 감소시킬 수 있음.\n\n* Straggler의 경우, speculative execution으로 야기되는 additional data copy overhead 감소 (사라지거나 감소됨) 효과를 기대할 수 있음. 특히, HDFS block size가 큰 경우 (처리 해야 할 data는 크지만, node의 수가 적은 경우, 64MB 이상으로 tuning하여 사용하는 경우가 많이 있음 - 그런데, 실제로 이렇게 tuning하면 어떤 장점/효과가 얼만큼 생기나?) additional data copy로 인한 overhead가 그만큼 커지게 되므로, 이 경우 straggler 발생 확률을 낮춤으로써 얻는 이득 역시 그만큼 커지게 됨.\n\n* Failed task의 경우, 상황에 따라서 두 가지 처리 옵션이 있다. 첫 번째 옵션은 failure가 발생했던 해당 node에서 task를 재시작하는 방법이며, 두 번째 옵션은 다른 node에서 task를 재시작하는 방법임.\n\n* Task failure의 원인이 해당 node의 H/W 혹은 S/W에 문제가 있는 것이 아니었다면 첫 번째 옵션을 택할 수 있다. 물론 H/W 혹은 시스템 S/W 결함이 아니었다는 것을 알수 있었어야 한다. 그러나 해당 node의 H/W 혹은 S/W에 문제가 있다는 것을 알고 있는데, 당장 다른 node의 execution slot도 여유가 없는 상황이라면, execution slot이 생길 때까지 좀 더 기다렸다가 재시작을 해야 한다. 이때, 기다려야만 하는 경우라면, 그만큼 job 처리 속도의 저하로 이어진다. 다른 노드에서 재시작을 하게 되더라도, 역시 additional data copy가 필요하며, 이로 인한 overhead는 피할 수 없다.\n\n\n----\n\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n\n* Google patent search (2 results, no relevant result)\n (HDFS OR \"hadoop distributed file system\") (((block replica) OR data) placement) (straggler OR fail*)\n\n* Google patent search (2 results, no relevant result)\n (HDFS OR \"hadoop distributed file system\") (((block replica) OR data) placement) bottleneck\n\n* Google patent search (5 results)\n HDFS block replica placement\n:- [http://www.google.com/patents/EP2288998A2?cl=en Directed placement of data in a redundant data storage system]\n:: Filed 9 Apr 2009 - Published 2 Mar 2011, John Howe - Omneon, Inc.\n\n\n\n* 검색식\n: mapreduce straggler (\"historical record\" OR \"history\")\n: 2건\n\n:* System and Method for Analyzing Data Records\n:: [http://www.google.com/patents/US20120215787 www.google.com/patents/US20120215787]\n:: App. - Filed 28 Feb 2012 - Published 23 Aug 2012 - Jeffrey Dean - Dean Jeffrey, Dorward Sean M, Ghemawat Sanjay, Pike Robert C, Quinlan Sean\n\n:* Scalable user clustering based on set similarity\n:: [http://www.google.com/patents/US7962529 www.google.com/patents/US7962529]\n:: Grant - Filed 6 May 2010 - Issued 14 Jun 2011 - Mayur Datar - Google Inc.\n\n=== # Memo / Questions ===\n\n==== References ====\n\n\n\n* Google search\n map reduce straggler study\n\n:- [http://static.usenix.org/event/osdi08/tech/full_papers/zaharia/zaharia_html/ Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]\n:: Matei Zaharia, Andy Konwinski, Anthony D. Joseph, Randy Katz, Ion Stoica // University of California, Berkeley\n\n:- [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CDAQFjAA&url=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2FUM%2Fpeople%2Fsrikanth%2Fdata%2FCombating%2520Outliers%2520in%2520Map-Reduce.web.pptx&ei=pq1iUer9NK6eiAfN2IHYBQ&usg=AFQjCNEOOEtTE2_nVb6f2qQN09OpoLcS5A&sig2=HakGM53pMqVB1y2PqhQZJQ Combating Outliers in Map-Reduce - Microsoft Research]\n:: Srikanth Kandula, Ganesh Ananthanarayanan, Albert Greenberg, Ion Stoica, Yi Lu, Bikas Saha, Ed Harris\n\n\n* Google search\n map reduce straggler study once relationship\n\n:- [http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]\n:: Soila Kavulya, Jiaqi Tan, Rajeev Gandhi and Priya Narasimhan. Carnegie Mellon Univ., Pittsburgh, PA, USA\n:: [http://www.pdl.cs.cmu.edu/PDL-FTP/associated/CMU-PDL-09-107.pdf Another Version, CMU-PDL-09-107 December 2009]\n:: [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster, CCGrid 2010]]\n\n:- [http://cseweb.ucsd.edu/~vahdat/papers/themis_socc12.pdf Themis: An I/O-Efﬁcient MapReduce // SOCC 2012]\n\n\n\n\n<br/>\n\n== PATENT-BRIAN-2013-007 ==\n\n=== data와 IO insight을 packaging 하는 기술 ===\n\n: 해당 [[data에 대한 IO pattern/insight 정보]]를 data와 함께 packaging하여 (마치 object-oriented manner) 같이 이동되게 함으로써, replication, migration, (node 간 tiering?) 등 분산 환경에서 data가 여러 노드로 이동하는 경우에도 해당 data에 대한 처리가 최적으로 이루어질 수 있도록 하는 기술\n: data에 대한 IO insight 정보로서 다음 정보가 포함될 수 있다\n\n:* data access patterns:\n::- 어떤 application이 얼마나 자주 이 data를 access하는지? (이 data를 access하는 application에 대한 정보가 없으면 insight가 잘못 적용될 수도 있을지도 모른다 - Hadoop 같은 경우는 어떻게 MapReduce Application 정보를 알 수 있을까? 혹시 MapReduce application에 대한 정보가 Hadoop layer에 가려지는 것은 아닐까? JobTracker/TaskTracker를 고려해야 할까?)\n::- 이 데이터(파일?)는 Rd(Read)-intensive 인가? Wr(write)-intensive인가?\n::- 이 데이터는 RRd(random read) / RWr(random write) / SRd(sequential read) / SWr(sequential write) 중 어느 것이 dominant한가? 혹은 Mix 되어 있다면 그 비율은 어떻게 되는가?\n\n:* data간 access pattern 연관성\n::- 이 data가 access되고 나면 어느 정도 확률로 어떤 다른 data가 access되는지?\n::- 어떤 data가 access되고 나면 어느 정도 확률로 이 data가 access되는지?\n\n:* data hot/cold history\n::- 이 data가 hot한 적이 얼마나 자주 있었나?\n::- 이 data가 hot한 시기가 어떤 패턴을 가지고 나타나는가?\n::- 한 번 hot하고 나면 이후에도 다시 hot할 가능성이 높은가?\n\n== PATENT-BRIAN-2013-005 ==\n\n=== IOWA based Proactive Data Placement 자체 특허 ===\n\n: 다양한 정보/Insight을 기반으로 Proactive하게 Data를 Placement하는 기술\n:: (Caching/Tiering in Local Case, Data Replication/Migration in Distributed Case)\n\n\n: 여기에, ML (혹은 HML까지도?)을 적용한다는 아이디어를 추가하자\n:: ML 기반의 IO Prediction\n::: ML을 통해서 예측을 한다면, 어떤어떤 정보들로부터, 어떤 예측을 해야하는 걸까?\n::: Fine-grained prediction이 말이 되는 소리인가?\n::: Coarse-grained prediction을 한다면 어느 스케일까지 fine/coarse-grained 해져야할까?\n\n\n:: ML 기반의 IO Insight (Data Placement를 위한 Macroscopic Guideline)\n::: ML을 통해서 최적의 배치를 할 수도 있는 것일까?\n:::: 가능함. 예를 들어, \"이러이러한 sign/indication을 보이는 data는 언제쯤 어떤 형태의 IO 양상을 보일 확률이 __%임\" 같은 형태의 insight이 있다면, \"이런 data는 현재 local system 뿐만 아니라 networked system의 상태도 같이 고려하여 어디에 위치시켜두는 것이 적당\" 하다는 식의 data placement를 \"proactive 하게\" 할 수 있겠음.\n::: IO Insight의 요건:\n::::# indication, as simple as possible\n::::# indication, as specific as possible\n::::# indication, efficiently traversable - corresponding indication case node들을 쉽게, 효과적으로 traversing하면서 최종 insight leaf에 도달 (Huffman code? Radix tree?)\n::::# indication, easily extensible - indication 추가 시에 변경되는 부분이 최소화될 수 있어야 함\n::: UCB study같은 형태로 나오는 것이 최선일까? 그런 형태/내용 외의 다른 것도 얻어낼 수 있을까?\n\n\n: HML이 도움이 되는 이유는 무엇일까?\n:: 굳이 HML이 아니더라도 ML 만으로도 잘 할 수 있는 범위는 어디까지일까?\n\n\n* Y1 = Proactive Data Placement\n* Y2 = Data-system-optimal Placement\n\n: Y1.x1 = 어느 address의 데이터(들)이\n:: Y1.x1.1 = 그 데이터들은 sequential access가 가능한 형태로 배열되어 있는가? (만약 그렇다면 굳이 cache시킬 필요가 있을까? 혹시 있는 건 아닐까? 정말 없을까? Sequential read하는 경우 SSD case와 HDD case를 비교해볼 필요 있음)\n:: Y1.x1.2 = 그 데이터들이 access되고 나면, ___%의 확률로 따라서 access되는 데이터들도 있지 않을까? (그렇다면, 그 놈들도 연달아서 미리 loading?)\n: Y1.x2 = 앞으로 얼마 후에\n: Y1.x3 = Access될 것인가?\n:: Y1.x3.1 = Read일까? Write일까?\n:: Y1.x3.2 = 그 얼마 후 Access되고 나서 몇 번을 더 Access될까? (이것을 알 수 있을까?)\n\n\n* X1 = IO Access Pattern\n* X2 = IO 유발자 정보\n\n\n\n\n\n\n\nproactive data placement (caching/tiering)를 위해서, layer abstraction 혹은 virtualization이 필요하지는 않을까?\n- 예를 들어, IBM의 GPFS에서 AFM (Active File Management)을 구현할 때, data의 lifecycle 및 next use에 의거한 automatic data transfer를 위해서, 기존에는 없었던 새로운 component 혹은 새로운 layer가 필요하지는 않았을까? [1][2]\n- proactive data placement 입장에서는, next IO use를 예측하거나, user/process context를 이해한다는 측면에서, 오히려 block layer보다는 file system layer에서 바라보는 것이 더욱 적절한 것은 아닐까?\nRead cache, write cache colocation을 하면 어떨까?\nadvanced tiering: access pattern-aware optimal placement (APOP)\n\n== PATENT-BRIAN-2013-006 ==\n\n=== SSD Retention Time Controlling for Caching/Tiering 특허 ===\n\n* Caching-optimal SSD Retention Time Control\n* SSD Retention Time Controlling for Caching\n\nCache-I/O의 특성에 맞도록 SSD Retention Time을 Control하는 기술.\n\n== PATENT-BRIAN-2013-XXX ==\n\n=== State Machine based Macro IO Prediction ===\n\n== PATENT-BRIAN-2013-00X ==\n\n=== Coarse-grained Spatial Locality Based SSD Cache I/O ===\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* DRAM Cache의 부족한 용량을 극복하기 위한 솔루션으로 SSD Cache가 도입되고 있음. 기본 원리는 자주 액세스되는 디스크 블록을 SSD에 Caching함으로써 HDD의 느린 I/O 속도를 극복하도록 하는 것임.\n* 그러나 블록 레이어에 구현되는 SSD Cache의 경우, Kernel에서 관리하는 Page Cache에 의해 이미 Hot data가 Serve되고 있기 때문에, Hit Ratio를 높이기에 근본적인 한계점을 가지고 있음.\n* 한편, kernel에서 관리되는 기존 Page Cache는 다음과 같은 한계점을 가지고 있음. (1) SSD 혹은 HDD에 비해 비싼 스토리지인 RAM 기반이기 때문에 다른 스토리지에 비해 작은 용량을 가지고 있는 경우가 일반적이므로 cache로 사용할 수 있는 공간의 제약이 큼. (2) 시스템에서 사용되지 않고 있는 idle RAM 영역을 이용하기 때문에, 시스템에서 구동되는 프로세스들이 요구하는 RAM 요구량이 많아지게 되면, 그만큼 page cache가 버려지게 되며 그만큼 시스템 I/O 성능의 저하가 발생하게 됨. 또한 이로 인해 성능의 편차가 불규칙하다는 단점 또한 근본적으로 가지고 있음.\n* 한편, SSD를 이용하는 page cache가 기존에 시도된 적이 있으나 매 page access 시마다 SSD에 page를 저장하는 메커니즘으로서 (synchronous I/O) NAND flash와 RAM I/O 특성 차이로 인해 기인하는 근본적인 성능적 한계점을 가지고 있음.\n\n<br/>\n\n\n=== # 본 발명의 특징 / 효과 ===\n\n\n=== # 대표 청구항 ===\n\n* (page tiering 기반의 hybrid cache에서) spatial locality에 기반한 효율적인 page cache I/O 방법\n** 고속이면서도 자원 효율적으로 spatial locality 패턴을 파악하는 방법\n***(range size를 동적으로, 혹은 서로 다르게 할 수 있는 방법은 필요 없을까?)\n\n* page chunk handling 방법\n** [host side] spatial-locality가 있는 page들이 가급적 page chunk 단위로 묶이도록 하는 방법\n** [host side] SSD 내부의 parallelism을 극대화할 수 있도록 page chunk 크기를 정하는 방법 (i.e., channel_# x erase_block_size)\n** [host side / ssd side] tier-2 page cache에 저장된 특정 page가 access될 때, 그 page가 속한 page chunk의 데이터를 같이 pre-loading 하는 방법\n*** 해당 page chunk에 대한 status update하는 것이 필요할까?\n\n* page chunk eviction 방법\n** [ssd side] tier-2 page cache에서 page chunk를 eviction 시키기 전에, page chunk 중에서 popular 한 page는 SSD에서 evict하기 전에 RAM에 올리는 것\n\n\n=== # 기술 상세 ===\n\n=== # 선행 기술 ===\n\n다음 검색식\n (Spatial locality based I/O SSD cache)\n으로 1건의 미국 공개/등록 문건을 검색할 수 있었으나,\n본 발명과 유사한 spatial locality based I/O for SSD cache 관련 선행 기술은 발견하지 못하였음.\n\n유사한 주제를 다루는 논문으로\n __\n이 있었음.\n\n그러나 __ 측면에서 본 발명과 상이함.\n\n<br/>\n\n\n=== # 침해 적발 ===\n\n== PATENT-BRIAN-2013-00X ==\nContent Repeatability-Aware SSD Cache Management\n\n=== 대표 청구항 ===\n\n== PATENT-BRIAN-2013-00X ==\n=== Likely Zone Based Page Pre-placement ===\n\n\n* periodicity의 특성을 이용해 pre-placement하는 개념도 추가할 수 있을까?\n\n* associated-likely-zone 기반의 page pre-placement (to RAM)\n\n* page cache tiering의 방향이 RAM으로부터 SSD로 가는 경우는 page eviction 시 class-2에 해당하는 page들을 SSD로 저장하는 경우임. page cache tiering의 방향이 SSD로부터 RAM으로 가는 경우는 class-1의 “currently-hot”한 page들과 매칭되는 associated-likely-zone이 존재하고, 동시에 현재 시스템에 page cache로 사용할 수 있는 RAM의 여유 공간이 존재할 때, SSD에 저장되어 있었던 해당 associated-likely-zone을 RAM에 미리 올리는 경우임. page cache로 사용할 수 있는 RAM의 여유 공간보다 associated-likely-zone의 크기가 큰 경우에는 RAM의 여유 공간 만큼만 우선적으로 RAM에 올려짐.\n\n* 이때, associated-likely-zone 중에서 우선적으로 RAM에 올려져야 할 영역을 결정하는 방법으로써, “currently-hot”한 현재 data와 지리적으로 가까운 영역의 data를 우선적으로 선택하는 방법, associated-likely-zone의 data들 중에서 access frequency가 높았던 data들을 우선적으로 선택하는 방법 등을 사용할 수 있다. 이에 대한 구체적인 방식은 본 특허와 개별적으로 구현될 수 있으므로, 별도의 특허에서 다루어진다.\n\n* associated-likely-zone은 과거의 access 패턴에 기반하여 서로 비슷한 시간대에 access되었던 data들의 set으로 구성한다. 여기서 ‘서로 비슷한 시간대’라는 개념은 window 2의 window size에 의해 결정된다.\n\n* 특정 address arange가 LZ인지, ULZ인지 구분하는 방법?\nLZ (Likely Zone)와 ULZ (Unlikely Zone)을 선정하는 방법:\naccess되는 page를 보면, 해당되는 inode정보와 이를 access한 process 정보를 알 수 있다. inode 정보를 보면, 이 page가 어떤 파일에 연결되어있는지를 알 수 있다. 이렇게 되면 그 파일이 걸쳐있는 address space 정보 (LBA range)를 알 수 있으며, 이는 likely zone의 일부로 마킹될 수 있다. 여기서 해당 파일 전체를 likely zone으로 할 것인지 해당 파일의 일부를 likely zone으로 할 것인지는 별도의 likely zone determinition rule에 의해 결정된다. 그리고 likely zone으로 마킹된 영역을 언제 class-2 t2 page cache media (e.g., SSD)에 loading할 것인지, loading한다면 likely zone 영역의 데이터들을 어떤 순서로 읽어들일지는 likely-zond loading rule에 의거하여 결정된다. LZ과 ULZ를 선정하는 빈도/시기는\n\n== PATENT-BRIAN-2013-00X ==\n\n* 하나 이상의 SSD를 Page Cache Media로 사용하는 경우, (1) SSD array manager와 연계하여 보다 효율적인 caching I/O를 달성하는 방법 (RACS 기반의 기존 SAVL을 그대로 이용하되 interfacing에 관련된 내용), 혹은 (2) 복수개의 SSD를 caching I/O에 맞도록 coordination하는 방법 (RACS 기반의 기존 SAVL에 추가적으로 caching I/O를 잘 handling할 수 있도록 하는 최적화된 I/O management 방법)\n\n\n* 복수 개의 SSD를 tier-2 page cache media로 사용하는 경우, SSD 1에 free space가 부족한데, 그 SSD 내에 cache되어 있는 page chunk들이 계속 caching해둘만한 가치가 있는 경우, page chunk migration (between SSDs)을 수행한다. 이때, tier-1 page cache 내의 page node 내의 page data location field 값은 update한다. (이때, 누가 migration을 initiation하는 것이 적절할까? host의 hybrid page cache manager? 혹은 activie SSD? 아무래도 SATA 기반의 SSD를 사용하는 경우에는 전자가 좀 더 현실적일 것으로 보임)\n\n\n* tier-2 page cache의 eviction threshold period를 두어서 RAM page cache 경우보다는 길겠지만 tier-2 page cache의 총량이 허용할 수 있는 page 용량을 감안하여 계산된 time period 동안 access 실적이 없으면 tier-2 page cache 중에서도 evictable flag를 set하게 되는데, 이때 복수개의 SSD를 tier-2 page cache media로 사용하는 경우, 전체 SSD 가용 용량을 합산해야 한다.\n\n== PATENT-BRIAN-2013-00X ==\nMultiple I/O Queue Handling for SSD Cache\n\n\n[청구항]\n\n== PATENT-BRIAN-2013-00X ==\npage chunk I/O handling mechanism for multi-tenancy SSD page cache\n\n\n[요약]\n물리적인 SSD 하나가 통째로 page cache로 사용되는 경우에는 SSD 전체를 위와 같이 나누어 사용하면 되겠으나, 하나의 SSD를 page cache media와 다른 용도로 같이 사용해야 하는 경우를 위한 구조 및 방법은 별도의 특허에서 기술하는 것으로 함. page cache media로 사용되는 공간과 다른 목적으로 사용될 공간을 별도의 partition으로 잡고, page cache media로 동작하기 위한 partition을 다시 meta 정보 영역과 page data 영역으로 slice하여 사용함. 이때, SSD는 page cache media로 partitioning된 영역에 해당하는 I/O에 대해서는 병렬성과 page chunk lookup table의 단순성을 극대화 할 수 있게 설계된 page chunk I/O 방식으로 처리할 수 있도록 하는 것이 필요함.\n\n[청구항]\n\n\n== PATENT-BRIAN-2013-00X ==\n\n=== # I/O Pattern-optimal Data Placement for Tiering ===\n\n* Automatic tiering 시, 단순히 hot data들을 fast media에 가져다 놓고 마는 것이 아니라, IO bottleneck이 미연에 방지될 수 있도록 data의 access pattern을 aware해서 차별적으로 배치하는 방법\n예) (a) random-read-intensive 한 data들, (b) sequential-write-intensive한 data들을 다른 방식으로 배치 (tiering)\n\n\n* 이에 필요한 data access pattern 모니터링/분석 방법\n데이터 수집 및 분석 시 PCIe 카드 엔진 활용 가능?\nNIC 이나 DMA를 통해서 data move가 일어나는 경우, PCIe 카드 등을 통해서 IO stream 분석\n\n\n* 이를 위해 필요한 system architecture 구조\n기본적으로 하나 이상의 SSD와 하나 이상의 HDD, 그리고 PCIe 카드, DRAM 일부 사용 방식, Tiering Mapping Table 구조, ...\n\n\n=== # 발명의 이용분야 ===\n=== # 배경 / 기존 기술의 문제점 ===\n=== # 본 발명의 특징 / 효과 ===\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n=== # Memo / Questions ===\n\n\n<br/>\n\n\n\n== Patent pool ==\n\n=== (Tiering-based?) Proactive Data Placement ===\n* 핵심 아이디어\n: \"proactive\" 하게 data를 배치시킨다는 것 자체!\n: Local node 내에서의 vertical tiering 뿐만 아니라 분산 node들 간의 horizontal tiering도 염두에 둘 것\n\n* 경쟁 기술과의 차별화\n: EMC의 FAST 기술이 안고 있는 근본적인 한계점은 무엇일까?\n: data access 패턴의 hot/cold 만 분류해서 hot은 fast tier에, cold는 slow tier에 두는 것이 전부인가? 아니면 그것 외에 뭔가가 더 있는가?\n: 어떻게 보면 기존의 automated storage tiering은 naive proactive placement로 볼 수도 있다. (과거에 자주 access되었던 data가 앞으로도 자주 access될 것이라고 믿고 data를 이동시키는 것이므로. 그러나 근거가 부족함)\n:: 이러한 naive proactive placement 방식으로 야기되는 단점이 있다. 만약 과거에는 자주 access되었는데 마침 tiering되고 난 후에 자주 access되지 않게 되면, 괜히 SSD의 wear-out만 유발시킨 결과가 된다. 다음 tiering 주기가 돌아오기 전 까지는 계속 느린 media에서 I/O가 serve되기 때문에 그만큼 pain이 된다.\n:: 물론 read에 대해서는 cache를 적극 활용함으로써 첫 access 시에만 slow media access로 인한 penalty를 얻고 이후에는 cache가 제공하는 수준의 성능을 얻을 수 있게 된다.\n:: 그러나 write에 대해서는 문제가 다르다. HDD의 경우 sequential write 경우에는 큰 문제가 되지 않는다. 그러나 random write 특성을 가지고 있으며, 게다가 write-intensive한 I/O라면? 그런데 random write이면서 write-intensive한 경우, write되는 address range가 생각보다 넓지 않다면 어떻게 될까? 즉 특정 구간 특정 데이터에 대한 update가 빈번한 것을 의미한다.\n:: write address range가 N개의 4KB 블럭으로 이루어져 있고, Storage System 내에 물리적인 Disk 갯수가 M개 존재한다고 가정하자. 만약 M이 N보다 적절하게 커서 RAID 10을 하건, RAID 5 등으로 이루어져 있건 간데, N개의 4KB 블럭을 각각 별도의 HDD로 분산 시킴으로써 random write을 random write이 아닌 것처럼 보이게 할 수 있다면? 예를 들어 VNX 5300 처럼 SAN 박스 하나 내에 HDD가 125개가 들어있고, random하고 intensive한 write pattern이 오고 있고, write access range가 125개 이하의 address 내에서 반복되고 있다면, 매번 도달하는 random write request를 마치 RAID 0로 striping 하듯이 계속 다른 HDD로 보냄으로써 I/O de-randomization을 할 수 있을 것이다. 여기서 좀 더 나아가서 하나의 request에 대해서 HDD가 완벽하게 처리하는 데에 걸리는 시간이 10ms 이고, 매 random I/O가 도달하는 평균 시간은 (평균 가지고 되려나? 아무튼 이것은 조금 뒤에 다시 생각해보자) 1ms 라고 한다면, 이론적으로 10번의 random I/O가 지난 다음, 11번째의 random I/O가 올 때에는 처음에 write했던 HDD에다가 다시 write을 해도 된다. 즉, 그 HDD에서 직전의 I/O가 끝나기를 기다리고 있지 않아도 된다는 것이다. 그러나 이러한 방식은 나중에 scatter했던 I/O들을 다시 불러모으려고 할 때 contribution한 HDD가 다른 I/O를 serving하고 있지 않을 수 있어야 최고의 성능을 낼 수 있게 된다. 즉, HDD cluster 구성을 상당히 dynamic하게 가져갈 수 있다면 어떨까? 이러한 dynamic clustering이 정말 최고의 효과를 낼 수 있는 workload case로는 어떤 것이 있을까? data placement를 함에 있어서 결국은 어딘가에 써야 할 것이고, (slow tier로 마크된 HDD들 array에다가 data를 쓴다고 그냥 푸대접하면서 써버릴 것이 아니다) slow tier에다가 쓸 때에도 나중에 어떻게 read되고 다시 write 될 지를 고려한다면, workload 특성에 따라서 concurrent I/O의 갯수 및 address range 크기가 다를 수 있는데, 그것을 aware해서 write을 해둔다면, 비록 slow-tier에다가 write했지만, 그리 slow하지만은 않은 성능을 내게 할 수 도 있을 것이다. 이것은 proactive data placement에 대한 이야기가 아니다. proactive와는 별개로, automated storage tiering을 함에 있어서 workload characteristics를 고려한 data placement에 대한 이야기이다.\n\n\n\n\n서로 독립적인 I/O stream의 갯수가 100개 라면 (즉 100개의 process가 I/O를 쏟아내고 있는 경우), 그리고 I/O queue의 크기가 N_Q라면, 어떻게 이러한 문제를 해결할 수 있을까?  \n\n  \n:: write에 대해서는 \n:: write-intensive하다는 것의 정의는? 이러한 경우에는 in-memory write caching (OS가 허용하는 범위의 delayed write을 최대한 활용)을 이용하되 transaction 기반으 atomicity를 보장함으로써 문제를 부분적으로 해결할 수 있다. transaction으로 묶여질 수 있는 여러 번의 I/O request (write)가 끝나기 전까지는 commit되지 않은 것으로 치는 것임. Fusion IO의 atomic write은 이를 어떻게 해결하는지? \n\n만약 write commit이 매우 중요한 민감한 데이터에 대해서는 어떻게 해야할까? 그리고 SSD-internal memory buffer를 이용해서\n: SAN 장비 내에서의 HDD와 SSD 간의 tiering만 되는 것일까? (vertical tiering within local node)\n: SAN 장비 간의 tiering이 되기 위해서는 어떤 것이 더 필요할까? EMC에서 이미 그러한 기술/솔루션을 가지고 있지는 않을까? (horizontal tiering between boxes)\n\n* 다양한 사례\n: 기존에 이미 생성되어 있던 data를 미래 access 예측에 따라 위치 변동을 시키는 경우\n: Tiering을 한다고 했을 때, access 빈도에 따라서 fast tier / slow tier 간 이동시키는 것이 전부일까? 그런 것 말고 다른 차원의 tiering은 없을까?\n: 새롭게 write되려는 data를 처음부터 어디에 배치시키는 것이 좋을까?\n\n* Placement 접근 방식\n: Tiering으로 한정?\n: Tiering과 Caching과의 결합 방식? (Caching engine에게 hint를 주는 방식)\n\n* I/O Prediction 결과를 받아서 proactive하게 data를 tiering 시키는 방법 및 아키텍쳐\n* Key questions\n:- 기존엔 proactive tiering이 없었나?\n:- 만약 없었다면 어떤 어떤 부분들을 청구항으로 넣어야 할까?\n:- 만약 있었다면 어떤 차별화가 필요할까?\n\n=== I/O Workload Analyzer Engine ===\n* I/O Trace 및 다양한 시스템 정보를 기반으로 I/O를 prediction하는 방법 및 구조\n* \n\n\n== Disclosure of Invention :: Template ==\n\n<!--\n== PATENT-BRIAN-2013-00X ==\n-->\n\n=== # RAM-SSD Hybrid Page Cache Architecture ===\n=== # 발명의 이용분야 ===\n=== # 배경 / 기존 기술의 문제점 ===\n=== # 본 발명의 특징 / 효과 ===\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n=== # Memo / Questions ===','utf-8'),(1954,'== PATENT-BRIAN-2013-001 ==\n\n=== # RAM-SSD Hybrid Page Cache Architecture ===\n\n[[Bnote patidea 2013-001]]\n\n== PATENT-BRIAN-2013-002 ==\n=== # Low-computation-overhead and Memory-efficient Periodicity Detection Method ===\n[[Bnote patidea 2013-002]]\n\n== PATENT-BRIAN-2013-003 ==\n\n=== 맵리듀스 작업의 병목 탐지 및 원인 분석을 위한 모니터링 프레임워크 기술 (A monitoring framework for detecting and analyzing execution bottlenecks of MapReduce jobs) ===\n\n[[Bnote patidea 2013-003]]\n\n== PATENT-BRIAN-2013-004 ==\n\n<!-- === Straggler-immune Data/Task Placement in the Distributed Environment === -->\n\n=== Straggler-immune Data Placement in the Distributed Environment (HDFS?) ===\n\n\n\n\n=== Memo ===\n\n* title candidates\n: outlier(straggler, failure, ...)-immune data placement for distributed file system\n: straggler-immune data placement in the distributed file system (DFS)\n\n\n* Assumptions // 환경\n: replica management가 있는 DFS 환경\n: replica management algorithm 변경 가능\n: MapReduce/HDFS처럼 data가 있는 곳에 computation을 보내는 구조\n: DFS 위에서 Hadoop MapReduce처럼 분산 병렬 처리를 수행하는 환경\n\n* Assumptions // Failure Characteristics \n: straggler 발생과 task의 type 간의 연관성이 있음\n: {task type, node} tuple이 \n\nHDFS 및 MapReduce 환경에서,\n\n\n특정 node와 특정 task type의 조합과 straggler 발생 빈도 간에 연관 관계가 있을 수 있을까?\n\n\n즉 straggler가 발생했던 case를 관찰했을 때,\nnode 정보만으로는 패턴 (혹은 straggler 발생과의 연관성)이 보이지 않고,\ntask type 정보만으로도 패턴 (혹은 straggler 발생과의 연관성)이 보이지 않지만,\nnode 정보와 task type 정보를 같이 고려했을 때 straggler 발생 빈도/확률과 연관성을 볼 수 있었다면?\n\n\n\n\n* Bottleneck History Record (BHR) based approach\n: do not throw away the bottleneck experience (history). KEEP IT to use the knowledge for later use.\n\n* Replica management\n: at the very first time to place the data\nDistributed File Systems\n\n\n\n=== # 요약 ===\n\n\n=== # 발명의 이용분야 ===\n\n* Hadoop MapReduce/HDFS 혹은 이와 유사한 분산 처리 시스템이 구동되는 Enterprise 데이터 분석 클러스터.\n* Hadoop MapReduce/HDFS 혹은 이와 유사한 분산 처리 시스템이 구동되는 Public Cloud 데이터센터\n\n\n----\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* Hadoop의 기본 DFS인 HDFS (Hadoop Distributed File System)은 replica management를 수행하고 있음.\n\n\n* HDFS에서의 replica management는 3-copy replica 구성 시, 다음 몇 가지 원칙에 의해 data를 분배하고 있음.\n:- 하나의 node에 동일 block이 두 개 이상 존재하지 않는다\n:- 하나의 rack에 동일 block이 세 개 이상 존재하지 않는다\n:- 첫 번째 replica는 client가 구동하고 있는 node에 배치\n:- 두 번째 replica는 첫 번째 replica가 있던 node가 속하지 않은 다른 rack의 임의의 node에 배치\n:- 세 번째 replica는 두 번째 replica가 배치된 rack 내의 다른 node에 배치\n:- 1st-2nd-3rd replica 배치는 순차적으로 실행\n\n\n* Yahoo!의 Hadoop Cluster에서 10개월간 구동된 17만개의 MapReduce job들을 분석한 연구에 따르면 약 3% 정도의 Job들이 fail되었으며, 각 task의 특성과 failure 발생과 연관성이 있음을 확인할 수 있다. (예를 들어, MapReduce 전체 failure의 80% 이상이 map task에서 발생하였으며, map task failure의 36%는 array indexing error에 의한 것이었음. 그리고 reduce task 의 23%는 I/O exception에 의한 것이었음)  이러한 failure 및 straggler로 인해 task restart가 많이 발생하고 있으며, 이는 MapReduce/HDFS 성능을 저하시키는 주요 요인임.\n\n\n* 현존 Hadoop MapReduce/HDFS 시스템에서는 straggler가 발생했다고 판단되면, 해당 task를 drop 시키고 새로운 node에서 task가 실행될 수 있도록 하고 있음. 즉, 이미 발생한 straggler에 대해서는 speculative execution을 수행하고 있지만 여전히 한계점은 존재함. (1) speculative execution을 위해 필요한 additional data copy overhead 존재. (2) 새로운 execution node를 찾는다 하더라도 그 node가 straggler-free한 node인지 보장할 수 없기 때문에, 제2, 제3의 straggler가 발생할 가능성 존재. (3) additional copy를 하려고 하더라도 이미 task들이 tight하게 많이 구동되고 있는 상황에서, 여유 execution slot을 가지고 있는 적절한 node를 바로 찾지 못할 수 있으며, 이렇게 기다리는 것 자체가 job completion time을 증가시키는 부정적인 효과가 있음.\n\n\n----\n\n=== # 본 발명의 특징 / 효과 ===\n\n\n* 특징\n:- 기존처럼 straggler가 발생한 후에 대응하기 보다는 (사후 대응), HDFS에 처음 data가 놓여질 때부터 straggler-immune node에 배치될 수 있도록 하는 사전 대응 방식을 특징으로 하고 있음.\n:- {node, task-type, bottleneck-risk-score} tuple로 구성되는 Bottleneck History Record (BHR) 정보에 기반하여 해당 task-type에 대해 bottleneck-risk-score 값이 가장 작은 node에 replica data를 배치하는 방식임\n:- {node, task-type}에 대한 bottleneck-risk-score 정보는 JobTracker에 추가되는 Bottleneck History Record Manager 모듈에 의해 update됨\n:- 참고로, 기존 HDFS에서의 data placement (replica management 시)에서는 이러한 straggler-immune data placement는 고려되어 있지 않음.\n\n\n* 기대 효과\n:- speculative execution을 위한 data copy overhead 감소\n:- 제2, 제3의 straggler / failure 발생 확률 감소\n:- 결과적으로, Hadoop MapReduce Job의 성능 향상 효과\n\n\n* 구현의 용이성\n:- Apache Jira HDFS-385에서 언급된 pluggable interface를 이용 시, 본 발명에서 제안하는 data placement 알고리즘을 HDFS의 block placement algorithm으로 추가하기가 용이함.\n\n\n* 침해 적발의 용이성\n:- namenode에서 수집하는 데이터들을 관찰하거나, HDFS-385 interface를 통해 오가는 데이터들을 관찰하였을 때, node, task-type, failure rate 정보를 namenode가 (혹은 pluggable data placement module이) 읽어들이고, 그 중 가장 failure rate 값이 낮은 하나의 node가 replica data를 저장하기 위한 datanode로 선택된다면, 본 특허를 침해한 것으로 판단 가능.\n\n\n----\n\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n\n\n* 기존처럼 straggler가 발생한 후에 대응하기 보다는 (사후 대응), HDFS에 처음 data가 놓여질 때부터 straggler-immune node에 배치될 수 있도록 하는 사전 대응 방식을 특징으로 하고 있음.\n\n\n* {node, task-type, failure rate} tuple 정보에 기반하여 해당 task-type에 대해 failure rate이 최소화 될 수 있는 node에 replica data를 배치하는 방식임\n\n\n==== 시스템 구성 요소 ====\n\n\n==== 처리 절차 ====\n\n\n==== 예상 효과 ====\n\n* Anomaly (straggler, failed task) 발생 자체를 줄임으로써, Straggler 혹은 Failed Task로 인해 야기되는 추가 처리 비용을 감소시킬 수 있음.\n\n* Straggler의 경우, speculative execution으로 야기되는 additional data copy overhead 감소 (사라지거나 감소됨) 효과를 기대할 수 있음. 특히, HDFS block size가 큰 경우 (처리 해야 할 data는 크지만, node의 수가 적은 경우, 64MB 이상으로 tuning하여 사용하는 경우가 많이 있음 - 그런데, 실제로 이렇게 tuning하면 어떤 장점/효과가 얼만큼 생기나?) additional data copy로 인한 overhead가 그만큼 커지게 되므로, 이 경우 straggler 발생 확률을 낮춤으로써 얻는 이득 역시 그만큼 커지게 됨.\n\n* Failed task의 경우, 상황에 따라서 두 가지 처리 옵션이 있다. 첫 번째 옵션은 failure가 발생했던 해당 node에서 task를 재시작하는 방법이며, 두 번째 옵션은 다른 node에서 task를 재시작하는 방법임.\n\n* Task failure의 원인이 해당 node의 H/W 혹은 S/W에 문제가 있는 것이 아니었다면 첫 번째 옵션을 택할 수 있다. 물론 H/W 혹은 시스템 S/W 결함이 아니었다는 것을 알수 있었어야 한다. 그러나 해당 node의 H/W 혹은 S/W에 문제가 있다는 것을 알고 있는데, 당장 다른 node의 execution slot도 여유가 없는 상황이라면, execution slot이 생길 때까지 좀 더 기다렸다가 재시작을 해야 한다. 이때, 기다려야만 하는 경우라면, 그만큼 job 처리 속도의 저하로 이어진다. 다른 노드에서 재시작을 하게 되더라도, 역시 additional data copy가 필요하며, 이로 인한 overhead는 피할 수 없다.\n\n\n----\n\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n\n* Google patent search (2 results, no relevant result)\n (HDFS OR \"hadoop distributed file system\") (((block replica) OR data) placement) (straggler OR fail*)\n\n* Google patent search (2 results, no relevant result)\n (HDFS OR \"hadoop distributed file system\") (((block replica) OR data) placement) bottleneck\n\n* Google patent search (5 results)\n HDFS block replica placement\n:- [http://www.google.com/patents/EP2288998A2?cl=en Directed placement of data in a redundant data storage system]\n:: Filed 9 Apr 2009 - Published 2 Mar 2011, John Howe - Omneon, Inc.\n\n\n\n* 검색식\n: mapreduce straggler (\"historical record\" OR \"history\")\n: 2건\n\n:* System and Method for Analyzing Data Records\n:: [http://www.google.com/patents/US20120215787 www.google.com/patents/US20120215787]\n:: App. - Filed 28 Feb 2012 - Published 23 Aug 2012 - Jeffrey Dean - Dean Jeffrey, Dorward Sean M, Ghemawat Sanjay, Pike Robert C, Quinlan Sean\n\n:* Scalable user clustering based on set similarity\n:: [http://www.google.com/patents/US7962529 www.google.com/patents/US7962529]\n:: Grant - Filed 6 May 2010 - Issued 14 Jun 2011 - Mayur Datar - Google Inc.\n\n=== # Memo / Questions ===\n\n==== References ====\n\n\n\n* Google search\n map reduce straggler study\n\n:- [http://static.usenix.org/event/osdi08/tech/full_papers/zaharia/zaharia_html/ Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]\n:: Matei Zaharia, Andy Konwinski, Anthony D. Joseph, Randy Katz, Ion Stoica // University of California, Berkeley\n\n:- [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CDAQFjAA&url=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2FUM%2Fpeople%2Fsrikanth%2Fdata%2FCombating%2520Outliers%2520in%2520Map-Reduce.web.pptx&ei=pq1iUer9NK6eiAfN2IHYBQ&usg=AFQjCNEOOEtTE2_nVb6f2qQN09OpoLcS5A&sig2=HakGM53pMqVB1y2PqhQZJQ Combating Outliers in Map-Reduce - Microsoft Research]\n:: Srikanth Kandula, Ganesh Ananthanarayanan, Albert Greenberg, Ion Stoica, Yi Lu, Bikas Saha, Ed Harris\n\n\n* Google search\n map reduce straggler study once relationship\n\n:- [http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]\n:: Soila Kavulya, Jiaqi Tan, Rajeev Gandhi and Priya Narasimhan. Carnegie Mellon Univ., Pittsburgh, PA, USA\n:: [http://www.pdl.cs.cmu.edu/PDL-FTP/associated/CMU-PDL-09-107.pdf Another Version, CMU-PDL-09-107 December 2009]\n:: [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster, CCGrid 2010]]\n\n:- [http://cseweb.ucsd.edu/~vahdat/papers/themis_socc12.pdf Themis: An I/O-Efﬁcient MapReduce // SOCC 2012]\n\n\n\n\n<br/>\n\n== PATENT-BRIAN-2013-007 ==\n\n=== data와 IO insight을 packaging 하는 기술 ===\n\n: 해당 [[data에 대한 IO pattern/insight 정보]]를 data와 함께 packaging하여 (마치 object-oriented manner) 같이 이동되게 함으로써, replication, migration, (node 간 tiering?) 등 분산 환경에서 data가 여러 노드로 이동하는 경우에도 해당 data에 대한 처리가 최적으로 이루어질 수 있도록 하는 기술\n: data에 대한 IO insight 정보로서 다음 정보가 포함될 수 있다\n\n:* data access patterns:\n::- 어떤 application이 얼마나 자주 이 data를 access하는지? (이 data를 access하는 application에 대한 정보가 없으면 insight가 잘못 적용될 수도 있을지도 모른다 - Hadoop 같은 경우는 어떻게 MapReduce Application 정보를 알 수 있을까? 혹시 MapReduce application에 대한 정보가 Hadoop layer에 가려지는 것은 아닐까? JobTracker/TaskTracker를 고려해야 할까?)\n::- 이 데이터(파일?)는 Rd(Read)-intensive 인가? Wr(write)-intensive인가?\n::- 이 데이터는 RRd(random read) / RWr(random write) / SRd(sequential read) / SWr(sequential write) 중 어느 것이 dominant한가? 혹은 Mix 되어 있다면 그 비율은 어떻게 되는가?\n\n:* data간 access pattern 연관성\n::- 이 data가 access되고 나면 어느 정도 확률로 어떤 다른 data가 access되는지?\n::- 어떤 data가 access되고 나면 어느 정도 확률로 이 data가 access되는지?\n\n:* data hot/cold history\n::- 이 data가 hot한 적이 얼마나 자주 있었나?\n::- 이 data가 hot한 시기가 어떤 패턴을 가지고 나타나는가?\n::- 한 번 hot하고 나면 이후에도 다시 hot할 가능성이 높은가?\n\n== PATENT-BRIAN-2013-005 ==\n\n=== IOWA based Proactive Data Placement 자체 특허 ===\n\n: 다양한 정보/Insight을 기반으로 Proactive하게 Data를 Placement하는 기술\n:: (Caching/Tiering in Local Case, Data Replication/Migration in Distributed Case)\n\n\n: 여기에, ML (혹은 HML까지도?)을 적용한다는 아이디어를 추가하자\n:: ML 기반의 IO Prediction\n::: ML을 통해서 예측을 한다면, 어떤어떤 정보들로부터, 어떤 예측을 해야하는 걸까?\n::: Fine-grained prediction이 말이 되는 소리인가?\n::: Coarse-grained prediction을 한다면 어느 스케일까지 fine/coarse-grained 해져야할까?\n\n\n:: ML 기반의 IO Insight (Data Placement를 위한 Macroscopic Guideline)\n::: ML을 통해서 최적의 배치를 할 수도 있는 것일까?\n:::: 가능함. 예를 들어, \"이러이러한 sign/indication을 보이는 data는 언제쯤 어떤 형태의 IO 양상을 보일 확률이 __%임\" 같은 형태의 insight이 있다면, \"이런 data는 현재 local system 뿐만 아니라 networked system의 상태도 같이 고려하여 어디에 위치시켜두는 것이 적당\" 하다는 식의 data placement를 \"proactive 하게\" 할 수 있겠음.\n::: IO Insight의 요건:\n::::# indication, as simple as possible\n::::# indication, as specific as possible\n::::# indication, efficiently traversable - corresponding indication case node들을 쉽게, 효과적으로 traversing하면서 최종 insight leaf에 도달 (Huffman code? Radix tree?)\n::::# indication, easily extensible - indication 추가 시에 변경되는 부분이 최소화될 수 있어야 함\n::: UCB study같은 형태로 나오는 것이 최선일까? 그런 형태/내용 외의 다른 것도 얻어낼 수 있을까?\n\n\n: HML이 도움이 되는 이유는 무엇일까?\n:: 굳이 HML이 아니더라도 ML 만으로도 잘 할 수 있는 범위는 어디까지일까?\n\n\n* Y1 = Proactive Data Placement\n* Y2 = Data-system-optimal Placement\n\n: Y1.x1 = 어느 address의 데이터(들)이\n:: Y1.x1.1 = 그 데이터들은 sequential access가 가능한 형태로 배열되어 있는가? (만약 그렇다면 굳이 cache시킬 필요가 있을까? 혹시 있는 건 아닐까? 정말 없을까? Sequential read하는 경우 SSD case와 HDD case를 비교해볼 필요 있음)\n:: Y1.x1.2 = 그 데이터들이 access되고 나면, ___%의 확률로 따라서 access되는 데이터들도 있지 않을까? (그렇다면, 그 놈들도 연달아서 미리 loading?)\n: Y1.x2 = 앞으로 얼마 후에\n: Y1.x3 = Access될 것인가?\n:: Y1.x3.1 = Read일까? Write일까?\n:: Y1.x3.2 = 그 얼마 후 Access되고 나서 몇 번을 더 Access될까? (이것을 알 수 있을까?)\n\n\n* X1 = IO Access Pattern\n* X2 = IO 유발자 정보\n\n\n\n\n\n\n\nproactive data placement (caching/tiering)를 위해서, layer abstraction 혹은 virtualization이 필요하지는 않을까?\n- 예를 들어, IBM의 GPFS에서 AFM (Active File Management)을 구현할 때, data의 lifecycle 및 next use에 의거한 automatic data transfer를 위해서, 기존에는 없었던 새로운 component 혹은 새로운 layer가 필요하지는 않았을까? [1][2]\n- proactive data placement 입장에서는, next IO use를 예측하거나, user/process context를 이해한다는 측면에서, 오히려 block layer보다는 file system layer에서 바라보는 것이 더욱 적절한 것은 아닐까?\nRead cache, write cache colocation을 하면 어떨까?\nadvanced tiering: access pattern-aware optimal placement (APOP)\n\n== PATENT-BRIAN-2013-006 ==\n\n=== SSD Retention Time Controlling for Caching/Tiering 특허 ===\n\n* Caching-optimal SSD Retention Time Control\n* SSD Retention Time Controlling for Caching\n\nCache-I/O의 특성에 맞도록 SSD Retention Time을 Control하는 기술.\n\n== PATENT-BRIAN-2013-XXX ==\n\n=== State Machine based Macro IO Prediction ===\n\n== PATENT-BRIAN-2013-00X ==\n\n=== Coarse-grained Spatial Locality Based SSD Cache I/O ===\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* DRAM Cache의 부족한 용량을 극복하기 위한 솔루션으로 SSD Cache가 도입되고 있음. 기본 원리는 자주 액세스되는 디스크 블록을 SSD에 Caching함으로써 HDD의 느린 I/O 속도를 극복하도록 하는 것임.\n* 그러나 블록 레이어에 구현되는 SSD Cache의 경우, Kernel에서 관리하는 Page Cache에 의해 이미 Hot data가 Serve되고 있기 때문에, Hit Ratio를 높이기에 근본적인 한계점을 가지고 있음.\n* 한편, kernel에서 관리되는 기존 Page Cache는 다음과 같은 한계점을 가지고 있음. (1) SSD 혹은 HDD에 비해 비싼 스토리지인 RAM 기반이기 때문에 다른 스토리지에 비해 작은 용량을 가지고 있는 경우가 일반적이므로 cache로 사용할 수 있는 공간의 제약이 큼. (2) 시스템에서 사용되지 않고 있는 idle RAM 영역을 이용하기 때문에, 시스템에서 구동되는 프로세스들이 요구하는 RAM 요구량이 많아지게 되면, 그만큼 page cache가 버려지게 되며 그만큼 시스템 I/O 성능의 저하가 발생하게 됨. 또한 이로 인해 성능의 편차가 불규칙하다는 단점 또한 근본적으로 가지고 있음.\n* 한편, SSD를 이용하는 page cache가 기존에 시도된 적이 있으나 매 page access 시마다 SSD에 page를 저장하는 메커니즘으로서 (synchronous I/O) NAND flash와 RAM I/O 특성 차이로 인해 기인하는 근본적인 성능적 한계점을 가지고 있음.\n\n<br/>\n\n\n=== # 본 발명의 특징 / 효과 ===\n\n\n=== # 대표 청구항 ===\n\n* (page tiering 기반의 hybrid cache에서) spatial locality에 기반한 효율적인 page cache I/O 방법\n** 고속이면서도 자원 효율적으로 spatial locality 패턴을 파악하는 방법\n***(range size를 동적으로, 혹은 서로 다르게 할 수 있는 방법은 필요 없을까?)\n\n* page chunk handling 방법\n** [host side] spatial-locality가 있는 page들이 가급적 page chunk 단위로 묶이도록 하는 방법\n** [host side] SSD 내부의 parallelism을 극대화할 수 있도록 page chunk 크기를 정하는 방법 (i.e., channel_# x erase_block_size)\n** [host side / ssd side] tier-2 page cache에 저장된 특정 page가 access될 때, 그 page가 속한 page chunk의 데이터를 같이 pre-loading 하는 방법\n*** 해당 page chunk에 대한 status update하는 것이 필요할까?\n\n* page chunk eviction 방법\n** [ssd side] tier-2 page cache에서 page chunk를 eviction 시키기 전에, page chunk 중에서 popular 한 page는 SSD에서 evict하기 전에 RAM에 올리는 것\n\n\n=== # 기술 상세 ===\n\n=== # 선행 기술 ===\n\n다음 검색식\n (Spatial locality based I/O SSD cache)\n으로 1건의 미국 공개/등록 문건을 검색할 수 있었으나,\n본 발명과 유사한 spatial locality based I/O for SSD cache 관련 선행 기술은 발견하지 못하였음.\n\n유사한 주제를 다루는 논문으로\n __\n이 있었음.\n\n그러나 __ 측면에서 본 발명과 상이함.\n\n<br/>\n\n\n=== # 침해 적발 ===\n\n== PATENT-BRIAN-2013-00X ==\nContent Repeatability-Aware SSD Cache Management\n\n=== 대표 청구항 ===\n\n== PATENT-BRIAN-2013-00X ==\n=== Likely Zone Based Page Pre-placement ===\n\n\n* periodicity의 특성을 이용해 pre-placement하는 개념도 추가할 수 있을까?\n\n* associated-likely-zone 기반의 page pre-placement (to RAM)\n\n* page cache tiering의 방향이 RAM으로부터 SSD로 가는 경우는 page eviction 시 class-2에 해당하는 page들을 SSD로 저장하는 경우임. page cache tiering의 방향이 SSD로부터 RAM으로 가는 경우는 class-1의 “currently-hot”한 page들과 매칭되는 associated-likely-zone이 존재하고, 동시에 현재 시스템에 page cache로 사용할 수 있는 RAM의 여유 공간이 존재할 때, SSD에 저장되어 있었던 해당 associated-likely-zone을 RAM에 미리 올리는 경우임. page cache로 사용할 수 있는 RAM의 여유 공간보다 associated-likely-zone의 크기가 큰 경우에는 RAM의 여유 공간 만큼만 우선적으로 RAM에 올려짐.\n\n* 이때, associated-likely-zone 중에서 우선적으로 RAM에 올려져야 할 영역을 결정하는 방법으로써, “currently-hot”한 현재 data와 지리적으로 가까운 영역의 data를 우선적으로 선택하는 방법, associated-likely-zone의 data들 중에서 access frequency가 높았던 data들을 우선적으로 선택하는 방법 등을 사용할 수 있다. 이에 대한 구체적인 방식은 본 특허와 개별적으로 구현될 수 있으므로, 별도의 특허에서 다루어진다.\n\n* associated-likely-zone은 과거의 access 패턴에 기반하여 서로 비슷한 시간대에 access되었던 data들의 set으로 구성한다. 여기서 ‘서로 비슷한 시간대’라는 개념은 window 2의 window size에 의해 결정된다.\n\n* 특정 address arange가 LZ인지, ULZ인지 구분하는 방법?\nLZ (Likely Zone)와 ULZ (Unlikely Zone)을 선정하는 방법:\naccess되는 page를 보면, 해당되는 inode정보와 이를 access한 process 정보를 알 수 있다. inode 정보를 보면, 이 page가 어떤 파일에 연결되어있는지를 알 수 있다. 이렇게 되면 그 파일이 걸쳐있는 address space 정보 (LBA range)를 알 수 있으며, 이는 likely zone의 일부로 마킹될 수 있다. 여기서 해당 파일 전체를 likely zone으로 할 것인지 해당 파일의 일부를 likely zone으로 할 것인지는 별도의 likely zone determinition rule에 의해 결정된다. 그리고 likely zone으로 마킹된 영역을 언제 class-2 t2 page cache media (e.g., SSD)에 loading할 것인지, loading한다면 likely zone 영역의 데이터들을 어떤 순서로 읽어들일지는 likely-zond loading rule에 의거하여 결정된다. LZ과 ULZ를 선정하는 빈도/시기는\n\n== PATENT-BRIAN-2013-00X ==\n\n* 하나 이상의 SSD를 Page Cache Media로 사용하는 경우, (1) SSD array manager와 연계하여 보다 효율적인 caching I/O를 달성하는 방법 (RACS 기반의 기존 SAVL을 그대로 이용하되 interfacing에 관련된 내용), 혹은 (2) 복수개의 SSD를 caching I/O에 맞도록 coordination하는 방법 (RACS 기반의 기존 SAVL에 추가적으로 caching I/O를 잘 handling할 수 있도록 하는 최적화된 I/O management 방법)\n\n\n* 복수 개의 SSD를 tier-2 page cache media로 사용하는 경우, SSD 1에 free space가 부족한데, 그 SSD 내에 cache되어 있는 page chunk들이 계속 caching해둘만한 가치가 있는 경우, page chunk migration (between SSDs)을 수행한다. 이때, tier-1 page cache 내의 page node 내의 page data location field 값은 update한다. (이때, 누가 migration을 initiation하는 것이 적절할까? host의 hybrid page cache manager? 혹은 activie SSD? 아무래도 SATA 기반의 SSD를 사용하는 경우에는 전자가 좀 더 현실적일 것으로 보임)\n\n\n* tier-2 page cache의 eviction threshold period를 두어서 RAM page cache 경우보다는 길겠지만 tier-2 page cache의 총량이 허용할 수 있는 page 용량을 감안하여 계산된 time period 동안 access 실적이 없으면 tier-2 page cache 중에서도 evictable flag를 set하게 되는데, 이때 복수개의 SSD를 tier-2 page cache media로 사용하는 경우, 전체 SSD 가용 용량을 합산해야 한다.\n\n== PATENT-BRIAN-2013-00X ==\nMultiple I/O Queue Handling for SSD Cache\n\n\n[청구항]\n\n== PATENT-BRIAN-2013-00X ==\npage chunk I/O handling mechanism for multi-tenancy SSD page cache\n\n\n[요약]\n물리적인 SSD 하나가 통째로 page cache로 사용되는 경우에는 SSD 전체를 위와 같이 나누어 사용하면 되겠으나, 하나의 SSD를 page cache media와 다른 용도로 같이 사용해야 하는 경우를 위한 구조 및 방법은 별도의 특허에서 기술하는 것으로 함. page cache media로 사용되는 공간과 다른 목적으로 사용될 공간을 별도의 partition으로 잡고, page cache media로 동작하기 위한 partition을 다시 meta 정보 영역과 page data 영역으로 slice하여 사용함. 이때, SSD는 page cache media로 partitioning된 영역에 해당하는 I/O에 대해서는 병렬성과 page chunk lookup table의 단순성을 극대화 할 수 있게 설계된 page chunk I/O 방식으로 처리할 수 있도록 하는 것이 필요함.\n\n[청구항]\n\n\n== PATENT-BRIAN-2013-00X ==\n\n=== # I/O Pattern-optimal Data Placement for Tiering ===\n\n* Automatic tiering 시, 단순히 hot data들을 fast media에 가져다 놓고 마는 것이 아니라, IO bottleneck이 미연에 방지될 수 있도록 data의 access pattern을 aware해서 차별적으로 배치하는 방법\n예) (a) random-read-intensive 한 data들, (b) sequential-write-intensive한 data들을 다른 방식으로 배치 (tiering)\n\n\n* 이에 필요한 data access pattern 모니터링/분석 방법\n데이터 수집 및 분석 시 PCIe 카드 엔진 활용 가능?\nNIC 이나 DMA를 통해서 data move가 일어나는 경우, PCIe 카드 등을 통해서 IO stream 분석\n\n\n* 이를 위해 필요한 system architecture 구조\n기본적으로 하나 이상의 SSD와 하나 이상의 HDD, 그리고 PCIe 카드, DRAM 일부 사용 방식, Tiering Mapping Table 구조, ...\n\n\n=== # 발명의 이용분야 ===\n=== # 배경 / 기존 기술의 문제점 ===\n=== # 본 발명의 특징 / 효과 ===\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n=== # Memo / Questions ===\n\n\n<br/>\n\n\n\n== Patent pool ==\n\n\n=== (SmartSSD API) SSD-internal I/O pattern logging interface and mechanism ===\n\n\n==== Questions ====\n\n* SmartSSD에서 제공할 수 있는 logging 서비스로서 어떤 것들이 있을 수 있나?\n:- 어느? 정도의 free space를 필요로하는 critical (heavy) I/O가 어떤? 주기로 도래할 지 알 수 있을까?\n:- I/O prediction에 도움될 수 있는 정보를 SmartSSD가 기록했다가 필요한 때 (안전한 방법으로?) 줄 수 있을까?\n:- I/O prediction까지는 아니더라도 해당 SSD의 I/O wellness(어떻게 정의?)를 측정했다가 bottleneck을 회피하는 데 유용한 정보를 제공할 수 있을까?\n:- 어떤 SSD가 현재 주어지고 있는 I/O workload에 대해 list performance spec을 만족하는데 어려움을 겪고 있다는 것을 알려줄 수 있는 정보가 어떤 것이 있을까? (SSD 내 write buffer의 fullness 혹은 I/O queue의 유동성? amount of free space in over-provisioning area?) (-> I/O wellness 라는 metric을 이것과 연관시켜 정의할 수도 있으며, 결국 SLA 혹은 Performance QoS와 연관시킬 수 있음)\n:- 지금까지의 S.M.A.R.T.와 비교하였을 때, 어떤 차별점이 있는가? 기존의 S.M.A.R.T.가 제공하지 못하던 타입의 정보를 제공하고, 이로 인해 기존에는 불가능했던 새로운 알고리즘 구현 혹은 새로운 서비스 제공이 가능해짐을 보이면 좋겠음.\n\n\n\n:- workload의 history?\n:- 각 erase block이 erase되어야만 했던 주기?\n:- free space의 추이 (얼마나 많이 남아 돌던지)?\n:- I/O의 heaviness 패턴?\n:- SSD내 write buffer (혹은 write cache)의 utilization정보? (즉, write buffer가 넘칠 정도가 되어서 I/O wait을 해야만 했던 상황이 얼마나 자주 발생했는지, write buffer의 가득찬 정도를 백분율로 표현한다고 했을 때, 평균/표준편차 등으로 대표할 수 있는 normal distribution을 따르는지?\n:- 전체 sequential read/write \n\n\n==== 배경 ====\n\n* 각 SSD 모델별로, 또 동일한 모델의 SSD라 하더라도 어떤 workload에 노출되어왔는지에 따라, 현재 낼 수 있는 I/O performance가 동일하지 않을 수 있다 (!check! 관련 실험 결과 - SSD 830을 이용하여 같은 시간 동안 하나의 host에서 생성되는 workload들을 나누어 받았다 하더라도 내부적인 free block의 갯수 및 random write에 의한 block 내 파편화등의 상태가 상이하여 성능에 차이가 나는 것을 보여줄 것. uFLIP 혹은 filebench 활용 가능). 한 예로, SSD가 어느 호스트의 어느 file system에 매핑되었는지에 따라 그 SSD가 받는 workload의 특성이 다를 수 있다. file system mount point가 달라지거나, 기존과 다른 새로운 응용이 설치/서비스되는 상황이 되면 \n\n\n=== (Tiering-based?) Proactive Data Placement ===\n* 핵심 아이디어\n: \"proactive\" 하게 data를 배치시킨다는 것 자체!\n: Local node 내에서의 vertical tiering 뿐만 아니라 분산 node들 간의 horizontal tiering도 염두에 둘 것\n\n* 경쟁 기술과의 차별화\n: EMC의 FAST 기술이 안고 있는 근본적인 한계점은 무엇일까?\n: data access 패턴의 hot/cold 만 분류해서 hot은 fast tier에, cold는 slow tier에 두는 것이 전부인가? 아니면 그것 외에 뭔가가 더 있는가?\n: 어떻게 보면 기존의 automated storage tiering은 naive proactive placement로 볼 수도 있다. (과거에 자주 access되었던 data가 앞으로도 자주 access될 것이라고 믿고 data를 이동시키는 것이므로. 그러나 근거가 부족함)\n:: 이러한 naive proactive placement 방식으로 야기되는 단점이 있다. 만약 과거에는 자주 access되었는데 마침 tiering되고 난 후에 자주 access되지 않게 되면, 괜히 SSD의 wear-out만 유발시킨 결과가 된다. 다음 tiering 주기가 돌아오기 전 까지는 계속 느린 media에서 I/O가 serve되기 때문에 그만큼 pain이 된다.\n:: 물론 read에 대해서는 cache를 적극 활용함으로써 첫 access 시에만 slow media access로 인한 penalty를 얻고 이후에는 cache가 제공하는 수준의 성능을 얻을 수 있게 된다.\n:: 그러나 write에 대해서는 문제가 다르다. HDD의 경우 sequential write 경우에는 큰 문제가 되지 않는다. 그러나 random write 특성을 가지고 있으며, 게다가 write-intensive한 I/O라면? 그런데 random write이면서 write-intensive한 경우, write되는 address range가 생각보다 넓지 않다면 어떻게 될까? 즉 특정 구간 특정 데이터에 대한 update가 빈번한 것을 의미한다.\n:: write address range가 N개의 4KB 블럭으로 이루어져 있고, Storage System 내에 물리적인 Disk 갯수가 M개 존재한다고 가정하자. 만약 M이 N보다 적절하게 커서 RAID 10을 하건, RAID 5 등으로 이루어져 있건 간데, N개의 4KB 블럭을 각각 별도의 HDD로 분산 시킴으로써 random write을 random write이 아닌 것처럼 보이게 할 수 있다면? 예를 들어 VNX 5300 처럼 SAN 박스 하나 내에 HDD가 125개가 들어있고, random하고 intensive한 write pattern이 오고 있고, write access range가 125개 이하의 address 내에서 반복되고 있다면, 매번 도달하는 random write request를 마치 RAID 0로 striping 하듯이 계속 다른 HDD로 보냄으로써 I/O de-randomization을 할 수 있을 것이다. 여기서 좀 더 나아가서 하나의 request에 대해서 HDD가 완벽하게 처리하는 데에 걸리는 시간이 10ms 이고, 매 random I/O가 도달하는 평균 시간은 (평균 가지고 되려나? 아무튼 이것은 조금 뒤에 다시 생각해보자) 1ms 라고 한다면, 이론적으로 10번의 random I/O가 지난 다음, 11번째의 random I/O가 올 때에는 처음에 write했던 HDD에다가 다시 write을 해도 된다. 즉, 그 HDD에서 직전의 I/O가 끝나기를 기다리고 있지 않아도 된다는 것이다. 그러나 이러한 방식은 나중에 scatter했던 I/O들을 다시 불러모으려고 할 때 contribution한 HDD가 다른 I/O를 serving하고 있지 않을 수 있어야 최고의 성능을 낼 수 있게 된다. 즉, HDD cluster 구성을 상당히 dynamic하게 가져갈 수 있다면 어떨까? 이러한 dynamic clustering이 정말 최고의 효과를 낼 수 있는 workload case로는 어떤 것이 있을까? data placement를 함에 있어서 결국은 어딘가에 써야 할 것이고, (slow tier로 마크된 HDD들 array에다가 data를 쓴다고 그냥 푸대접하면서 써버릴 것이 아니다) slow tier에다가 쓸 때에도 나중에 어떻게 read되고 다시 write 될 지를 고려한다면, workload 특성에 따라서 concurrent I/O의 갯수 및 address range 크기가 다를 수 있는데, 그것을 aware해서 write을 해둔다면, 비록 slow-tier에다가 write했지만, 그리 slow하지만은 않은 성능을 내게 할 수 도 있을 것이다. 이것은 proactive data placement에 대한 이야기가 아니다. proactive와는 별개로, automated storage tiering을 함에 있어서 workload characteristics를 고려한 data placement에 대한 이야기이다.\n\n\n\n\n서로 독립적인 I/O stream의 갯수가 100개 라면 (즉 100개의 process가 I/O를 쏟아내고 있는 경우), 그리고 I/O queue의 크기가 N_Q라면, 어떻게 이러한 문제를 해결할 수 있을까?  \n\n  \n:: write에 대해서는 \n:: write-intensive하다는 것의 정의는? 이러한 경우에는 in-memory write caching (OS가 허용하는 범위의 delayed write을 최대한 활용)을 이용하되 transaction 기반으 atomicity를 보장함으로써 문제를 부분적으로 해결할 수 있다. transaction으로 묶여질 수 있는 여러 번의 I/O request (write)가 끝나기 전까지는 commit되지 않은 것으로 치는 것임. Fusion IO의 atomic write은 이를 어떻게 해결하는지? \n\n만약 write commit이 매우 중요한 민감한 데이터에 대해서는 어떻게 해야할까? 그리고 SSD-internal memory buffer를 이용해서\n: SAN 장비 내에서의 HDD와 SSD 간의 tiering만 되는 것일까? (vertical tiering within local node)\n: SAN 장비 간의 tiering이 되기 위해서는 어떤 것이 더 필요할까? EMC에서 이미 그러한 기술/솔루션을 가지고 있지는 않을까? (horizontal tiering between boxes)\n\n* 다양한 사례\n: 기존에 이미 생성되어 있던 data를 미래 access 예측에 따라 위치 변동을 시키는 경우\n: Tiering을 한다고 했을 때, access 빈도에 따라서 fast tier / slow tier 간 이동시키는 것이 전부일까? 그런 것 말고 다른 차원의 tiering은 없을까?\n: 새롭게 write되려는 data를 처음부터 어디에 배치시키는 것이 좋을까?\n\n* Placement 접근 방식\n: Tiering으로 한정?\n: Tiering과 Caching과의 결합 방식? (Caching engine에게 hint를 주는 방식)\n\n* I/O Prediction 결과를 받아서 proactive하게 data를 tiering 시키는 방법 및 아키텍쳐\n* Key questions\n:- 기존엔 proactive tiering이 없었나?\n:- 만약 없었다면 어떤 어떤 부분들을 청구항으로 넣어야 할까?\n:- 만약 있었다면 어떤 차별화가 필요할까?\n\n=== I/O Workload Analyzer Engine ===\n* I/O Trace 및 다양한 시스템 정보를 기반으로 I/O를 prediction하는 방법 및 구조\n*\n\n== Disclosure of Invention :: Template ==\n\n<!--\n== PATENT-BRIAN-2013-00X ==\n-->\n\n=== # RAM-SSD Hybrid Page Cache Architecture ===\n=== # 발명의 이용분야 ===\n=== # 배경 / 기존 기술의 문제점 ===\n=== # 본 발명의 특징 / 효과 ===\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n=== # Memo / Questions ===','utf-8'),(1955,'== PATENT-BRIAN-2013-001 ==\n\n=== # RAM-SSD Hybrid Page Cache Architecture ===\n\n[[Bnote patidea 2013-001]]\n\n== PATENT-BRIAN-2013-002 ==\n=== # Low-computation-overhead and Memory-efficient Periodicity Detection Method ===\n[[Bnote patidea 2013-002]]\n\n== PATENT-BRIAN-2013-003 ==\n\n=== 맵리듀스 작업의 병목 탐지 및 원인 분석을 위한 모니터링 프레임워크 기술 (A monitoring framework for detecting and analyzing execution bottlenecks of MapReduce jobs) ===\n\n[[Bnote patidea 2013-003]]\n\n== PATENT-BRIAN-2013-004 ==\n\n<!-- === Straggler-immune Data/Task Placement in the Distributed Environment === -->\n\n=== Straggler-immune Data Placement in the Distributed Environment (HDFS?) ===\n\n\n\n\n=== Memo ===\n\n* title candidates\n: outlier(straggler, failure, ...)-immune data placement for distributed file system\n: straggler-immune data placement in the distributed file system (DFS)\n\n\n* Assumptions // 환경\n: replica management가 있는 DFS 환경\n: replica management algorithm 변경 가능\n: MapReduce/HDFS처럼 data가 있는 곳에 computation을 보내는 구조\n: DFS 위에서 Hadoop MapReduce처럼 분산 병렬 처리를 수행하는 환경\n\n* Assumptions // Failure Characteristics \n: straggler 발생과 task의 type 간의 연관성이 있음\n: {task type, node} tuple이 \n\nHDFS 및 MapReduce 환경에서,\n\n\n특정 node와 특정 task type의 조합과 straggler 발생 빈도 간에 연관 관계가 있을 수 있을까?\n\n\n즉 straggler가 발생했던 case를 관찰했을 때,\nnode 정보만으로는 패턴 (혹은 straggler 발생과의 연관성)이 보이지 않고,\ntask type 정보만으로도 패턴 (혹은 straggler 발생과의 연관성)이 보이지 않지만,\nnode 정보와 task type 정보를 같이 고려했을 때 straggler 발생 빈도/확률과 연관성을 볼 수 있었다면?\n\n\n\n\n* Bottleneck History Record (BHR) based approach\n: do not throw away the bottleneck experience (history). KEEP IT to use the knowledge for later use.\n\n* Replica management\n: at the very first time to place the data\nDistributed File Systems\n\n\n\n=== # 요약 ===\n\n\n=== # 발명의 이용분야 ===\n\n* Hadoop MapReduce/HDFS 혹은 이와 유사한 분산 처리 시스템이 구동되는 Enterprise 데이터 분석 클러스터.\n* Hadoop MapReduce/HDFS 혹은 이와 유사한 분산 처리 시스템이 구동되는 Public Cloud 데이터센터\n\n\n----\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* Hadoop의 기본 DFS인 HDFS (Hadoop Distributed File System)은 replica management를 수행하고 있음.\n\n\n* HDFS에서의 replica management는 3-copy replica 구성 시, 다음 몇 가지 원칙에 의해 data를 분배하고 있음.\n:- 하나의 node에 동일 block이 두 개 이상 존재하지 않는다\n:- 하나의 rack에 동일 block이 세 개 이상 존재하지 않는다\n:- 첫 번째 replica는 client가 구동하고 있는 node에 배치\n:- 두 번째 replica는 첫 번째 replica가 있던 node가 속하지 않은 다른 rack의 임의의 node에 배치\n:- 세 번째 replica는 두 번째 replica가 배치된 rack 내의 다른 node에 배치\n:- 1st-2nd-3rd replica 배치는 순차적으로 실행\n\n\n* Yahoo!의 Hadoop Cluster에서 10개월간 구동된 17만개의 MapReduce job들을 분석한 연구에 따르면 약 3% 정도의 Job들이 fail되었으며, 각 task의 특성과 failure 발생과 연관성이 있음을 확인할 수 있다. (예를 들어, MapReduce 전체 failure의 80% 이상이 map task에서 발생하였으며, map task failure의 36%는 array indexing error에 의한 것이었음. 그리고 reduce task 의 23%는 I/O exception에 의한 것이었음)  이러한 failure 및 straggler로 인해 task restart가 많이 발생하고 있으며, 이는 MapReduce/HDFS 성능을 저하시키는 주요 요인임.\n\n\n* 현존 Hadoop MapReduce/HDFS 시스템에서는 straggler가 발생했다고 판단되면, 해당 task를 drop 시키고 새로운 node에서 task가 실행될 수 있도록 하고 있음. 즉, 이미 발생한 straggler에 대해서는 speculative execution을 수행하고 있지만 여전히 한계점은 존재함. (1) speculative execution을 위해 필요한 additional data copy overhead 존재. (2) 새로운 execution node를 찾는다 하더라도 그 node가 straggler-free한 node인지 보장할 수 없기 때문에, 제2, 제3의 straggler가 발생할 가능성 존재. (3) additional copy를 하려고 하더라도 이미 task들이 tight하게 많이 구동되고 있는 상황에서, 여유 execution slot을 가지고 있는 적절한 node를 바로 찾지 못할 수 있으며, 이렇게 기다리는 것 자체가 job completion time을 증가시키는 부정적인 효과가 있음.\n\n\n----\n\n=== # 본 발명의 특징 / 효과 ===\n\n\n* 특징\n:- 기존처럼 straggler가 발생한 후에 대응하기 보다는 (사후 대응), HDFS에 처음 data가 놓여질 때부터 straggler-immune node에 배치될 수 있도록 하는 사전 대응 방식을 특징으로 하고 있음.\n:- {node, task-type, bottleneck-risk-score} tuple로 구성되는 Bottleneck History Record (BHR) 정보에 기반하여 해당 task-type에 대해 bottleneck-risk-score 값이 가장 작은 node에 replica data를 배치하는 방식임\n:- {node, task-type}에 대한 bottleneck-risk-score 정보는 JobTracker에 추가되는 Bottleneck History Record Manager 모듈에 의해 update됨\n:- 참고로, 기존 HDFS에서의 data placement (replica management 시)에서는 이러한 straggler-immune data placement는 고려되어 있지 않음.\n\n\n* 기대 효과\n:- speculative execution을 위한 data copy overhead 감소\n:- 제2, 제3의 straggler / failure 발생 확률 감소\n:- 결과적으로, Hadoop MapReduce Job의 성능 향상 효과\n\n\n* 구현의 용이성\n:- Apache Jira HDFS-385에서 언급된 pluggable interface를 이용 시, 본 발명에서 제안하는 data placement 알고리즘을 HDFS의 block placement algorithm으로 추가하기가 용이함.\n\n\n* 침해 적발의 용이성\n:- namenode에서 수집하는 데이터들을 관찰하거나, HDFS-385 interface를 통해 오가는 데이터들을 관찰하였을 때, node, task-type, failure rate 정보를 namenode가 (혹은 pluggable data placement module이) 읽어들이고, 그 중 가장 failure rate 값이 낮은 하나의 node가 replica data를 저장하기 위한 datanode로 선택된다면, 본 특허를 침해한 것으로 판단 가능.\n\n\n----\n\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n\n\n* 기존처럼 straggler가 발생한 후에 대응하기 보다는 (사후 대응), HDFS에 처음 data가 놓여질 때부터 straggler-immune node에 배치될 수 있도록 하는 사전 대응 방식을 특징으로 하고 있음.\n\n\n* {node, task-type, failure rate} tuple 정보에 기반하여 해당 task-type에 대해 failure rate이 최소화 될 수 있는 node에 replica data를 배치하는 방식임\n\n\n==== 시스템 구성 요소 ====\n\n\n==== 처리 절차 ====\n\n\n==== 예상 효과 ====\n\n* Anomaly (straggler, failed task) 발생 자체를 줄임으로써, Straggler 혹은 Failed Task로 인해 야기되는 추가 처리 비용을 감소시킬 수 있음.\n\n* Straggler의 경우, speculative execution으로 야기되는 additional data copy overhead 감소 (사라지거나 감소됨) 효과를 기대할 수 있음. 특히, HDFS block size가 큰 경우 (처리 해야 할 data는 크지만, node의 수가 적은 경우, 64MB 이상으로 tuning하여 사용하는 경우가 많이 있음 - 그런데, 실제로 이렇게 tuning하면 어떤 장점/효과가 얼만큼 생기나?) additional data copy로 인한 overhead가 그만큼 커지게 되므로, 이 경우 straggler 발생 확률을 낮춤으로써 얻는 이득 역시 그만큼 커지게 됨.\n\n* Failed task의 경우, 상황에 따라서 두 가지 처리 옵션이 있다. 첫 번째 옵션은 failure가 발생했던 해당 node에서 task를 재시작하는 방법이며, 두 번째 옵션은 다른 node에서 task를 재시작하는 방법임.\n\n* Task failure의 원인이 해당 node의 H/W 혹은 S/W에 문제가 있는 것이 아니었다면 첫 번째 옵션을 택할 수 있다. 물론 H/W 혹은 시스템 S/W 결함이 아니었다는 것을 알수 있었어야 한다. 그러나 해당 node의 H/W 혹은 S/W에 문제가 있다는 것을 알고 있는데, 당장 다른 node의 execution slot도 여유가 없는 상황이라면, execution slot이 생길 때까지 좀 더 기다렸다가 재시작을 해야 한다. 이때, 기다려야만 하는 경우라면, 그만큼 job 처리 속도의 저하로 이어진다. 다른 노드에서 재시작을 하게 되더라도, 역시 additional data copy가 필요하며, 이로 인한 overhead는 피할 수 없다.\n\n\n----\n\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n\n* Google patent search (2 results, no relevant result)\n (HDFS OR \"hadoop distributed file system\") (((block replica) OR data) placement) (straggler OR fail*)\n\n* Google patent search (2 results, no relevant result)\n (HDFS OR \"hadoop distributed file system\") (((block replica) OR data) placement) bottleneck\n\n* Google patent search (5 results)\n HDFS block replica placement\n:- [http://www.google.com/patents/EP2288998A2?cl=en Directed placement of data in a redundant data storage system]\n:: Filed 9 Apr 2009 - Published 2 Mar 2011, John Howe - Omneon, Inc.\n\n\n\n* 검색식\n: mapreduce straggler (\"historical record\" OR \"history\")\n: 2건\n\n:* System and Method for Analyzing Data Records\n:: [http://www.google.com/patents/US20120215787 www.google.com/patents/US20120215787]\n:: App. - Filed 28 Feb 2012 - Published 23 Aug 2012 - Jeffrey Dean - Dean Jeffrey, Dorward Sean M, Ghemawat Sanjay, Pike Robert C, Quinlan Sean\n\n:* Scalable user clustering based on set similarity\n:: [http://www.google.com/patents/US7962529 www.google.com/patents/US7962529]\n:: Grant - Filed 6 May 2010 - Issued 14 Jun 2011 - Mayur Datar - Google Inc.\n\n=== # Memo / Questions ===\n\n==== References ====\n\n\n\n* Google search\n map reduce straggler study\n\n:- [http://static.usenix.org/event/osdi08/tech/full_papers/zaharia/zaharia_html/ Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]\n:: Matei Zaharia, Andy Konwinski, Anthony D. Joseph, Randy Katz, Ion Stoica // University of California, Berkeley\n\n:- [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CDAQFjAA&url=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2FUM%2Fpeople%2Fsrikanth%2Fdata%2FCombating%2520Outliers%2520in%2520Map-Reduce.web.pptx&ei=pq1iUer9NK6eiAfN2IHYBQ&usg=AFQjCNEOOEtTE2_nVb6f2qQN09OpoLcS5A&sig2=HakGM53pMqVB1y2PqhQZJQ Combating Outliers in Map-Reduce - Microsoft Research]\n:: Srikanth Kandula, Ganesh Ananthanarayanan, Albert Greenberg, Ion Stoica, Yi Lu, Bikas Saha, Ed Harris\n\n\n* Google search\n map reduce straggler study once relationship\n\n:- [http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]\n:: Soila Kavulya, Jiaqi Tan, Rajeev Gandhi and Priya Narasimhan. Carnegie Mellon Univ., Pittsburgh, PA, USA\n:: [http://www.pdl.cs.cmu.edu/PDL-FTP/associated/CMU-PDL-09-107.pdf Another Version, CMU-PDL-09-107 December 2009]\n:: [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster, CCGrid 2010]]\n\n:- [http://cseweb.ucsd.edu/~vahdat/papers/themis_socc12.pdf Themis: An I/O-Efﬁcient MapReduce // SOCC 2012]\n\n\n\n\n<br/>\n\n== PATENT-BRIAN-2013-007 ==\n\n=== data와 IO insight을 packaging 하는 기술 ===\n\n: 해당 [[data에 대한 IO pattern/insight 정보]]를 data와 함께 packaging하여 (마치 object-oriented manner) 같이 이동되게 함으로써, replication, migration, (node 간 tiering?) 등 분산 환경에서 data가 여러 노드로 이동하는 경우에도 해당 data에 대한 처리가 최적으로 이루어질 수 있도록 하는 기술\n: data에 대한 IO insight 정보로서 다음 정보가 포함될 수 있다\n\n:* data access patterns:\n::- 어떤 application이 얼마나 자주 이 data를 access하는지? (이 data를 access하는 application에 대한 정보가 없으면 insight가 잘못 적용될 수도 있을지도 모른다 - Hadoop 같은 경우는 어떻게 MapReduce Application 정보를 알 수 있을까? 혹시 MapReduce application에 대한 정보가 Hadoop layer에 가려지는 것은 아닐까? JobTracker/TaskTracker를 고려해야 할까?)\n::- 이 데이터(파일?)는 Rd(Read)-intensive 인가? Wr(write)-intensive인가?\n::- 이 데이터는 RRd(random read) / RWr(random write) / SRd(sequential read) / SWr(sequential write) 중 어느 것이 dominant한가? 혹은 Mix 되어 있다면 그 비율은 어떻게 되는가?\n\n:* data간 access pattern 연관성\n::- 이 data가 access되고 나면 어느 정도 확률로 어떤 다른 data가 access되는지?\n::- 어떤 data가 access되고 나면 어느 정도 확률로 이 data가 access되는지?\n\n:* data hot/cold history\n::- 이 data가 hot한 적이 얼마나 자주 있었나?\n::- 이 data가 hot한 시기가 어떤 패턴을 가지고 나타나는가?\n::- 한 번 hot하고 나면 이후에도 다시 hot할 가능성이 높은가?\n\n== PATENT-BRIAN-2013-005 ==\n\n=== IOWA based Proactive Data Placement 자체 특허 ===\n\n: 다양한 정보/Insight을 기반으로 Proactive하게 Data를 Placement하는 기술\n:: (Caching/Tiering in Local Case, Data Replication/Migration in Distributed Case)\n\n\n: 여기에, ML (혹은 HML까지도?)을 적용한다는 아이디어를 추가하자\n:: ML 기반의 IO Prediction\n::: ML을 통해서 예측을 한다면, 어떤어떤 정보들로부터, 어떤 예측을 해야하는 걸까?\n::: Fine-grained prediction이 말이 되는 소리인가?\n::: Coarse-grained prediction을 한다면 어느 스케일까지 fine/coarse-grained 해져야할까?\n\n\n:: ML 기반의 IO Insight (Data Placement를 위한 Macroscopic Guideline)\n::: ML을 통해서 최적의 배치를 할 수도 있는 것일까?\n:::: 가능함. 예를 들어, \"이러이러한 sign/indication을 보이는 data는 언제쯤 어떤 형태의 IO 양상을 보일 확률이 __%임\" 같은 형태의 insight이 있다면, \"이런 data는 현재 local system 뿐만 아니라 networked system의 상태도 같이 고려하여 어디에 위치시켜두는 것이 적당\" 하다는 식의 data placement를 \"proactive 하게\" 할 수 있겠음.\n::: IO Insight의 요건:\n::::# indication, as simple as possible\n::::# indication, as specific as possible\n::::# indication, efficiently traversable - corresponding indication case node들을 쉽게, 효과적으로 traversing하면서 최종 insight leaf에 도달 (Huffman code? Radix tree?)\n::::# indication, easily extensible - indication 추가 시에 변경되는 부분이 최소화될 수 있어야 함\n::: UCB study같은 형태로 나오는 것이 최선일까? 그런 형태/내용 외의 다른 것도 얻어낼 수 있을까?\n\n\n: HML이 도움이 되는 이유는 무엇일까?\n:: 굳이 HML이 아니더라도 ML 만으로도 잘 할 수 있는 범위는 어디까지일까?\n\n\n* Y1 = Proactive Data Placement\n* Y2 = Data-system-optimal Placement\n\n: Y1.x1 = 어느 address의 데이터(들)이\n:: Y1.x1.1 = 그 데이터들은 sequential access가 가능한 형태로 배열되어 있는가? (만약 그렇다면 굳이 cache시킬 필요가 있을까? 혹시 있는 건 아닐까? 정말 없을까? Sequential read하는 경우 SSD case와 HDD case를 비교해볼 필요 있음)\n:: Y1.x1.2 = 그 데이터들이 access되고 나면, ___%의 확률로 따라서 access되는 데이터들도 있지 않을까? (그렇다면, 그 놈들도 연달아서 미리 loading?)\n: Y1.x2 = 앞으로 얼마 후에\n: Y1.x3 = Access될 것인가?\n:: Y1.x3.1 = Read일까? Write일까?\n:: Y1.x3.2 = 그 얼마 후 Access되고 나서 몇 번을 더 Access될까? (이것을 알 수 있을까?)\n\n\n* X1 = IO Access Pattern\n* X2 = IO 유발자 정보\n\n\n\n\n\n\n\nproactive data placement (caching/tiering)를 위해서, layer abstraction 혹은 virtualization이 필요하지는 않을까?\n- 예를 들어, IBM의 GPFS에서 AFM (Active File Management)을 구현할 때, data의 lifecycle 및 next use에 의거한 automatic data transfer를 위해서, 기존에는 없었던 새로운 component 혹은 새로운 layer가 필요하지는 않았을까? [1][2]\n- proactive data placement 입장에서는, next IO use를 예측하거나, user/process context를 이해한다는 측면에서, 오히려 block layer보다는 file system layer에서 바라보는 것이 더욱 적절한 것은 아닐까?\nRead cache, write cache colocation을 하면 어떨까?\nadvanced tiering: access pattern-aware optimal placement (APOP)\n\n== PATENT-BRIAN-2013-006 ==\n\n=== SSD Retention Time Controlling for Caching/Tiering 특허 ===\n\n* Caching-optimal SSD Retention Time Control\n* SSD Retention Time Controlling for Caching\n\nCache-I/O의 특성에 맞도록 SSD Retention Time을 Control하는 기술.\n\n== PATENT-BRIAN-2013-XXX ==\n\n=== State Machine based Macro IO Prediction ===\n\n== PATENT-BRIAN-2013-00X ==\n\n=== Coarse-grained Spatial Locality Based SSD Cache I/O ===\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* DRAM Cache의 부족한 용량을 극복하기 위한 솔루션으로 SSD Cache가 도입되고 있음. 기본 원리는 자주 액세스되는 디스크 블록을 SSD에 Caching함으로써 HDD의 느린 I/O 속도를 극복하도록 하는 것임.\n* 그러나 블록 레이어에 구현되는 SSD Cache의 경우, Kernel에서 관리하는 Page Cache에 의해 이미 Hot data가 Serve되고 있기 때문에, Hit Ratio를 높이기에 근본적인 한계점을 가지고 있음.\n* 한편, kernel에서 관리되는 기존 Page Cache는 다음과 같은 한계점을 가지고 있음. (1) SSD 혹은 HDD에 비해 비싼 스토리지인 RAM 기반이기 때문에 다른 스토리지에 비해 작은 용량을 가지고 있는 경우가 일반적이므로 cache로 사용할 수 있는 공간의 제약이 큼. (2) 시스템에서 사용되지 않고 있는 idle RAM 영역을 이용하기 때문에, 시스템에서 구동되는 프로세스들이 요구하는 RAM 요구량이 많아지게 되면, 그만큼 page cache가 버려지게 되며 그만큼 시스템 I/O 성능의 저하가 발생하게 됨. 또한 이로 인해 성능의 편차가 불규칙하다는 단점 또한 근본적으로 가지고 있음.\n* 한편, SSD를 이용하는 page cache가 기존에 시도된 적이 있으나 매 page access 시마다 SSD에 page를 저장하는 메커니즘으로서 (synchronous I/O) NAND flash와 RAM I/O 특성 차이로 인해 기인하는 근본적인 성능적 한계점을 가지고 있음.\n\n<br/>\n\n\n=== # 본 발명의 특징 / 효과 ===\n\n\n=== # 대표 청구항 ===\n\n* (page tiering 기반의 hybrid cache에서) spatial locality에 기반한 효율적인 page cache I/O 방법\n** 고속이면서도 자원 효율적으로 spatial locality 패턴을 파악하는 방법\n***(range size를 동적으로, 혹은 서로 다르게 할 수 있는 방법은 필요 없을까?)\n\n* page chunk handling 방법\n** [host side] spatial-locality가 있는 page들이 가급적 page chunk 단위로 묶이도록 하는 방법\n** [host side] SSD 내부의 parallelism을 극대화할 수 있도록 page chunk 크기를 정하는 방법 (i.e., channel_# x erase_block_size)\n** [host side / ssd side] tier-2 page cache에 저장된 특정 page가 access될 때, 그 page가 속한 page chunk의 데이터를 같이 pre-loading 하는 방법\n*** 해당 page chunk에 대한 status update하는 것이 필요할까?\n\n* page chunk eviction 방법\n** [ssd side] tier-2 page cache에서 page chunk를 eviction 시키기 전에, page chunk 중에서 popular 한 page는 SSD에서 evict하기 전에 RAM에 올리는 것\n\n\n=== # 기술 상세 ===\n\n=== # 선행 기술 ===\n\n다음 검색식\n (Spatial locality based I/O SSD cache)\n으로 1건의 미국 공개/등록 문건을 검색할 수 있었으나,\n본 발명과 유사한 spatial locality based I/O for SSD cache 관련 선행 기술은 발견하지 못하였음.\n\n유사한 주제를 다루는 논문으로\n __\n이 있었음.\n\n그러나 __ 측면에서 본 발명과 상이함.\n\n<br/>\n\n\n=== # 침해 적발 ===\n\n== PATENT-BRIAN-2013-00X ==\nContent Repeatability-Aware SSD Cache Management\n\n=== 대표 청구항 ===\n\n== PATENT-BRIAN-2013-00X ==\n=== Likely Zone Based Page Pre-placement ===\n\n\n* periodicity의 특성을 이용해 pre-placement하는 개념도 추가할 수 있을까?\n\n* associated-likely-zone 기반의 page pre-placement (to RAM)\n\n* page cache tiering의 방향이 RAM으로부터 SSD로 가는 경우는 page eviction 시 class-2에 해당하는 page들을 SSD로 저장하는 경우임. page cache tiering의 방향이 SSD로부터 RAM으로 가는 경우는 class-1의 “currently-hot”한 page들과 매칭되는 associated-likely-zone이 존재하고, 동시에 현재 시스템에 page cache로 사용할 수 있는 RAM의 여유 공간이 존재할 때, SSD에 저장되어 있었던 해당 associated-likely-zone을 RAM에 미리 올리는 경우임. page cache로 사용할 수 있는 RAM의 여유 공간보다 associated-likely-zone의 크기가 큰 경우에는 RAM의 여유 공간 만큼만 우선적으로 RAM에 올려짐.\n\n* 이때, associated-likely-zone 중에서 우선적으로 RAM에 올려져야 할 영역을 결정하는 방법으로써, “currently-hot”한 현재 data와 지리적으로 가까운 영역의 data를 우선적으로 선택하는 방법, associated-likely-zone의 data들 중에서 access frequency가 높았던 data들을 우선적으로 선택하는 방법 등을 사용할 수 있다. 이에 대한 구체적인 방식은 본 특허와 개별적으로 구현될 수 있으므로, 별도의 특허에서 다루어진다.\n\n* associated-likely-zone은 과거의 access 패턴에 기반하여 서로 비슷한 시간대에 access되었던 data들의 set으로 구성한다. 여기서 ‘서로 비슷한 시간대’라는 개념은 window 2의 window size에 의해 결정된다.\n\n* 특정 address arange가 LZ인지, ULZ인지 구분하는 방법?\nLZ (Likely Zone)와 ULZ (Unlikely Zone)을 선정하는 방법:\naccess되는 page를 보면, 해당되는 inode정보와 이를 access한 process 정보를 알 수 있다. inode 정보를 보면, 이 page가 어떤 파일에 연결되어있는지를 알 수 있다. 이렇게 되면 그 파일이 걸쳐있는 address space 정보 (LBA range)를 알 수 있으며, 이는 likely zone의 일부로 마킹될 수 있다. 여기서 해당 파일 전체를 likely zone으로 할 것인지 해당 파일의 일부를 likely zone으로 할 것인지는 별도의 likely zone determinition rule에 의해 결정된다. 그리고 likely zone으로 마킹된 영역을 언제 class-2 t2 page cache media (e.g., SSD)에 loading할 것인지, loading한다면 likely zone 영역의 데이터들을 어떤 순서로 읽어들일지는 likely-zond loading rule에 의거하여 결정된다. LZ과 ULZ를 선정하는 빈도/시기는\n\n== PATENT-BRIAN-2013-00X ==\n\n* 하나 이상의 SSD를 Page Cache Media로 사용하는 경우, (1) SSD array manager와 연계하여 보다 효율적인 caching I/O를 달성하는 방법 (RACS 기반의 기존 SAVL을 그대로 이용하되 interfacing에 관련된 내용), 혹은 (2) 복수개의 SSD를 caching I/O에 맞도록 coordination하는 방법 (RACS 기반의 기존 SAVL에 추가적으로 caching I/O를 잘 handling할 수 있도록 하는 최적화된 I/O management 방법)\n\n\n* 복수 개의 SSD를 tier-2 page cache media로 사용하는 경우, SSD 1에 free space가 부족한데, 그 SSD 내에 cache되어 있는 page chunk들이 계속 caching해둘만한 가치가 있는 경우, page chunk migration (between SSDs)을 수행한다. 이때, tier-1 page cache 내의 page node 내의 page data location field 값은 update한다. (이때, 누가 migration을 initiation하는 것이 적절할까? host의 hybrid page cache manager? 혹은 activie SSD? 아무래도 SATA 기반의 SSD를 사용하는 경우에는 전자가 좀 더 현실적일 것으로 보임)\n\n\n* tier-2 page cache의 eviction threshold period를 두어서 RAM page cache 경우보다는 길겠지만 tier-2 page cache의 총량이 허용할 수 있는 page 용량을 감안하여 계산된 time period 동안 access 실적이 없으면 tier-2 page cache 중에서도 evictable flag를 set하게 되는데, 이때 복수개의 SSD를 tier-2 page cache media로 사용하는 경우, 전체 SSD 가용 용량을 합산해야 한다.\n\n== PATENT-BRIAN-2013-00X ==\nMultiple I/O Queue Handling for SSD Cache\n\n\n[청구항]\n\n== PATENT-BRIAN-2013-00X ==\npage chunk I/O handling mechanism for multi-tenancy SSD page cache\n\n\n[요약]\n물리적인 SSD 하나가 통째로 page cache로 사용되는 경우에는 SSD 전체를 위와 같이 나누어 사용하면 되겠으나, 하나의 SSD를 page cache media와 다른 용도로 같이 사용해야 하는 경우를 위한 구조 및 방법은 별도의 특허에서 기술하는 것으로 함. page cache media로 사용되는 공간과 다른 목적으로 사용될 공간을 별도의 partition으로 잡고, page cache media로 동작하기 위한 partition을 다시 meta 정보 영역과 page data 영역으로 slice하여 사용함. 이때, SSD는 page cache media로 partitioning된 영역에 해당하는 I/O에 대해서는 병렬성과 page chunk lookup table의 단순성을 극대화 할 수 있게 설계된 page chunk I/O 방식으로 처리할 수 있도록 하는 것이 필요함.\n\n[청구항]\n\n\n== PATENT-BRIAN-2013-00X ==\n\n=== # I/O Pattern-optimal Data Placement for Tiering ===\n\n* Automatic tiering 시, 단순히 hot data들을 fast media에 가져다 놓고 마는 것이 아니라, IO bottleneck이 미연에 방지될 수 있도록 data의 access pattern을 aware해서 차별적으로 배치하는 방법\n예) (a) random-read-intensive 한 data들, (b) sequential-write-intensive한 data들을 다른 방식으로 배치 (tiering)\n\n\n* 이에 필요한 data access pattern 모니터링/분석 방법\n데이터 수집 및 분석 시 PCIe 카드 엔진 활용 가능?\nNIC 이나 DMA를 통해서 data move가 일어나는 경우, PCIe 카드 등을 통해서 IO stream 분석\n\n\n* 이를 위해 필요한 system architecture 구조\n기본적으로 하나 이상의 SSD와 하나 이상의 HDD, 그리고 PCIe 카드, DRAM 일부 사용 방식, Tiering Mapping Table 구조, ...\n\n\n=== # 발명의 이용분야 ===\n=== # 배경 / 기존 기술의 문제점 ===\n=== # 본 발명의 특징 / 효과 ===\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n=== # Memo / Questions ===\n\n\n<br/>\n\n\n\n== Patent pool ==\n\n\n=== (SmartSSD API) SSD-internal I/O pattern logging interface and mechanism ===\n\n\n==== Questions ====\n\n* SmartSSD에서 제공할 수 있는 logging 서비스로서 어떤 것들이 있을 수 있나?\n:- 어느? 정도의 free space를 필요로하는 critical (heavy) I/O가 어떤? 주기로 도래할 지 알 수 있을까?\n:- I/O prediction에 도움될 수 있는 정보를 SmartSSD가 기록했다가 필요한 때 (안전한 방법으로?) 줄 수 있을까?\n:- I/O prediction까지는 아니더라도 해당 SSD의 I/O wellness(어떻게 정의?)를 측정했다가 bottleneck을 회피하는 데 유용한 정보를 제공할 수 있을까?\n:- 어떤 SSD가 현재 주어지고 있는 I/O workload에 대해 list performance spec을 만족하는데 어려움을 겪고 있다는 것을 알려줄 수 있는 정보가 어떤 것이 있을까? (SSD 내 write buffer의 fullness 혹은 I/O queue의 유동성? amount of free space in over-provisioning area?) (-> I/O wellness 라는 metric을 이것과 연관시켜 정의할 수도 있으며, 결국 SLA 혹은 Performance QoS와 연관시킬 수 있음)\n:- 지금까지의 S.M.A.R.T.와 비교하였을 때, 어떤 차별점이 있는가? 기존의 S.M.A.R.T.가 제공하지 못하던 타입의 정보를 제공하고, 이로 인해 기존에는 불가능했던 새로운 알고리즘 구현 혹은 새로운 서비스 제공이 가능해짐을 보이면 좋겠음.\n\n\n\n:- workload의 history?\n:- 각 erase block이 erase되어야만 했던 주기?\n:- free space의 추이 (얼마나 많이 남아 돌던지)?\n:- I/O의 heaviness 패턴?\n:- SSD내 write buffer (혹은 write cache)의 utilization정보? (즉, write buffer가 넘칠 정도가 되어서 I/O wait을 해야만 했던 상황이 얼마나 자주 발생했는지, write buffer의 가득찬 정도를 백분율로 표현한다고 했을 때, 평균/표준편차 등으로 대표할 수 있는 normal distribution을 따르는지?\n:- 전체 sequential read/write \n\n\n==== 배경 ====\n\n* 각 SSD 모델별로, 또 동일한 모델의 SSD라 하더라도 어떤 workload에 노출되어왔는지에 따라, 현재 낼 수 있는 I/O performance가 동일하지 않을 수 있다 (!check! 관련 실험 결과 - SSD 830을 이용하여 같은 시간 동안 하나의 host에서 생성되는 workload들을 나누어 받았다 하더라도 내부적인 free block의 갯수 및 random write에 의한 block 내 파편화등의 상태가 상이하여 성능에 차이가 나는 것을 보여줄 것. uFLIP 혹은 filebench 활용 가능). 한 예로, SSD가 어느 호스트의 어느 file system에 매핑되었는지에 따라 그 SSD가 받는 workload의 특성이 다를 수 있다. file system mount point가 달라지거나, 기존과 다른 새로운 응용이 설치/서비스되는 상황이 되면 \n\n\n=== (Tiering-based?) Proactive Data Placement ===\n* 핵심 아이디어\n: \"proactive\" 하게 data를 배치시킨다는 것 자체!\n: Local node 내에서의 vertical tiering 뿐만 아니라 분산 node들 간의 horizontal tiering도 염두에 둘 것\n\n\n* 기존 기술과의 명료한 대비 (naive I/O prediction vs. full-fledged I/O prediction)\n: 기존 기술은 누적 hit count 정보에 의지하는 naive I/O prediction으로 볼 수 있음. 이러한 방식은 workload의 변화를 제대로 반영하지 못하기 때문에, static한 workload에 대해서는 잘 동작하지만, moving target처럼 dynamic한 workload에 대해서는 오히려 과거의 누적 hit count metric이 현재의 workload 패턴을 왜곡시키는 문제점을 가지고 있음. (temporal locality와 spatial locality가 깨지는 순간이 여러번 존재할 수록 기존의 naive I/O prediction 방식은 성능 향상이 어려워짐)\n\n* 경쟁 기술과의 차별화\n: EMC의 FAST 기술이 안고 있는 근본적인 한계점은 무엇일까?\n: data access 패턴의 hot/cold 만 분류해서 hot은 fast tier에, cold는 slow tier에 두는 것이 전부인가? 아니면 그것 외에 뭔가가 더 있는가?\n: 어떻게 보면 기존의 automated storage tiering은 naive proactive placement로 볼 수도 있다. (과거에 자주 access되었던 data가 앞으로도 자주 access될 것이라고 믿고 data를 이동시키는 것이므로. 그러나 근거가 부족함)\n:: 이러한 naive proactive placement 방식으로 야기되는 단점이 있다. 만약 과거에는 자주 access되었는데 마침 tiering되고 난 후에 자주 access되지 않게 되면, 괜히 SSD의 wear-out만 유발시킨 결과가 된다. 다음 tiering 주기가 돌아오기 전 까지는 계속 느린 media에서 I/O가 serve되기 때문에 그만큼 pain이 된다.\n:: 물론 read에 대해서는 cache를 적극 활용함으로써 첫 access 시에만 slow media access로 인한 penalty를 얻고 이후에는 cache가 제공하는 수준의 성능을 얻을 수 있게 된다.\n:: 그러나 write에 대해서는 문제가 다르다. HDD의 경우 sequential write 경우에는 큰 문제가 되지 않는다. 그러나 random write 특성을 가지고 있으며, 게다가 write-intensive한 I/O라면? 그런데 random write이면서 write-intensive한 경우, write되는 address range가 생각보다 넓지 않다면 어떻게 될까? 즉 특정 구간 특정 데이터에 대한 update가 빈번한 것을 의미한다.\n:: write address range가 N개의 4KB 블럭으로 이루어져 있고, Storage System 내에 물리적인 Disk 갯수가 M개 존재한다고 가정하자. 만약 M이 N보다 적절하게 커서 RAID 10을 하건, RAID 5 등으로 이루어져 있건 간데, N개의 4KB 블럭을 각각 별도의 HDD로 분산 시킴으로써 random write을 random write이 아닌 것처럼 보이게 할 수 있다면? 예를 들어 VNX 5300 처럼 SAN 박스 하나 내에 HDD가 125개가 들어있고, random하고 intensive한 write pattern이 오고 있고, write access range가 125개 이하의 address 내에서 반복되고 있다면, 매번 도달하는 random write request를 마치 RAID 0로 striping 하듯이 계속 다른 HDD로 보냄으로써 I/O de-randomization을 할 수 있을 것이다. 여기서 좀 더 나아가서 하나의 request에 대해서 HDD가 완벽하게 처리하는 데에 걸리는 시간이 10ms 이고, 매 random I/O가 도달하는 평균 시간은 (평균 가지고 되려나? 아무튼 이것은 조금 뒤에 다시 생각해보자) 1ms 라고 한다면, 이론적으로 10번의 random I/O가 지난 다음, 11번째의 random I/O가 올 때에는 처음에 write했던 HDD에다가 다시 write을 해도 된다. 즉, 그 HDD에서 직전의 I/O가 끝나기를 기다리고 있지 않아도 된다는 것이다. 그러나 이러한 방식은 나중에 scatter했던 I/O들을 다시 불러모으려고 할 때 contribution한 HDD가 다른 I/O를 serving하고 있지 않을 수 있어야 최고의 성능을 낼 수 있게 된다. 즉, HDD cluster 구성을 상당히 dynamic하게 가져갈 수 있다면 어떨까? 이러한 dynamic clustering이 정말 최고의 효과를 낼 수 있는 workload case로는 어떤 것이 있을까? data placement를 함에 있어서 결국은 어딘가에 써야 할 것이고, (slow tier로 마크된 HDD들 array에다가 data를 쓴다고 그냥 푸대접하면서 써버릴 것이 아니다) slow tier에다가 쓸 때에도 나중에 어떻게 read되고 다시 write 될 지를 고려한다면, workload 특성에 따라서 concurrent I/O의 갯수 및 address range 크기가 다를 수 있는데, 그것을 aware해서 write을 해둔다면, 비록 slow-tier에다가 write했지만, 그리 slow하지만은 않은 성능을 내게 할 수 도 있을 것이다. 이것은 proactive data placement에 대한 이야기가 아니다. proactive와는 별개로, automated storage tiering을 함에 있어서 workload characteristics를 고려한 data placement에 대한 이야기이다.\n\n\n\n\n서로 독립적인 I/O stream의 갯수가 100개 라면 (즉 100개의 process가 I/O를 쏟아내고 있는 경우), 그리고 I/O queue의 크기가 N_Q라면, 어떻게 이러한 문제를 해결할 수 있을까?  \n\n  \n:: write에 대해서는 \n:: write-intensive하다는 것의 정의는? 이러한 경우에는 in-memory write caching (OS가 허용하는 범위의 delayed write을 최대한 활용)을 이용하되 transaction 기반으 atomicity를 보장함으로써 문제를 부분적으로 해결할 수 있다. transaction으로 묶여질 수 있는 여러 번의 I/O request (write)가 끝나기 전까지는 commit되지 않은 것으로 치는 것임. Fusion IO의 atomic write은 이를 어떻게 해결하는지? \n\n만약 write commit이 매우 중요한 민감한 데이터에 대해서는 어떻게 해야할까? 그리고 SSD-internal memory buffer를 이용해서\n: SAN 장비 내에서의 HDD와 SSD 간의 tiering만 되는 것일까? (vertical tiering within local node)\n: SAN 장비 간의 tiering이 되기 위해서는 어떤 것이 더 필요할까? EMC에서 이미 그러한 기술/솔루션을 가지고 있지는 않을까? (horizontal tiering between boxes)\n\n* 다양한 사례\n: 기존에 이미 생성되어 있던 data를 미래 access 예측에 따라 위치 변동을 시키는 경우\n: Tiering을 한다고 했을 때, access 빈도에 따라서 fast tier / slow tier 간 이동시키는 것이 전부일까? 그런 것 말고 다른 차원의 tiering은 없을까?\n: 새롭게 write되려는 data를 처음부터 어디에 배치시키는 것이 좋을까?\n\n* Placement 접근 방식\n: Tiering으로 한정?\n: Tiering과 Caching과의 결합 방식? (Caching engine에게 hint를 주는 방식)\n\n* I/O Prediction 결과를 받아서 proactive하게 data를 tiering 시키는 방법 및 아키텍쳐\n* Key questions\n:- 기존엔 proactive tiering이 없었나?\n:- 만약 없었다면 어떤 어떤 부분들을 청구항으로 넣어야 할까?\n:- 만약 있었다면 어떤 차별화가 필요할까?\n\n=== I/O Workload Analyzer Engine ===\n* I/O Trace 및 다양한 시스템 정보를 기반으로 I/O를 prediction하는 방법 및 구조\n*\n\n== Disclosure of Invention :: Template ==\n\n<!--\n== PATENT-BRIAN-2013-00X ==\n-->\n\n=== # RAM-SSD Hybrid Page Cache Architecture ===\n=== # 발명의 이용분야 ===\n=== # 배경 / 기존 기술의 문제점 ===\n=== # 본 발명의 특징 / 효과 ===\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n=== # Memo / Questions ===','utf-8'),(1956,'== PATENT-BRIAN-2013-001 ==\n\n=== # RAM-SSD Hybrid Page Cache Architecture ===\n\n[[Bnote patidea 2013-001]]\n\n== PATENT-BRIAN-2013-002 ==\n=== # Low-computation-overhead and Memory-efficient Periodicity Detection Method ===\n[[Bnote patidea 2013-002]]\n\n== PATENT-BRIAN-2013-003 ==\n\n=== 맵리듀스 작업의 병목 탐지 및 원인 분석을 위한 모니터링 프레임워크 기술 (A monitoring framework for detecting and analyzing execution bottlenecks of MapReduce jobs) ===\n\n[[Bnote patidea 2013-003]]\n\n== PATENT-BRIAN-2013-004 ==\n\n<!-- === Straggler-immune Data/Task Placement in the Distributed Environment === -->\n\n=== Straggler-immune Data Placement in the Distributed Environment (HDFS?) ===\n\n\n\n\n=== Memo ===\n\n* title candidates\n: outlier(straggler, failure, ...)-immune data placement for distributed file system\n: straggler-immune data placement in the distributed file system (DFS)\n\n\n* Assumptions // 환경\n: replica management가 있는 DFS 환경\n: replica management algorithm 변경 가능\n: MapReduce/HDFS처럼 data가 있는 곳에 computation을 보내는 구조\n: DFS 위에서 Hadoop MapReduce처럼 분산 병렬 처리를 수행하는 환경\n\n* Assumptions // Failure Characteristics \n: straggler 발생과 task의 type 간의 연관성이 있음\n: {task type, node} tuple이 \n\nHDFS 및 MapReduce 환경에서,\n\n\n특정 node와 특정 task type의 조합과 straggler 발생 빈도 간에 연관 관계가 있을 수 있을까?\n\n\n즉 straggler가 발생했던 case를 관찰했을 때,\nnode 정보만으로는 패턴 (혹은 straggler 발생과의 연관성)이 보이지 않고,\ntask type 정보만으로도 패턴 (혹은 straggler 발생과의 연관성)이 보이지 않지만,\nnode 정보와 task type 정보를 같이 고려했을 때 straggler 발생 빈도/확률과 연관성을 볼 수 있었다면?\n\n\n\n\n* Bottleneck History Record (BHR) based approach\n: do not throw away the bottleneck experience (history). KEEP IT to use the knowledge for later use.\n\n* Replica management\n: at the very first time to place the data\nDistributed File Systems\n\n\n\n=== # 요약 ===\n\n\n=== # 발명의 이용분야 ===\n\n* Hadoop MapReduce/HDFS 혹은 이와 유사한 분산 처리 시스템이 구동되는 Enterprise 데이터 분석 클러스터.\n* Hadoop MapReduce/HDFS 혹은 이와 유사한 분산 처리 시스템이 구동되는 Public Cloud 데이터센터\n\n\n----\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* Hadoop의 기본 DFS인 HDFS (Hadoop Distributed File System)은 replica management를 수행하고 있음.\n\n\n* HDFS에서의 replica management는 3-copy replica 구성 시, 다음 몇 가지 원칙에 의해 data를 분배하고 있음.\n:- 하나의 node에 동일 block이 두 개 이상 존재하지 않는다\n:- 하나의 rack에 동일 block이 세 개 이상 존재하지 않는다\n:- 첫 번째 replica는 client가 구동하고 있는 node에 배치\n:- 두 번째 replica는 첫 번째 replica가 있던 node가 속하지 않은 다른 rack의 임의의 node에 배치\n:- 세 번째 replica는 두 번째 replica가 배치된 rack 내의 다른 node에 배치\n:- 1st-2nd-3rd replica 배치는 순차적으로 실행\n\n\n* Yahoo!의 Hadoop Cluster에서 10개월간 구동된 17만개의 MapReduce job들을 분석한 연구에 따르면 약 3% 정도의 Job들이 fail되었으며, 각 task의 특성과 failure 발생과 연관성이 있음을 확인할 수 있다. (예를 들어, MapReduce 전체 failure의 80% 이상이 map task에서 발생하였으며, map task failure의 36%는 array indexing error에 의한 것이었음. 그리고 reduce task 의 23%는 I/O exception에 의한 것이었음)  이러한 failure 및 straggler로 인해 task restart가 많이 발생하고 있으며, 이는 MapReduce/HDFS 성능을 저하시키는 주요 요인임.\n\n\n* 현존 Hadoop MapReduce/HDFS 시스템에서는 straggler가 발생했다고 판단되면, 해당 task를 drop 시키고 새로운 node에서 task가 실행될 수 있도록 하고 있음. 즉, 이미 발생한 straggler에 대해서는 speculative execution을 수행하고 있지만 여전히 한계점은 존재함. (1) speculative execution을 위해 필요한 additional data copy overhead 존재. (2) 새로운 execution node를 찾는다 하더라도 그 node가 straggler-free한 node인지 보장할 수 없기 때문에, 제2, 제3의 straggler가 발생할 가능성 존재. (3) additional copy를 하려고 하더라도 이미 task들이 tight하게 많이 구동되고 있는 상황에서, 여유 execution slot을 가지고 있는 적절한 node를 바로 찾지 못할 수 있으며, 이렇게 기다리는 것 자체가 job completion time을 증가시키는 부정적인 효과가 있음.\n\n\n----\n\n=== # 본 발명의 특징 / 효과 ===\n\n\n* 특징\n:- 기존처럼 straggler가 발생한 후에 대응하기 보다는 (사후 대응), HDFS에 처음 data가 놓여질 때부터 straggler-immune node에 배치될 수 있도록 하는 사전 대응 방식을 특징으로 하고 있음.\n:- {node, task-type, bottleneck-risk-score} tuple로 구성되는 Bottleneck History Record (BHR) 정보에 기반하여 해당 task-type에 대해 bottleneck-risk-score 값이 가장 작은 node에 replica data를 배치하는 방식임\n:- {node, task-type}에 대한 bottleneck-risk-score 정보는 JobTracker에 추가되는 Bottleneck History Record Manager 모듈에 의해 update됨\n:- 참고로, 기존 HDFS에서의 data placement (replica management 시)에서는 이러한 straggler-immune data placement는 고려되어 있지 않음.\n\n\n* 기대 효과\n:- speculative execution을 위한 data copy overhead 감소\n:- 제2, 제3의 straggler / failure 발생 확률 감소\n:- 결과적으로, Hadoop MapReduce Job의 성능 향상 효과\n\n\n* 구현의 용이성\n:- Apache Jira HDFS-385에서 언급된 pluggable interface를 이용 시, 본 발명에서 제안하는 data placement 알고리즘을 HDFS의 block placement algorithm으로 추가하기가 용이함.\n\n\n* 침해 적발의 용이성\n:- namenode에서 수집하는 데이터들을 관찰하거나, HDFS-385 interface를 통해 오가는 데이터들을 관찰하였을 때, node, task-type, failure rate 정보를 namenode가 (혹은 pluggable data placement module이) 읽어들이고, 그 중 가장 failure rate 값이 낮은 하나의 node가 replica data를 저장하기 위한 datanode로 선택된다면, 본 특허를 침해한 것으로 판단 가능.\n\n\n----\n\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n\n\n* 기존처럼 straggler가 발생한 후에 대응하기 보다는 (사후 대응), HDFS에 처음 data가 놓여질 때부터 straggler-immune node에 배치될 수 있도록 하는 사전 대응 방식을 특징으로 하고 있음.\n\n\n* {node, task-type, failure rate} tuple 정보에 기반하여 해당 task-type에 대해 failure rate이 최소화 될 수 있는 node에 replica data를 배치하는 방식임\n\n\n==== 시스템 구성 요소 ====\n\n\n==== 처리 절차 ====\n\n\n==== 예상 효과 ====\n\n* Anomaly (straggler, failed task) 발생 자체를 줄임으로써, Straggler 혹은 Failed Task로 인해 야기되는 추가 처리 비용을 감소시킬 수 있음.\n\n* Straggler의 경우, speculative execution으로 야기되는 additional data copy overhead 감소 (사라지거나 감소됨) 효과를 기대할 수 있음. 특히, HDFS block size가 큰 경우 (처리 해야 할 data는 크지만, node의 수가 적은 경우, 64MB 이상으로 tuning하여 사용하는 경우가 많이 있음 - 그런데, 실제로 이렇게 tuning하면 어떤 장점/효과가 얼만큼 생기나?) additional data copy로 인한 overhead가 그만큼 커지게 되므로, 이 경우 straggler 발생 확률을 낮춤으로써 얻는 이득 역시 그만큼 커지게 됨.\n\n* Failed task의 경우, 상황에 따라서 두 가지 처리 옵션이 있다. 첫 번째 옵션은 failure가 발생했던 해당 node에서 task를 재시작하는 방법이며, 두 번째 옵션은 다른 node에서 task를 재시작하는 방법임.\n\n* Task failure의 원인이 해당 node의 H/W 혹은 S/W에 문제가 있는 것이 아니었다면 첫 번째 옵션을 택할 수 있다. 물론 H/W 혹은 시스템 S/W 결함이 아니었다는 것을 알수 있었어야 한다. 그러나 해당 node의 H/W 혹은 S/W에 문제가 있다는 것을 알고 있는데, 당장 다른 node의 execution slot도 여유가 없는 상황이라면, execution slot이 생길 때까지 좀 더 기다렸다가 재시작을 해야 한다. 이때, 기다려야만 하는 경우라면, 그만큼 job 처리 속도의 저하로 이어진다. 다른 노드에서 재시작을 하게 되더라도, 역시 additional data copy가 필요하며, 이로 인한 overhead는 피할 수 없다.\n\n\n----\n\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n\n* Google patent search (2 results, no relevant result)\n (HDFS OR \"hadoop distributed file system\") (((block replica) OR data) placement) (straggler OR fail*)\n\n* Google patent search (2 results, no relevant result)\n (HDFS OR \"hadoop distributed file system\") (((block replica) OR data) placement) bottleneck\n\n* Google patent search (5 results)\n HDFS block replica placement\n:- [http://www.google.com/patents/EP2288998A2?cl=en Directed placement of data in a redundant data storage system]\n:: Filed 9 Apr 2009 - Published 2 Mar 2011, John Howe - Omneon, Inc.\n\n\n\n* 검색식\n: mapreduce straggler (\"historical record\" OR \"history\")\n: 2건\n\n:* System and Method for Analyzing Data Records\n:: [http://www.google.com/patents/US20120215787 www.google.com/patents/US20120215787]\n:: App. - Filed 28 Feb 2012 - Published 23 Aug 2012 - Jeffrey Dean - Dean Jeffrey, Dorward Sean M, Ghemawat Sanjay, Pike Robert C, Quinlan Sean\n\n:* Scalable user clustering based on set similarity\n:: [http://www.google.com/patents/US7962529 www.google.com/patents/US7962529]\n:: Grant - Filed 6 May 2010 - Issued 14 Jun 2011 - Mayur Datar - Google Inc.\n\n=== # Memo / Questions ===\n\n==== References ====\n\n\n\n* Google search\n map reduce straggler study\n\n:- [http://static.usenix.org/event/osdi08/tech/full_papers/zaharia/zaharia_html/ Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]\n:: Matei Zaharia, Andy Konwinski, Anthony D. Joseph, Randy Katz, Ion Stoica // University of California, Berkeley\n\n:- [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CDAQFjAA&url=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2FUM%2Fpeople%2Fsrikanth%2Fdata%2FCombating%2520Outliers%2520in%2520Map-Reduce.web.pptx&ei=pq1iUer9NK6eiAfN2IHYBQ&usg=AFQjCNEOOEtTE2_nVb6f2qQN09OpoLcS5A&sig2=HakGM53pMqVB1y2PqhQZJQ Combating Outliers in Map-Reduce - Microsoft Research]\n:: Srikanth Kandula, Ganesh Ananthanarayanan, Albert Greenberg, Ion Stoica, Yi Lu, Bikas Saha, Ed Harris\n\n\n* Google search\n map reduce straggler study once relationship\n\n:- [http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]\n:: Soila Kavulya, Jiaqi Tan, Rajeev Gandhi and Priya Narasimhan. Carnegie Mellon Univ., Pittsburgh, PA, USA\n:: [http://www.pdl.cs.cmu.edu/PDL-FTP/associated/CMU-PDL-09-107.pdf Another Version, CMU-PDL-09-107 December 2009]\n:: [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster, CCGrid 2010]]\n\n:- [http://cseweb.ucsd.edu/~vahdat/papers/themis_socc12.pdf Themis: An I/O-Efﬁcient MapReduce // SOCC 2012]\n\n\n\n\n<br/>\n\n== PATENT-BRIAN-2013-007 ==\n\n=== data와 IO insight을 packaging 하는 기술 ===\n\n: 해당 [[data에 대한 IO pattern/insight 정보]]를 data와 함께 packaging하여 (마치 object-oriented manner) 같이 이동되게 함으로써, replication, migration, (node 간 tiering?) 등 분산 환경에서 data가 여러 노드로 이동하는 경우에도 해당 data에 대한 처리가 최적으로 이루어질 수 있도록 하는 기술\n: data에 대한 IO insight 정보로서 다음 정보가 포함될 수 있다\n\n:* data access patterns:\n::- 어떤 application이 얼마나 자주 이 data를 access하는지? (이 data를 access하는 application에 대한 정보가 없으면 insight가 잘못 적용될 수도 있을지도 모른다 - Hadoop 같은 경우는 어떻게 MapReduce Application 정보를 알 수 있을까? 혹시 MapReduce application에 대한 정보가 Hadoop layer에 가려지는 것은 아닐까? JobTracker/TaskTracker를 고려해야 할까?)\n::- 이 데이터(파일?)는 Rd(Read)-intensive 인가? Wr(write)-intensive인가?\n::- 이 데이터는 RRd(random read) / RWr(random write) / SRd(sequential read) / SWr(sequential write) 중 어느 것이 dominant한가? 혹은 Mix 되어 있다면 그 비율은 어떻게 되는가?\n\n:* data간 access pattern 연관성\n::- 이 data가 access되고 나면 어느 정도 확률로 어떤 다른 data가 access되는지?\n::- 어떤 data가 access되고 나면 어느 정도 확률로 이 data가 access되는지?\n\n:* data hot/cold history\n::- 이 data가 hot한 적이 얼마나 자주 있었나?\n::- 이 data가 hot한 시기가 어떤 패턴을 가지고 나타나는가?\n::- 한 번 hot하고 나면 이후에도 다시 hot할 가능성이 높은가?\n\n== PATENT-BRIAN-2013-005 ==\n\n=== IOWA based Proactive Data Placement 자체 특허 ===\n\n: 다양한 정보/Insight을 기반으로 Proactive하게 Data를 Placement하는 기술\n:: (Caching/Tiering in Local Case, Data Replication/Migration in Distributed Case)\n\n\n: 여기에, ML (혹은 HML까지도?)을 적용한다는 아이디어를 추가하자\n:: ML 기반의 IO Prediction\n::: ML을 통해서 예측을 한다면, 어떤어떤 정보들로부터, 어떤 예측을 해야하는 걸까?\n::: Fine-grained prediction이 말이 되는 소리인가?\n::: Coarse-grained prediction을 한다면 어느 스케일까지 fine/coarse-grained 해져야할까?\n\n\n:: ML 기반의 IO Insight (Data Placement를 위한 Macroscopic Guideline)\n::: ML을 통해서 최적의 배치를 할 수도 있는 것일까?\n:::: 가능함. 예를 들어, \"이러이러한 sign/indication을 보이는 data는 언제쯤 어떤 형태의 IO 양상을 보일 확률이 __%임\" 같은 형태의 insight이 있다면, \"이런 data는 현재 local system 뿐만 아니라 networked system의 상태도 같이 고려하여 어디에 위치시켜두는 것이 적당\" 하다는 식의 data placement를 \"proactive 하게\" 할 수 있겠음.\n::: IO Insight의 요건:\n::::# indication, as simple as possible\n::::# indication, as specific as possible\n::::# indication, efficiently traversable - corresponding indication case node들을 쉽게, 효과적으로 traversing하면서 최종 insight leaf에 도달 (Huffman code? Radix tree?)\n::::# indication, easily extensible - indication 추가 시에 변경되는 부분이 최소화될 수 있어야 함\n::: UCB study같은 형태로 나오는 것이 최선일까? 그런 형태/내용 외의 다른 것도 얻어낼 수 있을까?\n\n\n: HML이 도움이 되는 이유는 무엇일까?\n:: 굳이 HML이 아니더라도 ML 만으로도 잘 할 수 있는 범위는 어디까지일까?\n\n\n* Y1 = Proactive Data Placement\n* Y2 = Data-system-optimal Placement\n\n: Y1.x1 = 어느 address의 데이터(들)이\n:: Y1.x1.1 = 그 데이터들은 sequential access가 가능한 형태로 배열되어 있는가? (만약 그렇다면 굳이 cache시킬 필요가 있을까? 혹시 있는 건 아닐까? 정말 없을까? Sequential read하는 경우 SSD case와 HDD case를 비교해볼 필요 있음)\n:: Y1.x1.2 = 그 데이터들이 access되고 나면, ___%의 확률로 따라서 access되는 데이터들도 있지 않을까? (그렇다면, 그 놈들도 연달아서 미리 loading?)\n: Y1.x2 = 앞으로 얼마 후에\n: Y1.x3 = Access될 것인가?\n:: Y1.x3.1 = Read일까? Write일까?\n:: Y1.x3.2 = 그 얼마 후 Access되고 나서 몇 번을 더 Access될까? (이것을 알 수 있을까?)\n\n\n* X1 = IO Access Pattern\n* X2 = IO 유발자 정보\n\n\n\n\n\n\n\nproactive data placement (caching/tiering)를 위해서, layer abstraction 혹은 virtualization이 필요하지는 않을까?\n- 예를 들어, IBM의 GPFS에서 AFM (Active File Management)을 구현할 때, data의 lifecycle 및 next use에 의거한 automatic data transfer를 위해서, 기존에는 없었던 새로운 component 혹은 새로운 layer가 필요하지는 않았을까? [1][2]\n- proactive data placement 입장에서는, next IO use를 예측하거나, user/process context를 이해한다는 측면에서, 오히려 block layer보다는 file system layer에서 바라보는 것이 더욱 적절한 것은 아닐까?\nRead cache, write cache colocation을 하면 어떨까?\nadvanced tiering: access pattern-aware optimal placement (APOP)\n\n== PATENT-BRIAN-2013-006 ==\n\n=== SSD Retention Time Controlling for Caching/Tiering 특허 ===\n\n* Caching-optimal SSD Retention Time Control\n* SSD Retention Time Controlling for Caching\n\nCache-I/O의 특성에 맞도록 SSD Retention Time을 Control하는 기술.\n\n== PATENT-BRIAN-2013-XXX ==\n\n=== State Machine based Macro IO Prediction ===\n\n== PATENT-BRIAN-2013-00X ==\n\n=== Coarse-grained Spatial Locality Based SSD Cache I/O ===\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* DRAM Cache의 부족한 용량을 극복하기 위한 솔루션으로 SSD Cache가 도입되고 있음. 기본 원리는 자주 액세스되는 디스크 블록을 SSD에 Caching함으로써 HDD의 느린 I/O 속도를 극복하도록 하는 것임.\n* 그러나 블록 레이어에 구현되는 SSD Cache의 경우, Kernel에서 관리하는 Page Cache에 의해 이미 Hot data가 Serve되고 있기 때문에, Hit Ratio를 높이기에 근본적인 한계점을 가지고 있음.\n* 한편, kernel에서 관리되는 기존 Page Cache는 다음과 같은 한계점을 가지고 있음. (1) SSD 혹은 HDD에 비해 비싼 스토리지인 RAM 기반이기 때문에 다른 스토리지에 비해 작은 용량을 가지고 있는 경우가 일반적이므로 cache로 사용할 수 있는 공간의 제약이 큼. (2) 시스템에서 사용되지 않고 있는 idle RAM 영역을 이용하기 때문에, 시스템에서 구동되는 프로세스들이 요구하는 RAM 요구량이 많아지게 되면, 그만큼 page cache가 버려지게 되며 그만큼 시스템 I/O 성능의 저하가 발생하게 됨. 또한 이로 인해 성능의 편차가 불규칙하다는 단점 또한 근본적으로 가지고 있음.\n* 한편, SSD를 이용하는 page cache가 기존에 시도된 적이 있으나 매 page access 시마다 SSD에 page를 저장하는 메커니즘으로서 (synchronous I/O) NAND flash와 RAM I/O 특성 차이로 인해 기인하는 근본적인 성능적 한계점을 가지고 있음.\n\n<br/>\n\n\n=== # 본 발명의 특징 / 효과 ===\n\n\n=== # 대표 청구항 ===\n\n* (page tiering 기반의 hybrid cache에서) spatial locality에 기반한 효율적인 page cache I/O 방법\n** 고속이면서도 자원 효율적으로 spatial locality 패턴을 파악하는 방법\n***(range size를 동적으로, 혹은 서로 다르게 할 수 있는 방법은 필요 없을까?)\n\n* page chunk handling 방법\n** [host side] spatial-locality가 있는 page들이 가급적 page chunk 단위로 묶이도록 하는 방법\n** [host side] SSD 내부의 parallelism을 극대화할 수 있도록 page chunk 크기를 정하는 방법 (i.e., channel_# x erase_block_size)\n** [host side / ssd side] tier-2 page cache에 저장된 특정 page가 access될 때, 그 page가 속한 page chunk의 데이터를 같이 pre-loading 하는 방법\n*** 해당 page chunk에 대한 status update하는 것이 필요할까?\n\n* page chunk eviction 방법\n** [ssd side] tier-2 page cache에서 page chunk를 eviction 시키기 전에, page chunk 중에서 popular 한 page는 SSD에서 evict하기 전에 RAM에 올리는 것\n\n\n=== # 기술 상세 ===\n\n=== # 선행 기술 ===\n\n다음 검색식\n (Spatial locality based I/O SSD cache)\n으로 1건의 미국 공개/등록 문건을 검색할 수 있었으나,\n본 발명과 유사한 spatial locality based I/O for SSD cache 관련 선행 기술은 발견하지 못하였음.\n\n유사한 주제를 다루는 논문으로\n __\n이 있었음.\n\n그러나 __ 측면에서 본 발명과 상이함.\n\n<br/>\n\n\n=== # 침해 적발 ===\n\n== PATENT-BRIAN-2013-00X ==\nContent Repeatability-Aware SSD Cache Management\n\n=== 대표 청구항 ===\n\n== PATENT-BRIAN-2013-00X ==\n=== Likely Zone Based Page Pre-placement ===\n\n\n* periodicity의 특성을 이용해 pre-placement하는 개념도 추가할 수 있을까?\n\n* associated-likely-zone 기반의 page pre-placement (to RAM)\n\n* page cache tiering의 방향이 RAM으로부터 SSD로 가는 경우는 page eviction 시 class-2에 해당하는 page들을 SSD로 저장하는 경우임. page cache tiering의 방향이 SSD로부터 RAM으로 가는 경우는 class-1의 “currently-hot”한 page들과 매칭되는 associated-likely-zone이 존재하고, 동시에 현재 시스템에 page cache로 사용할 수 있는 RAM의 여유 공간이 존재할 때, SSD에 저장되어 있었던 해당 associated-likely-zone을 RAM에 미리 올리는 경우임. page cache로 사용할 수 있는 RAM의 여유 공간보다 associated-likely-zone의 크기가 큰 경우에는 RAM의 여유 공간 만큼만 우선적으로 RAM에 올려짐.\n\n* 이때, associated-likely-zone 중에서 우선적으로 RAM에 올려져야 할 영역을 결정하는 방법으로써, “currently-hot”한 현재 data와 지리적으로 가까운 영역의 data를 우선적으로 선택하는 방법, associated-likely-zone의 data들 중에서 access frequency가 높았던 data들을 우선적으로 선택하는 방법 등을 사용할 수 있다. 이에 대한 구체적인 방식은 본 특허와 개별적으로 구현될 수 있으므로, 별도의 특허에서 다루어진다.\n\n* associated-likely-zone은 과거의 access 패턴에 기반하여 서로 비슷한 시간대에 access되었던 data들의 set으로 구성한다. 여기서 ‘서로 비슷한 시간대’라는 개념은 window 2의 window size에 의해 결정된다.\n\n* 특정 address arange가 LZ인지, ULZ인지 구분하는 방법?\nLZ (Likely Zone)와 ULZ (Unlikely Zone)을 선정하는 방법:\naccess되는 page를 보면, 해당되는 inode정보와 이를 access한 process 정보를 알 수 있다. inode 정보를 보면, 이 page가 어떤 파일에 연결되어있는지를 알 수 있다. 이렇게 되면 그 파일이 걸쳐있는 address space 정보 (LBA range)를 알 수 있으며, 이는 likely zone의 일부로 마킹될 수 있다. 여기서 해당 파일 전체를 likely zone으로 할 것인지 해당 파일의 일부를 likely zone으로 할 것인지는 별도의 likely zone determinition rule에 의해 결정된다. 그리고 likely zone으로 마킹된 영역을 언제 class-2 t2 page cache media (e.g., SSD)에 loading할 것인지, loading한다면 likely zone 영역의 데이터들을 어떤 순서로 읽어들일지는 likely-zond loading rule에 의거하여 결정된다. LZ과 ULZ를 선정하는 빈도/시기는\n\n== PATENT-BRIAN-2013-00X ==\n\n* 하나 이상의 SSD를 Page Cache Media로 사용하는 경우, (1) SSD array manager와 연계하여 보다 효율적인 caching I/O를 달성하는 방법 (RACS 기반의 기존 SAVL을 그대로 이용하되 interfacing에 관련된 내용), 혹은 (2) 복수개의 SSD를 caching I/O에 맞도록 coordination하는 방법 (RACS 기반의 기존 SAVL에 추가적으로 caching I/O를 잘 handling할 수 있도록 하는 최적화된 I/O management 방법)\n\n\n* 복수 개의 SSD를 tier-2 page cache media로 사용하는 경우, SSD 1에 free space가 부족한데, 그 SSD 내에 cache되어 있는 page chunk들이 계속 caching해둘만한 가치가 있는 경우, page chunk migration (between SSDs)을 수행한다. 이때, tier-1 page cache 내의 page node 내의 page data location field 값은 update한다. (이때, 누가 migration을 initiation하는 것이 적절할까? host의 hybrid page cache manager? 혹은 activie SSD? 아무래도 SATA 기반의 SSD를 사용하는 경우에는 전자가 좀 더 현실적일 것으로 보임)\n\n\n* tier-2 page cache의 eviction threshold period를 두어서 RAM page cache 경우보다는 길겠지만 tier-2 page cache의 총량이 허용할 수 있는 page 용량을 감안하여 계산된 time period 동안 access 실적이 없으면 tier-2 page cache 중에서도 evictable flag를 set하게 되는데, 이때 복수개의 SSD를 tier-2 page cache media로 사용하는 경우, 전체 SSD 가용 용량을 합산해야 한다.\n\n== PATENT-BRIAN-2013-00X ==\nMultiple I/O Queue Handling for SSD Cache\n\n\n[청구항]\n\n== PATENT-BRIAN-2013-00X ==\npage chunk I/O handling mechanism for multi-tenancy SSD page cache\n\n\n[요약]\n물리적인 SSD 하나가 통째로 page cache로 사용되는 경우에는 SSD 전체를 위와 같이 나누어 사용하면 되겠으나, 하나의 SSD를 page cache media와 다른 용도로 같이 사용해야 하는 경우를 위한 구조 및 방법은 별도의 특허에서 기술하는 것으로 함. page cache media로 사용되는 공간과 다른 목적으로 사용될 공간을 별도의 partition으로 잡고, page cache media로 동작하기 위한 partition을 다시 meta 정보 영역과 page data 영역으로 slice하여 사용함. 이때, SSD는 page cache media로 partitioning된 영역에 해당하는 I/O에 대해서는 병렬성과 page chunk lookup table의 단순성을 극대화 할 수 있게 설계된 page chunk I/O 방식으로 처리할 수 있도록 하는 것이 필요함.\n\n[청구항]\n\n\n== PATENT-BRIAN-2013-00X ==\n\n=== # I/O Pattern-optimal Data Placement for Tiering ===\n\n* Automatic tiering 시, 단순히 hot data들을 fast media에 가져다 놓고 마는 것이 아니라, IO bottleneck이 미연에 방지될 수 있도록 data의 access pattern을 aware해서 차별적으로 배치하는 방법\n예) (a) random-read-intensive 한 data들, (b) sequential-write-intensive한 data들을 다른 방식으로 배치 (tiering)\n\n\n* 이에 필요한 data access pattern 모니터링/분석 방법\n데이터 수집 및 분석 시 PCIe 카드 엔진 활용 가능?\nNIC 이나 DMA를 통해서 data move가 일어나는 경우, PCIe 카드 등을 통해서 IO stream 분석\n\n\n* 이를 위해 필요한 system architecture 구조\n기본적으로 하나 이상의 SSD와 하나 이상의 HDD, 그리고 PCIe 카드, DRAM 일부 사용 방식, Tiering Mapping Table 구조, ...\n\n\n=== # 발명의 이용분야 ===\n=== # 배경 / 기존 기술의 문제점 ===\n=== # 본 발명의 특징 / 효과 ===\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n=== # Memo / Questions ===\n\n\n<br/>\n\n\n\n== Patent pool ==\n\n\n=== (SmartSSD API) SSD-internal I/O pattern logging interface and mechanism ===\n\n\n==== Questions ====\n\n* SmartSSD에서 제공할 수 있는 logging 서비스로서 어떤 것들이 있을 수 있나?\n:- 어느? 정도의 free space를 필요로하는 critical (heavy) I/O가 어떤? 주기로 도래할 지 알 수 있을까?\n:- I/O prediction에 도움될 수 있는 정보를 SmartSSD가 기록했다가 필요한 때 (안전한 방법으로?) 줄 수 있을까?\n:- I/O prediction까지는 아니더라도 해당 SSD의 I/O wellness(어떻게 정의?)를 측정했다가 bottleneck을 회피하는 데 유용한 정보를 제공할 수 있을까?\n:- 어떤 SSD가 현재 주어지고 있는 I/O workload에 대해 list performance spec을 만족하는데 어려움을 겪고 있다는 것을 알려줄 수 있는 정보가 어떤 것이 있을까? (SSD 내 write buffer의 fullness 혹은 I/O queue의 유동성? amount of free space in over-provisioning area?) (-> I/O wellness 라는 metric을 이것과 연관시켜 정의할 수도 있으며, 결국 SLA 혹은 Performance QoS와 연관시킬 수 있음)\n:- 지금까지의 S.M.A.R.T.와 비교하였을 때, 어떤 차별점이 있는가? 기존의 S.M.A.R.T.가 제공하지 못하던 타입의 정보를 제공하고, 이로 인해 기존에는 불가능했던 새로운 알고리즘 구현 혹은 새로운 서비스 제공이 가능해짐을 보이면 좋겠음.\n\n\n\n:- workload의 history?\n:- 각 erase block이 erase되어야만 했던 주기?\n:- free space의 추이 (얼마나 많이 남아 돌던지)?\n:- I/O의 heaviness 패턴?\n:- SSD내 write buffer (혹은 write cache)의 utilization정보? (즉, write buffer가 넘칠 정도가 되어서 I/O wait을 해야만 했던 상황이 얼마나 자주 발생했는지, write buffer의 가득찬 정도를 백분율로 표현한다고 했을 때, 평균/표준편차 등으로 대표할 수 있는 normal distribution을 따르는지?\n:- 전체 sequential read/write \n\n\n==== 배경 ====\n\n* 각 SSD 모델별로, 또 동일한 모델의 SSD라 하더라도 어떤 workload에 노출되어왔는지에 따라, 현재 낼 수 있는 I/O performance가 동일하지 않을 수 있다 (!check! 관련 실험 결과 - SSD 830을 이용하여 같은 시간 동안 하나의 host에서 생성되는 workload들을 나누어 받았다 하더라도 내부적인 free block의 갯수 및 random write에 의한 block 내 파편화등의 상태가 상이하여 성능에 차이가 나는 것을 보여줄 것. uFLIP 혹은 filebench 활용 가능). 한 예로, SSD가 어느 호스트의 어느 file system에 매핑되었는지에 따라 그 SSD가 받는 workload의 특성이 다를 수 있다. file system mount point가 달라지거나, 기존과 다른 새로운 응용이 설치/서비스되는 상황이 되면 \n\n\n=== (Tiering-based?) Proactive Data Placement ===\n* 핵심 아이디어\n: \"proactive\" 하게 data를 배치시킨다는 것 자체!\n: Local node 내에서의 vertical tiering 뿐만 아니라 분산 node들 간의 horizontal tiering도 염두에 둘 것\n\n\n* 기존 기술과의 대비 (naive I/O prediction vs. full-fledged I/O prediction)\n: 기존 기술은 누적 hit count 정보에 의지하는 naive I/O prediction으로 볼 수 있음. 이러한 방식은 workload의 변화를 제대로 반영하지 못하기 때문에, static한 workload에 대해서는 잘 동작하지만, moving target처럼 dynamic한 workload에 대해서는 오히려 과거의 누적 hit count metric이 현재의 workload 패턴을 왜곡시키는 문제점을 가지고 있음. (temporal locality와 spatial locality가 깨지는 순간이 여러번 존재할 수록 기존의 naive I/O prediction 방식은 성능 향상이 어려워짐)\n\n* 경쟁 기술과의 차별화\n: EMC의 FAST 기술이 안고 있는 근본적인 한계점은 무엇일까?\n: data access 패턴의 hot/cold 만 분류해서 hot은 fast tier에, cold는 slow tier에 두는 것이 전부인가? 아니면 그것 외에 뭔가가 더 있는가?\n: 어떻게 보면 기존의 automated storage tiering은 naive proactive placement로 볼 수도 있다. (과거에 자주 access되었던 data가 앞으로도 자주 access될 것이라고 믿고 data를 이동시키는 것이므로. 그러나 근거가 부족함)\n:: 이러한 naive proactive placement 방식으로 야기되는 단점이 있다. 만약 과거에는 자주 access되었는데 마침 tiering되고 난 후에 자주 access되지 않게 되면, 괜히 SSD의 wear-out만 유발시킨 결과가 된다. 다음 tiering 주기가 돌아오기 전 까지는 계속 느린 media에서 I/O가 serve되기 때문에 그만큼 pain이 된다.\n:: 물론 read에 대해서는 cache를 적극 활용함으로써 첫 access 시에만 slow media access로 인한 penalty를 얻고 이후에는 cache가 제공하는 수준의 성능을 얻을 수 있게 된다.\n:: 그러나 write에 대해서는 문제가 다르다. HDD의 경우 sequential write 경우에는 큰 문제가 되지 않는다. 그러나 random write 특성을 가지고 있으며, 게다가 write-intensive한 I/O라면? 그런데 random write이면서 write-intensive한 경우, write되는 address range가 생각보다 넓지 않다면 어떻게 될까? 즉 특정 구간 특정 데이터에 대한 update가 빈번한 것을 의미한다.\n:: write address range가 N개의 4KB 블럭으로 이루어져 있고, Storage System 내에 물리적인 Disk 갯수가 M개 존재한다고 가정하자. 만약 M이 N보다 적절하게 커서 RAID 10을 하건, RAID 5 등으로 이루어져 있건 간데, N개의 4KB 블럭을 각각 별도의 HDD로 분산 시킴으로써 random write을 random write이 아닌 것처럼 보이게 할 수 있다면? 예를 들어 VNX 5300 처럼 SAN 박스 하나 내에 HDD가 125개가 들어있고, random하고 intensive한 write pattern이 오고 있고, write access range가 125개 이하의 address 내에서 반복되고 있다면, 매번 도달하는 random write request를 마치 RAID 0로 striping 하듯이 계속 다른 HDD로 보냄으로써 I/O de-randomization을 할 수 있을 것이다. 여기서 좀 더 나아가서 하나의 request에 대해서 HDD가 완벽하게 처리하는 데에 걸리는 시간이 10ms 이고, 매 random I/O가 도달하는 평균 시간은 (평균 가지고 되려나? 아무튼 이것은 조금 뒤에 다시 생각해보자) 1ms 라고 한다면, 이론적으로 10번의 random I/O가 지난 다음, 11번째의 random I/O가 올 때에는 처음에 write했던 HDD에다가 다시 write을 해도 된다. 즉, 그 HDD에서 직전의 I/O가 끝나기를 기다리고 있지 않아도 된다는 것이다. 그러나 이러한 방식은 나중에 scatter했던 I/O들을 다시 불러모으려고 할 때 contribution한 HDD가 다른 I/O를 serving하고 있지 않을 수 있어야 최고의 성능을 낼 수 있게 된다. 즉, HDD cluster 구성을 상당히 dynamic하게 가져갈 수 있다면 어떨까? 이러한 dynamic clustering이 정말 최고의 효과를 낼 수 있는 workload case로는 어떤 것이 있을까? data placement를 함에 있어서 결국은 어딘가에 써야 할 것이고, (slow tier로 마크된 HDD들 array에다가 data를 쓴다고 그냥 푸대접하면서 써버릴 것이 아니다) slow tier에다가 쓸 때에도 나중에 어떻게 read되고 다시 write 될 지를 고려한다면, workload 특성에 따라서 concurrent I/O의 갯수 및 address range 크기가 다를 수 있는데, 그것을 aware해서 write을 해둔다면, 비록 slow-tier에다가 write했지만, 그리 slow하지만은 않은 성능을 내게 할 수 도 있을 것이다. 이것은 proactive data placement에 대한 이야기가 아니다. proactive와는 별개로, automated storage tiering을 함에 있어서 workload characteristics를 고려한 data placement에 대한 이야기이다.\n\n\n\n\n서로 독립적인 I/O stream의 갯수가 100개 라면 (즉 100개의 process가 I/O를 쏟아내고 있는 경우), 그리고 I/O queue의 크기가 N_Q라면, 어떻게 이러한 문제를 해결할 수 있을까?  \n\n  \n:: write에 대해서는 \n:: write-intensive하다는 것의 정의는? 이러한 경우에는 in-memory write caching (OS가 허용하는 범위의 delayed write을 최대한 활용)을 이용하되 transaction 기반으 atomicity를 보장함으로써 문제를 부분적으로 해결할 수 있다. transaction으로 묶여질 수 있는 여러 번의 I/O request (write)가 끝나기 전까지는 commit되지 않은 것으로 치는 것임. Fusion IO의 atomic write은 이를 어떻게 해결하는지? \n\n만약 write commit이 매우 중요한 민감한 데이터에 대해서는 어떻게 해야할까? 그리고 SSD-internal memory buffer를 이용해서\n: SAN 장비 내에서의 HDD와 SSD 간의 tiering만 되는 것일까? (vertical tiering within local node)\n: SAN 장비 간의 tiering이 되기 위해서는 어떤 것이 더 필요할까? EMC에서 이미 그러한 기술/솔루션을 가지고 있지는 않을까? (horizontal tiering between boxes)\n\n* 다양한 사례\n: 기존에 이미 생성되어 있던 data를 미래 access 예측에 따라 위치 변동을 시키는 경우\n: Tiering을 한다고 했을 때, access 빈도에 따라서 fast tier / slow tier 간 이동시키는 것이 전부일까? 그런 것 말고 다른 차원의 tiering은 없을까?\n: 새롭게 write되려는 data를 처음부터 어디에 배치시키는 것이 좋을까?\n\n* Placement 접근 방식\n: Tiering으로 한정?\n: Tiering과 Caching과의 결합 방식? (Caching engine에게 hint를 주는 방식)\n\n* I/O Prediction 결과를 받아서 proactive하게 data를 tiering 시키는 방법 및 아키텍쳐\n* Key questions\n:- 기존엔 proactive tiering이 없었나?\n:- 만약 없었다면 어떤 어떤 부분들을 청구항으로 넣어야 할까?\n:- 만약 있었다면 어떤 차별화가 필요할까?\n\n=== I/O Workload Analyzer Engine ===\n* I/O Trace 및 다양한 시스템 정보를 기반으로 I/O를 prediction하는 방법 및 구조\n*\n\n== Disclosure of Invention :: Template ==\n\n<!--\n== PATENT-BRIAN-2013-00X ==\n-->\n\n=== # RAM-SSD Hybrid Page Cache Architecture ===\n=== # 발명의 이용분야 ===\n=== # 배경 / 기존 기술의 문제점 ===\n=== # 본 발명의 특징 / 효과 ===\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n=== # Memo / Questions ===','utf-8'),(1957,'== PATENT-BRIAN-2013-001 ==\n\n=== # RAM-SSD Hybrid Page Cache Architecture ===\n\n[[Bnote patidea 2013-001]]\n\n== PATENT-BRIAN-2013-002 ==\n=== # Low-computation-overhead and Memory-efficient Periodicity Detection Method ===\n[[Bnote patidea 2013-002]]\n\n== PATENT-BRIAN-2013-003 ==\n\n=== 맵리듀스 작업의 병목 탐지 및 원인 분석을 위한 모니터링 프레임워크 기술 (A monitoring framework for detecting and analyzing execution bottlenecks of MapReduce jobs) ===\n\n[[Bnote patidea 2013-003]]\n\n== PATENT-BRIAN-2013-004 ==\n\n<!-- === Straggler-immune Data/Task Placement in the Distributed Environment === -->\n\n=== Straggler-immune Data Placement in the Distributed Environment (HDFS?) ===\n\n\n\n\n=== Memo ===\n\n* title candidates\n: outlier(straggler, failure, ...)-immune data placement for distributed file system\n: straggler-immune data placement in the distributed file system (DFS)\n\n\n* Assumptions // 환경\n: replica management가 있는 DFS 환경\n: replica management algorithm 변경 가능\n: MapReduce/HDFS처럼 data가 있는 곳에 computation을 보내는 구조\n: DFS 위에서 Hadoop MapReduce처럼 분산 병렬 처리를 수행하는 환경\n\n* Assumptions // Failure Characteristics \n: straggler 발생과 task의 type 간의 연관성이 있음\n: {task type, node} tuple이 \n\nHDFS 및 MapReduce 환경에서,\n\n\n특정 node와 특정 task type의 조합과 straggler 발생 빈도 간에 연관 관계가 있을 수 있을까?\n\n\n즉 straggler가 발생했던 case를 관찰했을 때,\nnode 정보만으로는 패턴 (혹은 straggler 발생과의 연관성)이 보이지 않고,\ntask type 정보만으로도 패턴 (혹은 straggler 발생과의 연관성)이 보이지 않지만,\nnode 정보와 task type 정보를 같이 고려했을 때 straggler 발생 빈도/확률과 연관성을 볼 수 있었다면?\n\n\n\n\n* Bottleneck History Record (BHR) based approach\n: do not throw away the bottleneck experience (history). KEEP IT to use the knowledge for later use.\n\n* Replica management\n: at the very first time to place the data\nDistributed File Systems\n\n\n\n=== # 요약 ===\n\n\n=== # 발명의 이용분야 ===\n\n* Hadoop MapReduce/HDFS 혹은 이와 유사한 분산 처리 시스템이 구동되는 Enterprise 데이터 분석 클러스터.\n* Hadoop MapReduce/HDFS 혹은 이와 유사한 분산 처리 시스템이 구동되는 Public Cloud 데이터센터\n\n\n----\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* Hadoop의 기본 DFS인 HDFS (Hadoop Distributed File System)은 replica management를 수행하고 있음.\n\n\n* HDFS에서의 replica management는 3-copy replica 구성 시, 다음 몇 가지 원칙에 의해 data를 분배하고 있음.\n:- 하나의 node에 동일 block이 두 개 이상 존재하지 않는다\n:- 하나의 rack에 동일 block이 세 개 이상 존재하지 않는다\n:- 첫 번째 replica는 client가 구동하고 있는 node에 배치\n:- 두 번째 replica는 첫 번째 replica가 있던 node가 속하지 않은 다른 rack의 임의의 node에 배치\n:- 세 번째 replica는 두 번째 replica가 배치된 rack 내의 다른 node에 배치\n:- 1st-2nd-3rd replica 배치는 순차적으로 실행\n\n\n* Yahoo!의 Hadoop Cluster에서 10개월간 구동된 17만개의 MapReduce job들을 분석한 연구에 따르면 약 3% 정도의 Job들이 fail되었으며, 각 task의 특성과 failure 발생과 연관성이 있음을 확인할 수 있다. (예를 들어, MapReduce 전체 failure의 80% 이상이 map task에서 발생하였으며, map task failure의 36%는 array indexing error에 의한 것이었음. 그리고 reduce task 의 23%는 I/O exception에 의한 것이었음)  이러한 failure 및 straggler로 인해 task restart가 많이 발생하고 있으며, 이는 MapReduce/HDFS 성능을 저하시키는 주요 요인임.\n\n\n* 현존 Hadoop MapReduce/HDFS 시스템에서는 straggler가 발생했다고 판단되면, 해당 task를 drop 시키고 새로운 node에서 task가 실행될 수 있도록 하고 있음. 즉, 이미 발생한 straggler에 대해서는 speculative execution을 수행하고 있지만 여전히 한계점은 존재함. (1) speculative execution을 위해 필요한 additional data copy overhead 존재. (2) 새로운 execution node를 찾는다 하더라도 그 node가 straggler-free한 node인지 보장할 수 없기 때문에, 제2, 제3의 straggler가 발생할 가능성 존재. (3) additional copy를 하려고 하더라도 이미 task들이 tight하게 많이 구동되고 있는 상황에서, 여유 execution slot을 가지고 있는 적절한 node를 바로 찾지 못할 수 있으며, 이렇게 기다리는 것 자체가 job completion time을 증가시키는 부정적인 효과가 있음.\n\n\n----\n\n=== # 본 발명의 특징 / 효과 ===\n\n\n* 특징\n:- 기존처럼 straggler가 발생한 후에 대응하기 보다는 (사후 대응), HDFS에 처음 data가 놓여질 때부터 straggler-immune node에 배치될 수 있도록 하는 사전 대응 방식을 특징으로 하고 있음.\n:- {node, task-type, bottleneck-risk-score} tuple로 구성되는 Bottleneck History Record (BHR) 정보에 기반하여 해당 task-type에 대해 bottleneck-risk-score 값이 가장 작은 node에 replica data를 배치하는 방식임\n:- {node, task-type}에 대한 bottleneck-risk-score 정보는 JobTracker에 추가되는 Bottleneck History Record Manager 모듈에 의해 update됨\n:- 참고로, 기존 HDFS에서의 data placement (replica management 시)에서는 이러한 straggler-immune data placement는 고려되어 있지 않음.\n\n\n* 기대 효과\n:- speculative execution을 위한 data copy overhead 감소\n:- 제2, 제3의 straggler / failure 발생 확률 감소\n:- 결과적으로, Hadoop MapReduce Job의 성능 향상 효과\n\n\n* 구현의 용이성\n:- Apache Jira HDFS-385에서 언급된 pluggable interface를 이용 시, 본 발명에서 제안하는 data placement 알고리즘을 HDFS의 block placement algorithm으로 추가하기가 용이함.\n\n\n* 침해 적발의 용이성\n:- namenode에서 수집하는 데이터들을 관찰하거나, HDFS-385 interface를 통해 오가는 데이터들을 관찰하였을 때, node, task-type, failure rate 정보를 namenode가 (혹은 pluggable data placement module이) 읽어들이고, 그 중 가장 failure rate 값이 낮은 하나의 node가 replica data를 저장하기 위한 datanode로 선택된다면, 본 특허를 침해한 것으로 판단 가능.\n\n\n----\n\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n\n\n* 기존처럼 straggler가 발생한 후에 대응하기 보다는 (사후 대응), HDFS에 처음 data가 놓여질 때부터 straggler-immune node에 배치될 수 있도록 하는 사전 대응 방식을 특징으로 하고 있음.\n\n\n* {node, task-type, failure rate} tuple 정보에 기반하여 해당 task-type에 대해 failure rate이 최소화 될 수 있는 node에 replica data를 배치하는 방식임\n\n\n==== 시스템 구성 요소 ====\n\n\n==== 처리 절차 ====\n\n\n==== 예상 효과 ====\n\n* Anomaly (straggler, failed task) 발생 자체를 줄임으로써, Straggler 혹은 Failed Task로 인해 야기되는 추가 처리 비용을 감소시킬 수 있음.\n\n* Straggler의 경우, speculative execution으로 야기되는 additional data copy overhead 감소 (사라지거나 감소됨) 효과를 기대할 수 있음. 특히, HDFS block size가 큰 경우 (처리 해야 할 data는 크지만, node의 수가 적은 경우, 64MB 이상으로 tuning하여 사용하는 경우가 많이 있음 - 그런데, 실제로 이렇게 tuning하면 어떤 장점/효과가 얼만큼 생기나?) additional data copy로 인한 overhead가 그만큼 커지게 되므로, 이 경우 straggler 발생 확률을 낮춤으로써 얻는 이득 역시 그만큼 커지게 됨.\n\n* Failed task의 경우, 상황에 따라서 두 가지 처리 옵션이 있다. 첫 번째 옵션은 failure가 발생했던 해당 node에서 task를 재시작하는 방법이며, 두 번째 옵션은 다른 node에서 task를 재시작하는 방법임.\n\n* Task failure의 원인이 해당 node의 H/W 혹은 S/W에 문제가 있는 것이 아니었다면 첫 번째 옵션을 택할 수 있다. 물론 H/W 혹은 시스템 S/W 결함이 아니었다는 것을 알수 있었어야 한다. 그러나 해당 node의 H/W 혹은 S/W에 문제가 있다는 것을 알고 있는데, 당장 다른 node의 execution slot도 여유가 없는 상황이라면, execution slot이 생길 때까지 좀 더 기다렸다가 재시작을 해야 한다. 이때, 기다려야만 하는 경우라면, 그만큼 job 처리 속도의 저하로 이어진다. 다른 노드에서 재시작을 하게 되더라도, 역시 additional data copy가 필요하며, 이로 인한 overhead는 피할 수 없다.\n\n\n----\n\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n\n* Google patent search (2 results, no relevant result)\n (HDFS OR \"hadoop distributed file system\") (((block replica) OR data) placement) (straggler OR fail*)\n\n* Google patent search (2 results, no relevant result)\n (HDFS OR \"hadoop distributed file system\") (((block replica) OR data) placement) bottleneck\n\n* Google patent search (5 results)\n HDFS block replica placement\n:- [http://www.google.com/patents/EP2288998A2?cl=en Directed placement of data in a redundant data storage system]\n:: Filed 9 Apr 2009 - Published 2 Mar 2011, John Howe - Omneon, Inc.\n\n\n\n* 검색식\n: mapreduce straggler (\"historical record\" OR \"history\")\n: 2건\n\n:* System and Method for Analyzing Data Records\n:: [http://www.google.com/patents/US20120215787 www.google.com/patents/US20120215787]\n:: App. - Filed 28 Feb 2012 - Published 23 Aug 2012 - Jeffrey Dean - Dean Jeffrey, Dorward Sean M, Ghemawat Sanjay, Pike Robert C, Quinlan Sean\n\n:* Scalable user clustering based on set similarity\n:: [http://www.google.com/patents/US7962529 www.google.com/patents/US7962529]\n:: Grant - Filed 6 May 2010 - Issued 14 Jun 2011 - Mayur Datar - Google Inc.\n\n=== # Memo / Questions ===\n\n==== References ====\n\n\n\n* Google search\n map reduce straggler study\n\n:- [http://static.usenix.org/event/osdi08/tech/full_papers/zaharia/zaharia_html/ Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]\n:: Matei Zaharia, Andy Konwinski, Anthony D. Joseph, Randy Katz, Ion Stoica // University of California, Berkeley\n\n:- [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CDAQFjAA&url=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2FUM%2Fpeople%2Fsrikanth%2Fdata%2FCombating%2520Outliers%2520in%2520Map-Reduce.web.pptx&ei=pq1iUer9NK6eiAfN2IHYBQ&usg=AFQjCNEOOEtTE2_nVb6f2qQN09OpoLcS5A&sig2=HakGM53pMqVB1y2PqhQZJQ Combating Outliers in Map-Reduce - Microsoft Research]\n:: Srikanth Kandula, Ganesh Ananthanarayanan, Albert Greenberg, Ion Stoica, Yi Lu, Bikas Saha, Ed Harris\n\n\n* Google search\n map reduce straggler study once relationship\n\n:- [http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]\n:: Soila Kavulya, Jiaqi Tan, Rajeev Gandhi and Priya Narasimhan. Carnegie Mellon Univ., Pittsburgh, PA, USA\n:: [http://www.pdl.cs.cmu.edu/PDL-FTP/associated/CMU-PDL-09-107.pdf Another Version, CMU-PDL-09-107 December 2009]\n:: [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster, CCGrid 2010]]\n\n:- [http://cseweb.ucsd.edu/~vahdat/papers/themis_socc12.pdf Themis: An I/O-Efﬁcient MapReduce // SOCC 2012]\n\n\n\n\n<br/>\n\n== PATENT-BRIAN-2013-007 ==\n\n=== data와 IO insight을 packaging 하는 기술 ===\n\n: 해당 [[data에 대한 IO pattern/insight 정보]]를 data와 함께 packaging하여 (마치 object-oriented manner) 같이 이동되게 함으로써, replication, migration, (node 간 tiering?) 등 분산 환경에서 data가 여러 노드로 이동하는 경우에도 해당 data에 대한 처리가 최적으로 이루어질 수 있도록 하는 기술\n: data에 대한 IO insight 정보로서 다음 정보가 포함될 수 있다\n\n:* data access patterns:\n::- 어떤 application이 얼마나 자주 이 data를 access하는지? (이 data를 access하는 application에 대한 정보가 없으면 insight가 잘못 적용될 수도 있을지도 모른다 - Hadoop 같은 경우는 어떻게 MapReduce Application 정보를 알 수 있을까? 혹시 MapReduce application에 대한 정보가 Hadoop layer에 가려지는 것은 아닐까? JobTracker/TaskTracker를 고려해야 할까?)\n::- 이 데이터(파일?)는 Rd(Read)-intensive 인가? Wr(write)-intensive인가?\n::- 이 데이터는 RRd(random read) / RWr(random write) / SRd(sequential read) / SWr(sequential write) 중 어느 것이 dominant한가? 혹은 Mix 되어 있다면 그 비율은 어떻게 되는가?\n\n:* data간 access pattern 연관성\n::- 이 data가 access되고 나면 어느 정도 확률로 어떤 다른 data가 access되는지?\n::- 어떤 data가 access되고 나면 어느 정도 확률로 이 data가 access되는지?\n\n:* data hot/cold history\n::- 이 data가 hot한 적이 얼마나 자주 있었나?\n::- 이 data가 hot한 시기가 어떤 패턴을 가지고 나타나는가?\n::- 한 번 hot하고 나면 이후에도 다시 hot할 가능성이 높은가?\n\n== PATENT-BRIAN-2013-005 ==\n\n=== IOWA based Proactive Data Placement 자체 특허 ===\n\n: 다양한 정보/Insight을 기반으로 Proactive하게 Data를 Placement하는 기술\n:: (Caching/Tiering in Local Case, Data Replication/Migration in Distributed Case)\n\n\n: 여기에, ML (혹은 HML까지도?)을 적용한다는 아이디어를 추가하자\n:: ML 기반의 IO Prediction\n::: ML을 통해서 예측을 한다면, 어떤어떤 정보들로부터, 어떤 예측을 해야하는 걸까?\n::: Fine-grained prediction이 말이 되는 소리인가?\n::: Coarse-grained prediction을 한다면 어느 스케일까지 fine/coarse-grained 해져야할까?\n\n\n:: ML 기반의 IO Insight (Data Placement를 위한 Macroscopic Guideline)\n::: ML을 통해서 최적의 배치를 할 수도 있는 것일까?\n:::: 가능함. 예를 들어, \"이러이러한 sign/indication을 보이는 data는 언제쯤 어떤 형태의 IO 양상을 보일 확률이 __%임\" 같은 형태의 insight이 있다면, \"이런 data는 현재 local system 뿐만 아니라 networked system의 상태도 같이 고려하여 어디에 위치시켜두는 것이 적당\" 하다는 식의 data placement를 \"proactive 하게\" 할 수 있겠음.\n::: IO Insight의 요건:\n::::# indication, as simple as possible\n::::# indication, as specific as possible\n::::# indication, efficiently traversable - corresponding indication case node들을 쉽게, 효과적으로 traversing하면서 최종 insight leaf에 도달 (Huffman code? Radix tree?)\n::::# indication, easily extensible - indication 추가 시에 변경되는 부분이 최소화될 수 있어야 함\n::: UCB study같은 형태로 나오는 것이 최선일까? 그런 형태/내용 외의 다른 것도 얻어낼 수 있을까?\n\n\n: HML이 도움이 되는 이유는 무엇일까?\n:: 굳이 HML이 아니더라도 ML 만으로도 잘 할 수 있는 범위는 어디까지일까?\n\n\n* Y1 = Proactive Data Placement\n* Y2 = Data-system-optimal Placement\n\n: Y1.x1 = 어느 address의 데이터(들)이\n:: Y1.x1.1 = 그 데이터들은 sequential access가 가능한 형태로 배열되어 있는가? (만약 그렇다면 굳이 cache시킬 필요가 있을까? 혹시 있는 건 아닐까? 정말 없을까? Sequential read하는 경우 SSD case와 HDD case를 비교해볼 필요 있음)\n:: Y1.x1.2 = 그 데이터들이 access되고 나면, ___%의 확률로 따라서 access되는 데이터들도 있지 않을까? (그렇다면, 그 놈들도 연달아서 미리 loading?)\n: Y1.x2 = 앞으로 얼마 후에\n: Y1.x3 = Access될 것인가?\n:: Y1.x3.1 = Read일까? Write일까?\n:: Y1.x3.2 = 그 얼마 후 Access되고 나서 몇 번을 더 Access될까? (이것을 알 수 있을까?)\n\n\n* X1 = IO Access Pattern\n* X2 = IO 유발자 정보\n\n\n\n\n\n\n\nproactive data placement (caching/tiering)를 위해서, layer abstraction 혹은 virtualization이 필요하지는 않을까?\n- 예를 들어, IBM의 GPFS에서 AFM (Active File Management)을 구현할 때, data의 lifecycle 및 next use에 의거한 automatic data transfer를 위해서, 기존에는 없었던 새로운 component 혹은 새로운 layer가 필요하지는 않았을까? [1][2]\n- proactive data placement 입장에서는, next IO use를 예측하거나, user/process context를 이해한다는 측면에서, 오히려 block layer보다는 file system layer에서 바라보는 것이 더욱 적절한 것은 아닐까?\nRead cache, write cache colocation을 하면 어떨까?\nadvanced tiering: access pattern-aware optimal placement (APOP)\n\n== PATENT-BRIAN-2013-006 ==\n\n=== SSD Retention Time Controlling for Caching/Tiering 특허 ===\n\n* Caching-optimal SSD Retention Time Control\n* SSD Retention Time Controlling for Caching\n\nCache-I/O의 특성에 맞도록 SSD Retention Time을 Control하는 기술.\n\n== PATENT-BRIAN-2013-XXX ==\n\n=== State Machine based Macro IO Prediction ===\n\n== PATENT-BRIAN-2013-00X ==\n\n=== Coarse-grained Spatial Locality Based SSD Cache I/O ===\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* DRAM Cache의 부족한 용량을 극복하기 위한 솔루션으로 SSD Cache가 도입되고 있음. 기본 원리는 자주 액세스되는 디스크 블록을 SSD에 Caching함으로써 HDD의 느린 I/O 속도를 극복하도록 하는 것임.\n* 그러나 블록 레이어에 구현되는 SSD Cache의 경우, Kernel에서 관리하는 Page Cache에 의해 이미 Hot data가 Serve되고 있기 때문에, Hit Ratio를 높이기에 근본적인 한계점을 가지고 있음.\n* 한편, kernel에서 관리되는 기존 Page Cache는 다음과 같은 한계점을 가지고 있음. (1) SSD 혹은 HDD에 비해 비싼 스토리지인 RAM 기반이기 때문에 다른 스토리지에 비해 작은 용량을 가지고 있는 경우가 일반적이므로 cache로 사용할 수 있는 공간의 제약이 큼. (2) 시스템에서 사용되지 않고 있는 idle RAM 영역을 이용하기 때문에, 시스템에서 구동되는 프로세스들이 요구하는 RAM 요구량이 많아지게 되면, 그만큼 page cache가 버려지게 되며 그만큼 시스템 I/O 성능의 저하가 발생하게 됨. 또한 이로 인해 성능의 편차가 불규칙하다는 단점 또한 근본적으로 가지고 있음.\n* 한편, SSD를 이용하는 page cache가 기존에 시도된 적이 있으나 매 page access 시마다 SSD에 page를 저장하는 메커니즘으로서 (synchronous I/O) NAND flash와 RAM I/O 특성 차이로 인해 기인하는 근본적인 성능적 한계점을 가지고 있음.\n\n<br/>\n\n\n=== # 본 발명의 특징 / 효과 ===\n\n\n=== # 대표 청구항 ===\n\n* (page tiering 기반의 hybrid cache에서) spatial locality에 기반한 효율적인 page cache I/O 방법\n** 고속이면서도 자원 효율적으로 spatial locality 패턴을 파악하는 방법\n***(range size를 동적으로, 혹은 서로 다르게 할 수 있는 방법은 필요 없을까?)\n\n* page chunk handling 방법\n** [host side] spatial-locality가 있는 page들이 가급적 page chunk 단위로 묶이도록 하는 방법\n** [host side] SSD 내부의 parallelism을 극대화할 수 있도록 page chunk 크기를 정하는 방법 (i.e., channel_# x erase_block_size)\n** [host side / ssd side] tier-2 page cache에 저장된 특정 page가 access될 때, 그 page가 속한 page chunk의 데이터를 같이 pre-loading 하는 방법\n*** 해당 page chunk에 대한 status update하는 것이 필요할까?\n\n* page chunk eviction 방법\n** [ssd side] tier-2 page cache에서 page chunk를 eviction 시키기 전에, page chunk 중에서 popular 한 page는 SSD에서 evict하기 전에 RAM에 올리는 것\n\n\n=== # 기술 상세 ===\n\n=== # 선행 기술 ===\n\n다음 검색식\n (Spatial locality based I/O SSD cache)\n으로 1건의 미국 공개/등록 문건을 검색할 수 있었으나,\n본 발명과 유사한 spatial locality based I/O for SSD cache 관련 선행 기술은 발견하지 못하였음.\n\n유사한 주제를 다루는 논문으로\n __\n이 있었음.\n\n그러나 __ 측면에서 본 발명과 상이함.\n\n<br/>\n\n\n=== # 침해 적발 ===\n\n== PATENT-BRIAN-2013-00X ==\nContent Repeatability-Aware SSD Cache Management\n\n=== 대표 청구항 ===\n\n== PATENT-BRIAN-2013-00X ==\n=== Likely Zone Based Page Pre-placement ===\n\n\n* periodicity의 특성을 이용해 pre-placement하는 개념도 추가할 수 있을까?\n\n* associated-likely-zone 기반의 page pre-placement (to RAM)\n\n* page cache tiering의 방향이 RAM으로부터 SSD로 가는 경우는 page eviction 시 class-2에 해당하는 page들을 SSD로 저장하는 경우임. page cache tiering의 방향이 SSD로부터 RAM으로 가는 경우는 class-1의 “currently-hot”한 page들과 매칭되는 associated-likely-zone이 존재하고, 동시에 현재 시스템에 page cache로 사용할 수 있는 RAM의 여유 공간이 존재할 때, SSD에 저장되어 있었던 해당 associated-likely-zone을 RAM에 미리 올리는 경우임. page cache로 사용할 수 있는 RAM의 여유 공간보다 associated-likely-zone의 크기가 큰 경우에는 RAM의 여유 공간 만큼만 우선적으로 RAM에 올려짐.\n\n* 이때, associated-likely-zone 중에서 우선적으로 RAM에 올려져야 할 영역을 결정하는 방법으로써, “currently-hot”한 현재 data와 지리적으로 가까운 영역의 data를 우선적으로 선택하는 방법, associated-likely-zone의 data들 중에서 access frequency가 높았던 data들을 우선적으로 선택하는 방법 등을 사용할 수 있다. 이에 대한 구체적인 방식은 본 특허와 개별적으로 구현될 수 있으므로, 별도의 특허에서 다루어진다.\n\n* associated-likely-zone은 과거의 access 패턴에 기반하여 서로 비슷한 시간대에 access되었던 data들의 set으로 구성한다. 여기서 ‘서로 비슷한 시간대’라는 개념은 window 2의 window size에 의해 결정된다.\n\n* 특정 address arange가 LZ인지, ULZ인지 구분하는 방법?\nLZ (Likely Zone)와 ULZ (Unlikely Zone)을 선정하는 방법:\naccess되는 page를 보면, 해당되는 inode정보와 이를 access한 process 정보를 알 수 있다. inode 정보를 보면, 이 page가 어떤 파일에 연결되어있는지를 알 수 있다. 이렇게 되면 그 파일이 걸쳐있는 address space 정보 (LBA range)를 알 수 있으며, 이는 likely zone의 일부로 마킹될 수 있다. 여기서 해당 파일 전체를 likely zone으로 할 것인지 해당 파일의 일부를 likely zone으로 할 것인지는 별도의 likely zone determinition rule에 의해 결정된다. 그리고 likely zone으로 마킹된 영역을 언제 class-2 t2 page cache media (e.g., SSD)에 loading할 것인지, loading한다면 likely zone 영역의 데이터들을 어떤 순서로 읽어들일지는 likely-zond loading rule에 의거하여 결정된다. LZ과 ULZ를 선정하는 빈도/시기는\n\n== PATENT-BRIAN-2013-00X ==\n\n* 하나 이상의 SSD를 Page Cache Media로 사용하는 경우, (1) SSD array manager와 연계하여 보다 효율적인 caching I/O를 달성하는 방법 (RACS 기반의 기존 SAVL을 그대로 이용하되 interfacing에 관련된 내용), 혹은 (2) 복수개의 SSD를 caching I/O에 맞도록 coordination하는 방법 (RACS 기반의 기존 SAVL에 추가적으로 caching I/O를 잘 handling할 수 있도록 하는 최적화된 I/O management 방법)\n\n\n* 복수 개의 SSD를 tier-2 page cache media로 사용하는 경우, SSD 1에 free space가 부족한데, 그 SSD 내에 cache되어 있는 page chunk들이 계속 caching해둘만한 가치가 있는 경우, page chunk migration (between SSDs)을 수행한다. 이때, tier-1 page cache 내의 page node 내의 page data location field 값은 update한다. (이때, 누가 migration을 initiation하는 것이 적절할까? host의 hybrid page cache manager? 혹은 activie SSD? 아무래도 SATA 기반의 SSD를 사용하는 경우에는 전자가 좀 더 현실적일 것으로 보임)\n\n\n* tier-2 page cache의 eviction threshold period를 두어서 RAM page cache 경우보다는 길겠지만 tier-2 page cache의 총량이 허용할 수 있는 page 용량을 감안하여 계산된 time period 동안 access 실적이 없으면 tier-2 page cache 중에서도 evictable flag를 set하게 되는데, 이때 복수개의 SSD를 tier-2 page cache media로 사용하는 경우, 전체 SSD 가용 용량을 합산해야 한다.\n\n== PATENT-BRIAN-2013-00X ==\nMultiple I/O Queue Handling for SSD Cache\n\n\n[청구항]\n\n== PATENT-BRIAN-2013-00X ==\npage chunk I/O handling mechanism for multi-tenancy SSD page cache\n\n\n[요약]\n물리적인 SSD 하나가 통째로 page cache로 사용되는 경우에는 SSD 전체를 위와 같이 나누어 사용하면 되겠으나, 하나의 SSD를 page cache media와 다른 용도로 같이 사용해야 하는 경우를 위한 구조 및 방법은 별도의 특허에서 기술하는 것으로 함. page cache media로 사용되는 공간과 다른 목적으로 사용될 공간을 별도의 partition으로 잡고, page cache media로 동작하기 위한 partition을 다시 meta 정보 영역과 page data 영역으로 slice하여 사용함. 이때, SSD는 page cache media로 partitioning된 영역에 해당하는 I/O에 대해서는 병렬성과 page chunk lookup table의 단순성을 극대화 할 수 있게 설계된 page chunk I/O 방식으로 처리할 수 있도록 하는 것이 필요함.\n\n[청구항]\n\n\n== PATENT-BRIAN-2013-00X ==\n\n=== # I/O Pattern-optimal Data Placement for Tiering ===\n\n* Automatic tiering 시, 단순히 hot data들을 fast media에 가져다 놓고 마는 것이 아니라, IO bottleneck이 미연에 방지될 수 있도록 data의 access pattern을 aware해서 차별적으로 배치하는 방법\n예) (a) random-read-intensive 한 data들, (b) sequential-write-intensive한 data들을 다른 방식으로 배치 (tiering)\n\n\n* 이에 필요한 data access pattern 모니터링/분석 방법\n데이터 수집 및 분석 시 PCIe 카드 엔진 활용 가능?\nNIC 이나 DMA를 통해서 data move가 일어나는 경우, PCIe 카드 등을 통해서 IO stream 분석\n\n\n* 이를 위해 필요한 system architecture 구조\n기본적으로 하나 이상의 SSD와 하나 이상의 HDD, 그리고 PCIe 카드, DRAM 일부 사용 방식, Tiering Mapping Table 구조, ...\n\n\n=== # 발명의 이용분야 ===\n=== # 배경 / 기존 기술의 문제점 ===\n=== # 본 발명의 특징 / 효과 ===\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n=== # Memo / Questions ===\n\n\n<br/>\n\n\n\n== Patent pool ==\n\n\n=== (SmartSSD API) SSD-internal I/O pattern logging interface and mechanism ===\n\n\n==== Questions ====\n\n* SmartSSD에서 제공할 수 있는 logging 서비스로서 어떤 것들이 있을 수 있나?\n:- 어느? 정도의 free space를 필요로하는 critical (heavy) I/O가 어떤? 주기로 도래할 지 알 수 있을까?\n:- I/O prediction에 도움될 수 있는 정보를 SmartSSD가 기록했다가 필요한 때 (안전한 방법으로?) 줄 수 있을까?\n:- I/O prediction까지는 아니더라도 해당 SSD의 I/O wellness(어떻게 정의?)를 측정했다가 bottleneck을 회피하는 데 유용한 정보를 제공할 수 있을까?\n:- 어떤 SSD가 현재 주어지고 있는 I/O workload에 대해 list performance spec을 만족하는데 어려움을 겪고 있다는 것을 알려줄 수 있는 정보가 어떤 것이 있을까? (SSD 내 write buffer의 fullness 혹은 I/O queue의 유동성? amount of free space in over-provisioning area?) (-> I/O wellness 라는 metric을 이것과 연관시켜 정의할 수도 있으며, 결국 SLA 혹은 Performance QoS와 연관시킬 수 있음)\n:- 지금까지의 S.M.A.R.T.와 비교하였을 때, 어떤 차별점이 있는가? 기존의 S.M.A.R.T.가 제공하지 못하던 타입의 정보를 제공하고, 이로 인해 기존에는 불가능했던 새로운 알고리즘 구현 혹은 새로운 서비스 제공이 가능해짐을 보이면 좋겠음.\n\n\n\n:- workload의 history?\n:- 각 erase block이 erase되어야만 했던 주기?\n:- free space의 추이 (얼마나 많이 남아 돌던지)?\n:- I/O의 heaviness 패턴?\n:- SSD내 write buffer (혹은 write cache)의 utilization정보? (즉, write buffer가 넘칠 정도가 되어서 I/O wait을 해야만 했던 상황이 얼마나 자주 발생했는지, write buffer의 가득찬 정도를 백분율로 표현한다고 했을 때, 평균/표준편차 등으로 대표할 수 있는 normal distribution을 따르는지?\n:- 전체 sequential read/write \n\n\n==== 배경 ====\n\n* 각 SSD 모델별로, 또 동일한 모델의 SSD라 하더라도 어떤 workload에 노출되어왔는지에 따라, 현재 낼 수 있는 I/O performance가 동일하지 않을 수 있다 (!check! 관련 실험 결과 - SSD 830을 이용하여 같은 시간 동안 하나의 host에서 생성되는 workload들을 나누어 받았다 하더라도 내부적인 free block의 갯수 및 random write에 의한 block 내 파편화등의 상태가 상이하여 성능에 차이가 나는 것을 보여줄 것. uFLIP 혹은 filebench 활용 가능). 한 예로, SSD가 어느 호스트의 어느 file system에 매핑되었는지에 따라 그 SSD가 받는 workload의 특성이 다를 수 있다. file system mount point가 달라지거나, 기존과 다른 새로운 응용이 설치/서비스되는 상황이 되면 \n\n\n=== I/O Prediction-based Proactive Data Placement ===\n\n* I/O prediction을 기반으로 \"proactive\" 하게 data를 배치시킨다는 것 자체!\n\n* I/O prediction에 의거하여 \'어떤\' data에 대한 tiering이 \'언제\' 일어나야 할 지를 결정 (elastic tiering period 특징을 가짐 - 기존 방식은 static tiering period)\n\n* I/O를 triggering하는 indicator (전조) 정보가 감지되면 해당되는 data block을 미리 필요한 장소에 proactive하게 placement시키는 방식임 (이러한 측면에서 I/O prediction하는 방식이 기존의 accumulated access frequency 기반의 naive prediction과 차별화됨)\n\n* Run-time에 저비용으로 감지될 수 있는 Indicator 정보와, 이에 의해 access될 data 간의 mapping은 Bayesian Inference 이용\n\n\n=== Tiering Method Avoiding I/O Bottleneck ===\n\n* I/O Prediction에 의해 예측된 미래의 Hot Data를 Proactive하게 Placement한다고 할 때, 예상되는 access pattern으로 인해 발생 가능한 I/O Bottleneck을 최소화할 수 있도록 배치하는 방법\n\n* 예를 들어 미래의 hot data block 1 (200MB), hot data block 2 (100MB), hot data block 3 (400MB)이 1분 후에 access 될 것으로 예측되었다고 가정. data block 1에 대해서는 4KB 단위로 random read가 dominant한 access pattern이 예상되고, data block 2에 대해서는 1024KB 단위의 sequential read가 dominant한 access pattern이 예상되고, data block 3에 대해서는 4KB 단위의 random read와 512KB 단위의 sequential write이 각각 80:20의 비율로 mix된 형태의 access pattern이 예상된다고 했을 때, 각 data block을 어디에 어떤 형태로 placement시킬 것인가?\n\n: machine learning 혹은 pattern mining에 기반한 base workload pattern data를 기반으로 incremental하게 update될 수 있는 data access의 spatial locality와 periodicity\n: Local node 내에서의 vertical tiering 뿐만 아니라 분산 node들 간의 horizontal tiering도 염두에 둘 것\n\n\n* 기존 기술과의 대비 (naive I/O prediction vs. full-fledged I/O prediction)\n: 기존 기술은 누적 hit count 정보에 의지하는 naive I/O prediction으로 볼 수 있음. 이러한 방식은 workload의 변화를 제대로 반영하지 못하기 때문에, static한 workload에 대해서는 잘 동작하지만, moving target처럼 dynamic한 workload에 대해서는 오히려 과거의 누적 hit count metric이 현재의 workload 패턴을 왜곡하는 문제점을 가지고 있음. (temporal locality와 spatial locality가 깨지는 순간이 여러번 존재할 수록 기존의 naive I/O prediction 방식으로 성능 향상은 어려워짐)\n\n\n\n\n* 경쟁 기술과의 차별화\n: EMC의 FAST 기술이 안고 있는 근본적인 한계점은 무엇일까?\n: data access 패턴의 hot/cold 만 분류해서 hot은 fast tier에, cold는 slow tier에 두는 것이 전부인가? 아니면 그것 외에 뭔가가 더 있는가?\n: 어떻게 보면 기존의 automated storage tiering은 naive proactive placement로 볼 수도 있다. (과거에 자주 access되었던 data가 앞으로도 자주 access될 것이라고 믿고 data를 이동시키는 것이므로. 그러나 근거가 부족함)\n:: 이러한 naive proactive placement 방식으로 야기되는 단점이 있다. 만약 과거에는 자주 access되었는데 마침 tiering되고 난 후에 자주 access되지 않게 되면, 괜히 SSD의 wear-out만 유발시킨 결과가 된다. 다음 tiering 주기가 돌아오기 전 까지는 계속 느린 media에서 I/O가 serve되기 때문에 그만큼 pain이 된다.\n:: 물론 read에 대해서는 cache를 적극 활용함으로써 첫 access 시에만 slow media access로 인한 penalty를 얻고 이후에는 cache가 제공하는 수준의 성능을 얻을 수 있게 된다.\n:: 그러나 write에 대해서는 문제가 다르다. HDD의 경우 sequential write 경우에는 큰 문제가 되지 않는다. 그러나 random write 특성을 가지고 있으며, 게다가 write-intensive한 I/O라면? 그런데 random write이면서 write-intensive한 경우, write되는 address range가 생각보다 넓지 않다면 어떻게 될까? 즉 특정 구간 특정 데이터에 대한 update가 빈번한 것을 의미한다.\n:: write address range가 N개의 4KB 블럭으로 이루어져 있고, Storage System 내에 물리적인 Disk 갯수가 M개 존재한다고 가정하자. 만약 M이 N보다 적절하게 커서 RAID 10을 하건, RAID 5 등으로 이루어져 있건 간데, N개의 4KB 블럭을 각각 별도의 HDD로 분산 시킴으로써 random write을 random write이 아닌 것처럼 보이게 할 수 있다면? 예를 들어 VNX 5300 처럼 SAN 박스 하나 내에 HDD가 125개가 들어있고, random하고 intensive한 write pattern이 오고 있고, write access range가 125개 이하의 address 내에서 반복되고 있다면, 매번 도달하는 random write request를 마치 RAID 0로 striping 하듯이 계속 다른 HDD로 보냄으로써 I/O de-randomization을 할 수 있을 것이다. 여기서 좀 더 나아가서 하나의 request에 대해서 HDD가 완벽하게 처리하는 데에 걸리는 시간이 10ms 이고, 매 random I/O가 도달하는 평균 시간은 (평균 가지고 되려나? 아무튼 이것은 조금 뒤에 다시 생각해보자) 1ms 라고 한다면, 이론적으로 10번의 random I/O가 지난 다음, 11번째의 random I/O가 올 때에는 처음에 write했던 HDD에다가 다시 write을 해도 된다. 즉, 그 HDD에서 직전의 I/O가 끝나기를 기다리고 있지 않아도 된다는 것이다. 그러나 이러한 방식은 나중에 scatter했던 I/O들을 다시 불러모으려고 할 때 contribution한 HDD가 다른 I/O를 serving하고 있지 않을 수 있어야 최고의 성능을 낼 수 있게 된다. 즉, HDD cluster 구성을 상당히 dynamic하게 가져갈 수 있다면 어떨까? 이러한 dynamic clustering이 정말 최고의 효과를 낼 수 있는 workload case로는 어떤 것이 있을까? data placement를 함에 있어서 결국은 어딘가에 써야 할 것이고, (slow tier로 마크된 HDD들 array에다가 data를 쓴다고 그냥 푸대접하면서 써버릴 것이 아니다) slow tier에다가 쓸 때에도 나중에 어떻게 read되고 다시 write 될 지를 고려한다면, workload 특성에 따라서 concurrent I/O의 갯수 및 address range 크기가 다를 수 있는데, 그것을 aware해서 write을 해둔다면, 비록 slow-tier에다가 write했지만, 그리 slow하지만은 않은 성능을 내게 할 수 도 있을 것이다. 이것은 proactive data placement에 대한 이야기가 아니다. proactive와는 별개로, automated storage tiering을 함에 있어서 workload characteristics를 고려한 data placement에 대한 이야기이다.\n\n\n\n\n서로 독립적인 I/O stream의 갯수가 100개 라면 (즉 100개의 process가 I/O를 쏟아내고 있는 경우), 그리고 I/O queue의 크기가 N_Q라면, 어떻게 이러한 문제를 해결할 수 있을까?  \n\n  \n:: write에 대해서는 \n:: write-intensive하다는 것의 정의는? 이러한 경우에는 in-memory write caching (OS가 허용하는 범위의 delayed write을 최대한 활용)을 이용하되 transaction 기반으 atomicity를 보장함으로써 문제를 부분적으로 해결할 수 있다. transaction으로 묶여질 수 있는 여러 번의 I/O request (write)가 끝나기 전까지는 commit되지 않은 것으로 치는 것임. Fusion IO의 atomic write은 이를 어떻게 해결하는지? \n\n만약 write commit이 매우 중요한 민감한 데이터에 대해서는 어떻게 해야할까? 그리고 SSD-internal memory buffer를 이용해서\n: SAN 장비 내에서의 HDD와 SSD 간의 tiering만 되는 것일까? (vertical tiering within local node)\n: SAN 장비 간의 tiering이 되기 위해서는 어떤 것이 더 필요할까? EMC에서 이미 그러한 기술/솔루션을 가지고 있지는 않을까? (horizontal tiering between boxes)\n\n* 다양한 사례\n: 기존에 이미 생성되어 있던 data를 미래 access 예측에 따라 위치 변동을 시키는 경우\n: Tiering을 한다고 했을 때, access 빈도에 따라서 fast tier / slow tier 간 이동시키는 것이 전부일까? 그런 것 말고 다른 차원의 tiering은 없을까?\n: 새롭게 write되려는 data를 처음부터 어디에 배치시키는 것이 좋을까?\n\n* Placement 접근 방식\n: Tiering으로 한정?\n: Tiering과 Caching과의 결합 방식? (Caching engine에게 hint를 주는 방식)\n\n* I/O Prediction 결과를 받아서 proactive하게 data를 tiering 시키는 방법 및 아키텍쳐\n* Key questions\n:- 기존엔 proactive tiering이 없었나?\n:- 만약 없었다면 어떤 어떤 부분들을 청구항으로 넣어야 할까?\n:- 만약 있었다면 어떤 차별화가 필요할까?\n\n=== I/O Workload Analyzer Engine ===\n* I/O Trace 및 다양한 시스템 정보를 기반으로 I/O를 prediction하는 방법 및 구조\n*\n\n== Disclosure of Invention :: Template ==\n\n<!--\n== PATENT-BRIAN-2013-00X ==\n-->\n\n=== # RAM-SSD Hybrid Page Cache Architecture ===\n=== # 발명의 이용분야 ===\n=== # 배경 / 기존 기술의 문제점 ===\n=== # 본 발명의 특징 / 효과 ===\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n=== # Memo / Questions ===','utf-8'),(1958,'== PATENT-BRIAN-2013-001 ==\n\n=== # RAM-SSD Hybrid Page Cache Architecture ===\n\n[[Bnote patidea 2013-001]]\n\n== PATENT-BRIAN-2013-002 ==\n=== # Low-computation-overhead and Memory-efficient Periodicity Detection Method ===\n[[Bnote patidea 2013-002]]\n\n== PATENT-BRIAN-2013-003 ==\n\n=== 맵리듀스 작업의 병목 탐지 및 원인 분석을 위한 모니터링 프레임워크 기술 (A monitoring framework for detecting and analyzing execution bottlenecks of MapReduce jobs) ===\n\n[[Bnote patidea 2013-003]]\n\n== PATENT-BRIAN-2013-004 ==\n\n<!-- === Straggler-immune Data/Task Placement in the Distributed Environment === -->\n\n=== Straggler-immune Data Placement in the Distributed Environment (HDFS?) ===\n\n\n\n\n=== Memo ===\n\n* title candidates\n: outlier(straggler, failure, ...)-immune data placement for distributed file system\n: straggler-immune data placement in the distributed file system (DFS)\n\n\n* Assumptions // 환경\n: replica management가 있는 DFS 환경\n: replica management algorithm 변경 가능\n: MapReduce/HDFS처럼 data가 있는 곳에 computation을 보내는 구조\n: DFS 위에서 Hadoop MapReduce처럼 분산 병렬 처리를 수행하는 환경\n\n* Assumptions // Failure Characteristics \n: straggler 발생과 task의 type 간의 연관성이 있음\n: {task type, node} tuple이 \n\nHDFS 및 MapReduce 환경에서,\n\n\n특정 node와 특정 task type의 조합과 straggler 발생 빈도 간에 연관 관계가 있을 수 있을까?\n\n\n즉 straggler가 발생했던 case를 관찰했을 때,\nnode 정보만으로는 패턴 (혹은 straggler 발생과의 연관성)이 보이지 않고,\ntask type 정보만으로도 패턴 (혹은 straggler 발생과의 연관성)이 보이지 않지만,\nnode 정보와 task type 정보를 같이 고려했을 때 straggler 발생 빈도/확률과 연관성을 볼 수 있었다면?\n\n\n\n\n* Bottleneck History Record (BHR) based approach\n: do not throw away the bottleneck experience (history). KEEP IT to use the knowledge for later use.\n\n* Replica management\n: at the very first time to place the data\nDistributed File Systems\n\n\n\n=== # 요약 ===\n\n\n=== # 발명의 이용분야 ===\n\n* Hadoop MapReduce/HDFS 혹은 이와 유사한 분산 처리 시스템이 구동되는 Enterprise 데이터 분석 클러스터.\n* Hadoop MapReduce/HDFS 혹은 이와 유사한 분산 처리 시스템이 구동되는 Public Cloud 데이터센터\n\n\n----\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* Hadoop의 기본 DFS인 HDFS (Hadoop Distributed File System)은 replica management를 수행하고 있음.\n\n\n* HDFS에서의 replica management는 3-copy replica 구성 시, 다음 몇 가지 원칙에 의해 data를 분배하고 있음.\n:- 하나의 node에 동일 block이 두 개 이상 존재하지 않는다\n:- 하나의 rack에 동일 block이 세 개 이상 존재하지 않는다\n:- 첫 번째 replica는 client가 구동하고 있는 node에 배치\n:- 두 번째 replica는 첫 번째 replica가 있던 node가 속하지 않은 다른 rack의 임의의 node에 배치\n:- 세 번째 replica는 두 번째 replica가 배치된 rack 내의 다른 node에 배치\n:- 1st-2nd-3rd replica 배치는 순차적으로 실행\n\n\n* Yahoo!의 Hadoop Cluster에서 10개월간 구동된 17만개의 MapReduce job들을 분석한 연구에 따르면 약 3% 정도의 Job들이 fail되었으며, 각 task의 특성과 failure 발생과 연관성이 있음을 확인할 수 있다. (예를 들어, MapReduce 전체 failure의 80% 이상이 map task에서 발생하였으며, map task failure의 36%는 array indexing error에 의한 것이었음. 그리고 reduce task 의 23%는 I/O exception에 의한 것이었음)  이러한 failure 및 straggler로 인해 task restart가 많이 발생하고 있으며, 이는 MapReduce/HDFS 성능을 저하시키는 주요 요인임.\n\n\n* 현존 Hadoop MapReduce/HDFS 시스템에서는 straggler가 발생했다고 판단되면, 해당 task를 drop 시키고 새로운 node에서 task가 실행될 수 있도록 하고 있음. 즉, 이미 발생한 straggler에 대해서는 speculative execution을 수행하고 있지만 여전히 한계점은 존재함. (1) speculative execution을 위해 필요한 additional data copy overhead 존재. (2) 새로운 execution node를 찾는다 하더라도 그 node가 straggler-free한 node인지 보장할 수 없기 때문에, 제2, 제3의 straggler가 발생할 가능성 존재. (3) additional copy를 하려고 하더라도 이미 task들이 tight하게 많이 구동되고 있는 상황에서, 여유 execution slot을 가지고 있는 적절한 node를 바로 찾지 못할 수 있으며, 이렇게 기다리는 것 자체가 job completion time을 증가시키는 부정적인 효과가 있음.\n\n\n----\n\n=== # 본 발명의 특징 / 효과 ===\n\n\n* 특징\n:- 기존처럼 straggler가 발생한 후에 대응하기 보다는 (사후 대응), HDFS에 처음 data가 놓여질 때부터 straggler-immune node에 배치될 수 있도록 하는 사전 대응 방식을 특징으로 하고 있음.\n:- {node, task-type, bottleneck-risk-score} tuple로 구성되는 Bottleneck History Record (BHR) 정보에 기반하여 해당 task-type에 대해 bottleneck-risk-score 값이 가장 작은 node에 replica data를 배치하는 방식임\n:- {node, task-type}에 대한 bottleneck-risk-score 정보는 JobTracker에 추가되는 Bottleneck History Record Manager 모듈에 의해 update됨\n:- 참고로, 기존 HDFS에서의 data placement (replica management 시)에서는 이러한 straggler-immune data placement는 고려되어 있지 않음.\n\n\n* 기대 효과\n:- speculative execution을 위한 data copy overhead 감소\n:- 제2, 제3의 straggler / failure 발생 확률 감소\n:- 결과적으로, Hadoop MapReduce Job의 성능 향상 효과\n\n\n* 구현의 용이성\n:- Apache Jira HDFS-385에서 언급된 pluggable interface를 이용 시, 본 발명에서 제안하는 data placement 알고리즘을 HDFS의 block placement algorithm으로 추가하기가 용이함.\n\n\n* 침해 적발의 용이성\n:- namenode에서 수집하는 데이터들을 관찰하거나, HDFS-385 interface를 통해 오가는 데이터들을 관찰하였을 때, node, task-type, failure rate 정보를 namenode가 (혹은 pluggable data placement module이) 읽어들이고, 그 중 가장 failure rate 값이 낮은 하나의 node가 replica data를 저장하기 위한 datanode로 선택된다면, 본 특허를 침해한 것으로 판단 가능.\n\n\n----\n\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n\n\n* 기존처럼 straggler가 발생한 후에 대응하기 보다는 (사후 대응), HDFS에 처음 data가 놓여질 때부터 straggler-immune node에 배치될 수 있도록 하는 사전 대응 방식을 특징으로 하고 있음.\n\n\n* {node, task-type, failure rate} tuple 정보에 기반하여 해당 task-type에 대해 failure rate이 최소화 될 수 있는 node에 replica data를 배치하는 방식임\n\n\n==== 시스템 구성 요소 ====\n\n\n==== 처리 절차 ====\n\n\n==== 예상 효과 ====\n\n* Anomaly (straggler, failed task) 발생 자체를 줄임으로써, Straggler 혹은 Failed Task로 인해 야기되는 추가 처리 비용을 감소시킬 수 있음.\n\n* Straggler의 경우, speculative execution으로 야기되는 additional data copy overhead 감소 (사라지거나 감소됨) 효과를 기대할 수 있음. 특히, HDFS block size가 큰 경우 (처리 해야 할 data는 크지만, node의 수가 적은 경우, 64MB 이상으로 tuning하여 사용하는 경우가 많이 있음 - 그런데, 실제로 이렇게 tuning하면 어떤 장점/효과가 얼만큼 생기나?) additional data copy로 인한 overhead가 그만큼 커지게 되므로, 이 경우 straggler 발생 확률을 낮춤으로써 얻는 이득 역시 그만큼 커지게 됨.\n\n* Failed task의 경우, 상황에 따라서 두 가지 처리 옵션이 있다. 첫 번째 옵션은 failure가 발생했던 해당 node에서 task를 재시작하는 방법이며, 두 번째 옵션은 다른 node에서 task를 재시작하는 방법임.\n\n* Task failure의 원인이 해당 node의 H/W 혹은 S/W에 문제가 있는 것이 아니었다면 첫 번째 옵션을 택할 수 있다. 물론 H/W 혹은 시스템 S/W 결함이 아니었다는 것을 알수 있었어야 한다. 그러나 해당 node의 H/W 혹은 S/W에 문제가 있다는 것을 알고 있는데, 당장 다른 node의 execution slot도 여유가 없는 상황이라면, execution slot이 생길 때까지 좀 더 기다렸다가 재시작을 해야 한다. 이때, 기다려야만 하는 경우라면, 그만큼 job 처리 속도의 저하로 이어진다. 다른 노드에서 재시작을 하게 되더라도, 역시 additional data copy가 필요하며, 이로 인한 overhead는 피할 수 없다.\n\n\n----\n\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n\n* Google patent search (2 results, no relevant result)\n (HDFS OR \"hadoop distributed file system\") (((block replica) OR data) placement) (straggler OR fail*)\n\n* Google patent search (2 results, no relevant result)\n (HDFS OR \"hadoop distributed file system\") (((block replica) OR data) placement) bottleneck\n\n* Google patent search (5 results)\n HDFS block replica placement\n:- [http://www.google.com/patents/EP2288998A2?cl=en Directed placement of data in a redundant data storage system]\n:: Filed 9 Apr 2009 - Published 2 Mar 2011, John Howe - Omneon, Inc.\n\n\n\n* 검색식\n: mapreduce straggler (\"historical record\" OR \"history\")\n: 2건\n\n:* System and Method for Analyzing Data Records\n:: [http://www.google.com/patents/US20120215787 www.google.com/patents/US20120215787]\n:: App. - Filed 28 Feb 2012 - Published 23 Aug 2012 - Jeffrey Dean - Dean Jeffrey, Dorward Sean M, Ghemawat Sanjay, Pike Robert C, Quinlan Sean\n\n:* Scalable user clustering based on set similarity\n:: [http://www.google.com/patents/US7962529 www.google.com/patents/US7962529]\n:: Grant - Filed 6 May 2010 - Issued 14 Jun 2011 - Mayur Datar - Google Inc.\n\n=== # Memo / Questions ===\n\n==== References ====\n\n\n\n* Google search\n map reduce straggler study\n\n:- [http://static.usenix.org/event/osdi08/tech/full_papers/zaharia/zaharia_html/ Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]\n:: Matei Zaharia, Andy Konwinski, Anthony D. Joseph, Randy Katz, Ion Stoica // University of California, Berkeley\n\n:- [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CDAQFjAA&url=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2FUM%2Fpeople%2Fsrikanth%2Fdata%2FCombating%2520Outliers%2520in%2520Map-Reduce.web.pptx&ei=pq1iUer9NK6eiAfN2IHYBQ&usg=AFQjCNEOOEtTE2_nVb6f2qQN09OpoLcS5A&sig2=HakGM53pMqVB1y2PqhQZJQ Combating Outliers in Map-Reduce - Microsoft Research]\n:: Srikanth Kandula, Ganesh Ananthanarayanan, Albert Greenberg, Ion Stoica, Yi Lu, Bikas Saha, Ed Harris\n\n\n* Google search\n map reduce straggler study once relationship\n\n:- [http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]\n:: Soila Kavulya, Jiaqi Tan, Rajeev Gandhi and Priya Narasimhan. Carnegie Mellon Univ., Pittsburgh, PA, USA\n:: [http://www.pdl.cs.cmu.edu/PDL-FTP/associated/CMU-PDL-09-107.pdf Another Version, CMU-PDL-09-107 December 2009]\n:: [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster, CCGrid 2010]]\n\n:- [http://cseweb.ucsd.edu/~vahdat/papers/themis_socc12.pdf Themis: An I/O-Efﬁcient MapReduce // SOCC 2012]\n\n\n\n\n<br/>\n\n== PATENT-BRIAN-2013-007 ==\n\n=== data와 IO insight을 packaging 하는 기술 ===\n\n: 해당 [[data에 대한 IO pattern/insight 정보]]를 data와 함께 packaging하여 (마치 object-oriented manner) 같이 이동되게 함으로써, replication, migration, (node 간 tiering?) 등 분산 환경에서 data가 여러 노드로 이동하는 경우에도 해당 data에 대한 처리가 최적으로 이루어질 수 있도록 하는 기술\n: data에 대한 IO insight 정보로서 다음 정보가 포함될 수 있다\n\n:* data access patterns:\n::- 어떤 application이 얼마나 자주 이 data를 access하는지? (이 data를 access하는 application에 대한 정보가 없으면 insight가 잘못 적용될 수도 있을지도 모른다 - Hadoop 같은 경우는 어떻게 MapReduce Application 정보를 알 수 있을까? 혹시 MapReduce application에 대한 정보가 Hadoop layer에 가려지는 것은 아닐까? JobTracker/TaskTracker를 고려해야 할까?)\n::- 이 데이터(파일?)는 Rd(Read)-intensive 인가? Wr(write)-intensive인가?\n::- 이 데이터는 RRd(random read) / RWr(random write) / SRd(sequential read) / SWr(sequential write) 중 어느 것이 dominant한가? 혹은 Mix 되어 있다면 그 비율은 어떻게 되는가?\n\n:* data간 access pattern 연관성\n::- 이 data가 access되고 나면 어느 정도 확률로 어떤 다른 data가 access되는지?\n::- 어떤 data가 access되고 나면 어느 정도 확률로 이 data가 access되는지?\n\n:* data hot/cold history\n::- 이 data가 hot한 적이 얼마나 자주 있었나?\n::- 이 data가 hot한 시기가 어떤 패턴을 가지고 나타나는가?\n::- 한 번 hot하고 나면 이후에도 다시 hot할 가능성이 높은가?\n\n== PATENT-BRIAN-2013-005 ==\n\n=== IOWA based Proactive Data Placement 자체 특허 ===\n\n: 다양한 정보/Insight을 기반으로 Proactive하게 Data를 Placement하는 기술\n:: (Caching/Tiering in Local Case, Data Replication/Migration in Distributed Case)\n\n\n: 여기에, ML (혹은 HML까지도?)을 적용한다는 아이디어를 추가하자\n:: ML 기반의 IO Prediction\n::: ML을 통해서 예측을 한다면, 어떤어떤 정보들로부터, 어떤 예측을 해야하는 걸까?\n::: Fine-grained prediction이 말이 되는 소리인가?\n::: Coarse-grained prediction을 한다면 어느 스케일까지 fine/coarse-grained 해져야할까?\n\n\n:: ML 기반의 IO Insight (Data Placement를 위한 Macroscopic Guideline)\n::: ML을 통해서 최적의 배치를 할 수도 있는 것일까?\n:::: 가능함. 예를 들어, \"이러이러한 sign/indication을 보이는 data는 언제쯤 어떤 형태의 IO 양상을 보일 확률이 __%임\" 같은 형태의 insight이 있다면, \"이런 data는 현재 local system 뿐만 아니라 networked system의 상태도 같이 고려하여 어디에 위치시켜두는 것이 적당\" 하다는 식의 data placement를 \"proactive 하게\" 할 수 있겠음.\n::: IO Insight의 요건:\n::::# indication, as simple as possible\n::::# indication, as specific as possible\n::::# indication, efficiently traversable - corresponding indication case node들을 쉽게, 효과적으로 traversing하면서 최종 insight leaf에 도달 (Huffman code? Radix tree?)\n::::# indication, easily extensible - indication 추가 시에 변경되는 부분이 최소화될 수 있어야 함\n::: UCB study같은 형태로 나오는 것이 최선일까? 그런 형태/내용 외의 다른 것도 얻어낼 수 있을까?\n\n\n: HML이 도움이 되는 이유는 무엇일까?\n:: 굳이 HML이 아니더라도 ML 만으로도 잘 할 수 있는 범위는 어디까지일까?\n\n\n* Y1 = Proactive Data Placement\n* Y2 = Data-system-optimal Placement\n\n: Y1.x1 = 어느 address의 데이터(들)이\n:: Y1.x1.1 = 그 데이터들은 sequential access가 가능한 형태로 배열되어 있는가? (만약 그렇다면 굳이 cache시킬 필요가 있을까? 혹시 있는 건 아닐까? 정말 없을까? Sequential read하는 경우 SSD case와 HDD case를 비교해볼 필요 있음)\n:: Y1.x1.2 = 그 데이터들이 access되고 나면, ___%의 확률로 따라서 access되는 데이터들도 있지 않을까? (그렇다면, 그 놈들도 연달아서 미리 loading?)\n: Y1.x2 = 앞으로 얼마 후에\n: Y1.x3 = Access될 것인가?\n:: Y1.x3.1 = Read일까? Write일까?\n:: Y1.x3.2 = 그 얼마 후 Access되고 나서 몇 번을 더 Access될까? (이것을 알 수 있을까?)\n\n\n* X1 = IO Access Pattern\n* X2 = IO 유발자 정보\n\n\n\n\n\n\n\nproactive data placement (caching/tiering)를 위해서, layer abstraction 혹은 virtualization이 필요하지는 않을까?\n- 예를 들어, IBM의 GPFS에서 AFM (Active File Management)을 구현할 때, data의 lifecycle 및 next use에 의거한 automatic data transfer를 위해서, 기존에는 없었던 새로운 component 혹은 새로운 layer가 필요하지는 않았을까? [1][2]\n- proactive data placement 입장에서는, next IO use를 예측하거나, user/process context를 이해한다는 측면에서, 오히려 block layer보다는 file system layer에서 바라보는 것이 더욱 적절한 것은 아닐까?\nRead cache, write cache colocation을 하면 어떨까?\nadvanced tiering: access pattern-aware optimal placement (APOP)\n\n== PATENT-BRIAN-2013-006 ==\n\n=== SSD Retention Time Controlling for Caching/Tiering 특허 ===\n\n* Caching-optimal SSD Retention Time Control\n* SSD Retention Time Controlling for Caching\n\nCache-I/O의 특성에 맞도록 SSD Retention Time을 Control하는 기술.\n\n== PATENT-BRIAN-2013-XXX ==\n\n=== State Machine based Macro IO Prediction ===\n\n== PATENT-BRIAN-2013-00X ==\n\n=== Coarse-grained Spatial Locality Based SSD Cache I/O ===\n\n=== # 배경 / 기존 기술의 문제점 ===\n\n* DRAM Cache의 부족한 용량을 극복하기 위한 솔루션으로 SSD Cache가 도입되고 있음. 기본 원리는 자주 액세스되는 디스크 블록을 SSD에 Caching함으로써 HDD의 느린 I/O 속도를 극복하도록 하는 것임.\n* 그러나 블록 레이어에 구현되는 SSD Cache의 경우, Kernel에서 관리하는 Page Cache에 의해 이미 Hot data가 Serve되고 있기 때문에, Hit Ratio를 높이기에 근본적인 한계점을 가지고 있음.\n* 한편, kernel에서 관리되는 기존 Page Cache는 다음과 같은 한계점을 가지고 있음. (1) SSD 혹은 HDD에 비해 비싼 스토리지인 RAM 기반이기 때문에 다른 스토리지에 비해 작은 용량을 가지고 있는 경우가 일반적이므로 cache로 사용할 수 있는 공간의 제약이 큼. (2) 시스템에서 사용되지 않고 있는 idle RAM 영역을 이용하기 때문에, 시스템에서 구동되는 프로세스들이 요구하는 RAM 요구량이 많아지게 되면, 그만큼 page cache가 버려지게 되며 그만큼 시스템 I/O 성능의 저하가 발생하게 됨. 또한 이로 인해 성능의 편차가 불규칙하다는 단점 또한 근본적으로 가지고 있음.\n* 한편, SSD를 이용하는 page cache가 기존에 시도된 적이 있으나 매 page access 시마다 SSD에 page를 저장하는 메커니즘으로서 (synchronous I/O) NAND flash와 RAM I/O 특성 차이로 인해 기인하는 근본적인 성능적 한계점을 가지고 있음.\n\n<br/>\n\n\n=== # 본 발명의 특징 / 효과 ===\n\n\n=== # 대표 청구항 ===\n\n* (page tiering 기반의 hybrid cache에서) spatial locality에 기반한 효율적인 page cache I/O 방법\n** 고속이면서도 자원 효율적으로 spatial locality 패턴을 파악하는 방법\n***(range size를 동적으로, 혹은 서로 다르게 할 수 있는 방법은 필요 없을까?)\n\n* page chunk handling 방법\n** [host side] spatial-locality가 있는 page들이 가급적 page chunk 단위로 묶이도록 하는 방법\n** [host side] SSD 내부의 parallelism을 극대화할 수 있도록 page chunk 크기를 정하는 방법 (i.e., channel_# x erase_block_size)\n** [host side / ssd side] tier-2 page cache에 저장된 특정 page가 access될 때, 그 page가 속한 page chunk의 데이터를 같이 pre-loading 하는 방법\n*** 해당 page chunk에 대한 status update하는 것이 필요할까?\n\n* page chunk eviction 방법\n** [ssd side] tier-2 page cache에서 page chunk를 eviction 시키기 전에, page chunk 중에서 popular 한 page는 SSD에서 evict하기 전에 RAM에 올리는 것\n\n\n=== # 기술 상세 ===\n\n=== # 선행 기술 ===\n\n다음 검색식\n (Spatial locality based I/O SSD cache)\n으로 1건의 미국 공개/등록 문건을 검색할 수 있었으나,\n본 발명과 유사한 spatial locality based I/O for SSD cache 관련 선행 기술은 발견하지 못하였음.\n\n유사한 주제를 다루는 논문으로\n __\n이 있었음.\n\n그러나 __ 측면에서 본 발명과 상이함.\n\n<br/>\n\n\n=== # 침해 적발 ===\n\n== PATENT-BRIAN-2013-00X ==\nContent Repeatability-Aware SSD Cache Management\n\n=== 대표 청구항 ===\n\n== PATENT-BRIAN-2013-00X ==\n=== Likely Zone Based Page Pre-placement ===\n\n\n* periodicity의 특성을 이용해 pre-placement하는 개념도 추가할 수 있을까?\n\n* associated-likely-zone 기반의 page pre-placement (to RAM)\n\n* page cache tiering의 방향이 RAM으로부터 SSD로 가는 경우는 page eviction 시 class-2에 해당하는 page들을 SSD로 저장하는 경우임. page cache tiering의 방향이 SSD로부터 RAM으로 가는 경우는 class-1의 “currently-hot”한 page들과 매칭되는 associated-likely-zone이 존재하고, 동시에 현재 시스템에 page cache로 사용할 수 있는 RAM의 여유 공간이 존재할 때, SSD에 저장되어 있었던 해당 associated-likely-zone을 RAM에 미리 올리는 경우임. page cache로 사용할 수 있는 RAM의 여유 공간보다 associated-likely-zone의 크기가 큰 경우에는 RAM의 여유 공간 만큼만 우선적으로 RAM에 올려짐.\n\n* 이때, associated-likely-zone 중에서 우선적으로 RAM에 올려져야 할 영역을 결정하는 방법으로써, “currently-hot”한 현재 data와 지리적으로 가까운 영역의 data를 우선적으로 선택하는 방법, associated-likely-zone의 data들 중에서 access frequency가 높았던 data들을 우선적으로 선택하는 방법 등을 사용할 수 있다. 이에 대한 구체적인 방식은 본 특허와 개별적으로 구현될 수 있으므로, 별도의 특허에서 다루어진다.\n\n* associated-likely-zone은 과거의 access 패턴에 기반하여 서로 비슷한 시간대에 access되었던 data들의 set으로 구성한다. 여기서 ‘서로 비슷한 시간대’라는 개념은 window 2의 window size에 의해 결정된다.\n\n* 특정 address arange가 LZ인지, ULZ인지 구분하는 방법?\nLZ (Likely Zone)와 ULZ (Unlikely Zone)을 선정하는 방법:\naccess되는 page를 보면, 해당되는 inode정보와 이를 access한 process 정보를 알 수 있다. inode 정보를 보면, 이 page가 어떤 파일에 연결되어있는지를 알 수 있다. 이렇게 되면 그 파일이 걸쳐있는 address space 정보 (LBA range)를 알 수 있으며, 이는 likely zone의 일부로 마킹될 수 있다. 여기서 해당 파일 전체를 likely zone으로 할 것인지 해당 파일의 일부를 likely zone으로 할 것인지는 별도의 likely zone determinition rule에 의해 결정된다. 그리고 likely zone으로 마킹된 영역을 언제 class-2 t2 page cache media (e.g., SSD)에 loading할 것인지, loading한다면 likely zone 영역의 데이터들을 어떤 순서로 읽어들일지는 likely-zond loading rule에 의거하여 결정된다. LZ과 ULZ를 선정하는 빈도/시기는\n\n== PATENT-BRIAN-2013-00X ==\n\n* 하나 이상의 SSD를 Page Cache Media로 사용하는 경우, (1) SSD array manager와 연계하여 보다 효율적인 caching I/O를 달성하는 방법 (RACS 기반의 기존 SAVL을 그대로 이용하되 interfacing에 관련된 내용), 혹은 (2) 복수개의 SSD를 caching I/O에 맞도록 coordination하는 방법 (RACS 기반의 기존 SAVL에 추가적으로 caching I/O를 잘 handling할 수 있도록 하는 최적화된 I/O management 방법)\n\n\n* 복수 개의 SSD를 tier-2 page cache media로 사용하는 경우, SSD 1에 free space가 부족한데, 그 SSD 내에 cache되어 있는 page chunk들이 계속 caching해둘만한 가치가 있는 경우, page chunk migration (between SSDs)을 수행한다. 이때, tier-1 page cache 내의 page node 내의 page data location field 값은 update한다. (이때, 누가 migration을 initiation하는 것이 적절할까? host의 hybrid page cache manager? 혹은 activie SSD? 아무래도 SATA 기반의 SSD를 사용하는 경우에는 전자가 좀 더 현실적일 것으로 보임)\n\n\n* tier-2 page cache의 eviction threshold period를 두어서 RAM page cache 경우보다는 길겠지만 tier-2 page cache의 총량이 허용할 수 있는 page 용량을 감안하여 계산된 time period 동안 access 실적이 없으면 tier-2 page cache 중에서도 evictable flag를 set하게 되는데, 이때 복수개의 SSD를 tier-2 page cache media로 사용하는 경우, 전체 SSD 가용 용량을 합산해야 한다.\n\n== PATENT-BRIAN-2013-00X ==\nMultiple I/O Queue Handling for SSD Cache\n\n\n[청구항]\n\n== PATENT-BRIAN-2013-00X ==\npage chunk I/O handling mechanism for multi-tenancy SSD page cache\n\n\n[요약]\n물리적인 SSD 하나가 통째로 page cache로 사용되는 경우에는 SSD 전체를 위와 같이 나누어 사용하면 되겠으나, 하나의 SSD를 page cache media와 다른 용도로 같이 사용해야 하는 경우를 위한 구조 및 방법은 별도의 특허에서 기술하는 것으로 함. page cache media로 사용되는 공간과 다른 목적으로 사용될 공간을 별도의 partition으로 잡고, page cache media로 동작하기 위한 partition을 다시 meta 정보 영역과 page data 영역으로 slice하여 사용함. 이때, SSD는 page cache media로 partitioning된 영역에 해당하는 I/O에 대해서는 병렬성과 page chunk lookup table의 단순성을 극대화 할 수 있게 설계된 page chunk I/O 방식으로 처리할 수 있도록 하는 것이 필요함.\n\n[청구항]\n\n\n== PATENT-BRIAN-2013-00X ==\n\n=== # I/O Pattern-optimal Data Placement for Tiering ===\n\n* Automatic tiering 시, 단순히 hot data들을 fast media에 가져다 놓고 마는 것이 아니라, IO bottleneck이 미연에 방지될 수 있도록 data의 access pattern을 aware해서 차별적으로 배치하는 방법\n예) (a) random-read-intensive 한 data들, (b) sequential-write-intensive한 data들을 다른 방식으로 배치 (tiering)\n\n\n* 이에 필요한 data access pattern 모니터링/분석 방법\n데이터 수집 및 분석 시 PCIe 카드 엔진 활용 가능?\nNIC 이나 DMA를 통해서 data move가 일어나는 경우, PCIe 카드 등을 통해서 IO stream 분석\n\n\n* 이를 위해 필요한 system architecture 구조\n기본적으로 하나 이상의 SSD와 하나 이상의 HDD, 그리고 PCIe 카드, DRAM 일부 사용 방식, Tiering Mapping Table 구조, ...\n\n\n=== # 발명의 이용분야 ===\n=== # 배경 / 기존 기술의 문제점 ===\n=== # 본 발명의 특징 / 효과 ===\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n=== # Memo / Questions ===\n\n\n<br/>\n\n\n\n== Patent pool ==\n\n----\n=== (SmartSSD API) SSD-internal I/O pattern logging interface and mechanism ===\n\n\n==== Questions ====\n\n* SmartSSD에서 제공할 수 있는 logging 서비스로서 어떤 것들이 있을 수 있나?\n:- 어느? 정도의 free space를 필요로하는 critical (heavy) I/O가 어떤? 주기로 도래할 지 알 수 있을까?\n:- I/O prediction에 도움될 수 있는 정보를 SmartSSD가 기록했다가 필요한 때 (안전한 방법으로?) 줄 수 있을까?\n:- I/O prediction까지는 아니더라도 해당 SSD의 I/O wellness(어떻게 정의?)를 측정했다가 bottleneck을 회피하는 데 유용한 정보를 제공할 수 있을까?\n:- 어떤 SSD가 현재 주어지고 있는 I/O workload에 대해 list performance spec을 만족하는데 어려움을 겪고 있다는 것을 알려줄 수 있는 정보가 어떤 것이 있을까? (SSD 내 write buffer의 fullness 혹은 I/O queue의 유동성? amount of free space in over-provisioning area?) (-> I/O wellness 라는 metric을 이것과 연관시켜 정의할 수도 있으며, 결국 SLA 혹은 Performance QoS와 연관시킬 수 있음)\n:- 지금까지의 S.M.A.R.T.와 비교하였을 때, 어떤 차별점이 있는가? 기존의 S.M.A.R.T.가 제공하지 못하던 타입의 정보를 제공하고, 이로 인해 기존에는 불가능했던 새로운 알고리즘 구현 혹은 새로운 서비스 제공이 가능해짐을 보이면 좋겠음.\n\n\n\n:- workload의 history?\n:- 각 erase block이 erase되어야만 했던 주기?\n:- free space의 추이 (얼마나 많이 남아 돌던지)?\n:- I/O의 heaviness 패턴?\n:- SSD내 write buffer (혹은 write cache)의 utilization정보? (즉, write buffer가 넘칠 정도가 되어서 I/O wait을 해야만 했던 상황이 얼마나 자주 발생했는지, write buffer의 가득찬 정도를 백분율로 표현한다고 했을 때, 평균/표준편차 등으로 대표할 수 있는 normal distribution을 따르는지?\n:- 전체 sequential read/write \n\n\n==== 배경 ====\n\n* 각 SSD 모델별로, 또 동일한 모델의 SSD라 하더라도 어떤 workload에 노출되어왔는지에 따라, 현재 낼 수 있는 I/O performance가 동일하지 않을 수 있다 (!check! 관련 실험 결과 - SSD 830을 이용하여 같은 시간 동안 하나의 host에서 생성되는 workload들을 나누어 받았다 하더라도 내부적인 free block의 갯수 및 random write에 의한 block 내 파편화등의 상태가 상이하여 성능에 차이가 나는 것을 보여줄 것. uFLIP 혹은 filebench 활용 가능). 한 예로, SSD가 어느 호스트의 어느 file system에 매핑되었는지에 따라 그 SSD가 받는 workload의 특성이 다를 수 있다. file system mount point가 달라지거나, 기존과 다른 새로운 응용이 설치/서비스되는 상황이 되면 \n\n\n----\n=== I/O Prediction-based Proactive Data Placement ===\n\n* I/O prediction을 기반으로 \"proactive\" 하게 data를 배치시킨다는 것 자체!\n\n* I/O prediction에 의거하여 \'어떤\' data에 대한 tiering이 \'언제\' 일어나야 할 지를 결정 (elastic tiering period 특징을 가짐 - 기존 방식은 static tiering period)\n\n* I/O를 triggering하는 indicator (전조) 정보가 감지되면 해당되는 data block을 미리 필요한 장소에 proactive하게 placement시키는 방식임 (이러한 측면에서 I/O prediction하는 방식이 기존의 accumulated access frequency 기반의 naive prediction과 차별화됨)\n\n* Run-time에 저비용으로 감지될 수 있는 Indicator 정보와, 이에 의해 access될 data 간의 mapping은 Bayesian Inference 이용\n\n\n----\n* 경쟁 기술과의 차별화\n: EMC의 FAST 기술이 안고 있는 근본적인 한계점은 무엇일까?\n: data access 패턴의 hot/cold 만 분류해서 hot은 fast tier에, cold는 slow tier에 두는 것이 전부인가? 아니면 그것 외에 뭔가가 더 있는가?\n: 어떻게 보면 기존의 automated storage tiering은 naive proactive placement로 볼 수도 있다. (과거에 자주 access되었던 data가 앞으로도 자주 access될 것이라고 믿고 data를 이동시키는 것이므로. 그러나 근거가 부족함)\n:: 이러한 naive proactive placement 방식으로 야기되는 단점이 있다. 만약 과거에는 자주 access되었는데 마침 tiering되고 난 후에 자주 access되지 않게 되면, 괜히 SSD의 wear-out만 유발시킨 결과가 된다. 다음 tiering 주기가 돌아오기 전 까지는 계속 느린 media에서 I/O가 serve되기 때문에 그만큼 pain이 된다.\n:: 물론 read에 대해서는 cache를 적극 활용함으로써 첫 access 시에만 slow media access로 인한 penalty를 얻고 이후에는 cache가 제공하는 수준의 성능을 얻을 수 있게 된다.\n:: 그러나 write에 대해서는 문제가 다르다. HDD의 경우 sequential write 경우에는 큰 문제가 되지 않는다. 그러나 random write 특성을 가지고 있으며, 게다가 write-intensive한 I/O라면? 그런데 random write이면서 write-intensive한 경우, write되는 address range가 생각보다 넓지 않다면 어떻게 될까? 즉 특정 구간 특정 데이터에 대한 update가 빈번한 것을 의미한다.\n:: write address range가 N개의 4KB 블럭으로 이루어져 있고, Storage System 내에 물리적인 Disk 갯수가 M개 존재한다고 가정하자. 만약 M이 N보다 적절하게 커서 RAID 10을 하건, RAID 5 등으로 이루어져 있건 간데, N개의 4KB 블럭을 각각 별도의 HDD로 분산 시킴으로써 random write을 random write이 아닌 것처럼 보이게 할 수 있다면? 예를 들어 VNX 5300 처럼 SAN 박스 하나 내에 HDD가 125개가 들어있고, random하고 intensive한 write pattern이 오고 있고, write access range가 125개 이하의 address 내에서 반복되고 있다면, 매번 도달하는 random write request를 마치 RAID 0로 striping 하듯이 계속 다른 HDD로 보냄으로써 I/O de-randomization을 할 수 있을 것이다. 여기서 좀 더 나아가서 하나의 request에 대해서 HDD가 완벽하게 처리하는 데에 걸리는 시간이 10ms 이고, 매 random I/O가 도달하는 평균 시간은 (평균 가지고 되려나? 아무튼 이것은 조금 뒤에 다시 생각해보자) 1ms 라고 한다면, 이론적으로 10번의 random I/O가 지난 다음, 11번째의 random I/O가 올 때에는 처음에 write했던 HDD에다가 다시 write을 해도 된다. 즉, 그 HDD에서 직전의 I/O가 끝나기를 기다리고 있지 않아도 된다는 것이다. 그러나 이러한 방식은 나중에 scatter했던 I/O들을 다시 불러모으려고 할 때 contribution한 HDD가 다른 I/O를 serving하고 있지 않을 수 있어야 최고의 성능을 낼 수 있게 된다. 즉, HDD cluster 구성을 상당히 dynamic하게 가져갈 수 있다면 어떨까? 이러한 dynamic clustering이 정말 최고의 효과를 낼 수 있는 workload case로는 어떤 것이 있을까? data placement를 함에 있어서 결국은 어딘가에 써야 할 것이고, (slow tier로 마크된 HDD들 array에다가 data를 쓴다고 그냥 푸대접하면서 써버릴 것이 아니다) slow tier에다가 쓸 때에도 나중에 어떻게 read되고 다시 write 될 지를 고려한다면, workload 특성에 따라서 concurrent I/O의 갯수 및 address range 크기가 다를 수 있는데, 그것을 aware해서 write을 해둔다면, 비록 slow-tier에다가 write했지만, 그리 slow하지만은 않은 성능을 내게 할 수 도 있을 것이다. 이것은 proactive data placement에 대한 이야기가 아니다. proactive와는 별개로, automated storage tiering을 함에 있어서 workload characteristics를 고려한 data placement에 대한 이야기이다.\n\n\n\n\n서로 독립적인 I/O stream의 갯수가 100개 라면 (즉 100개의 process가 I/O를 쏟아내고 있는 경우), 그리고 I/O queue의 크기가 N_Q라면, 어떻게 이러한 문제를 해결할 수 있을까?  \n\n  \n:: write에 대해서는 \n:: write-intensive하다는 것의 정의는? 이러한 경우에는 in-memory write caching (OS가 허용하는 범위의 delayed write을 최대한 활용)을 이용하되 transaction 기반으 atomicity를 보장함으로써 문제를 부분적으로 해결할 수 있다. transaction으로 묶여질 수 있는 여러 번의 I/O request (write)가 끝나기 전까지는 commit되지 않은 것으로 치는 것임. Fusion IO의 atomic write은 이를 어떻게 해결하는지? \n\n만약 write commit이 매우 중요한 민감한 데이터에 대해서는 어떻게 해야할까? 그리고 SSD-internal memory buffer를 이용해서\n: SAN 장비 내에서의 HDD와 SSD 간의 tiering만 되는 것일까? (vertical tiering within local node)\n: SAN 장비 간의 tiering이 되기 위해서는 어떤 것이 더 필요할까? EMC에서 이미 그러한 기술/솔루션을 가지고 있지는 않을까? (horizontal tiering between boxes)\n\n* 다양한 사례\n: 기존에 이미 생성되어 있던 data를 미래 access 예측에 따라 위치 변동을 시키는 경우\n: Tiering을 한다고 했을 때, access 빈도에 따라서 fast tier / slow tier 간 이동시키는 것이 전부일까? 그런 것 말고 다른 차원의 tiering은 없을까?\n: 새롭게 write되려는 data를 처음부터 어디에 배치시키는 것이 좋을까?\n\n* Placement 접근 방식\n: Tiering으로 한정?\n: Tiering과 Caching과의 결합 방식? (Caching engine에게 hint를 주는 방식)\n\n* I/O Prediction 결과를 받아서 proactive하게 data를 tiering 시키는 방법 및 아키텍쳐\n* Key questions\n:- 기존엔 proactive tiering이 없었나?\n:- 만약 없었다면 어떤 어떤 부분들을 청구항으로 넣어야 할까?\n:- 만약 있었다면 어떤 차별화가 필요할까?\n\n\n----\n=== Tiering Method Avoiding I/O Bottleneck ===\n\n* I/O Prediction에 의해 예측된 미래의 Hot Data를 Proactive하게 Placement한다고 할 때, 예상되는 access pattern으로 인해 발생 가능한 I/O Bottleneck을 최소화할 수 있도록 배치하는 방법\n\n* 예를 들어 미래의 hot data block 1 (200MB), hot data block 2 (100MB), hot data block 3 (400MB)이 1분 후에 access 될 것으로 예측되었다고 가정. data block 1에 대해서는 4KB 단위로 random read가 dominant한 access pattern이 예상되고, data block 2에 대해서는 1024KB 단위의 sequential read가 dominant한 access pattern이 예상되고, data block 3에 대해서는 4KB 단위의 random read와 512KB 단위의 sequential write이 각각 80:20의 비율로 mix된 형태의 access pattern이 예상된다고 했을 때, 각 data block을 어디에 어떤 형태로 placement시킬 것인가?\n\n: machine learning 혹은 pattern mining에 기반한 base workload pattern data를 기반으로 incremental하게 update될 수 있는 data access의 spatial locality와 periodicity\n: Local node 내에서의 vertical tiering 뿐만 아니라 분산 node들 간의 horizontal tiering도 염두에 둘 것\n\n\n* 기존 기술과의 대비 (naive I/O prediction vs. full-fledged I/O prediction)\n: 기존 기술은 누적 hit count 정보에 의지하는 naive I/O prediction으로 볼 수 있음. 이러한 방식은 workload의 변화를 제대로 반영하지 못하기 때문에, static한 workload에 대해서는 잘 동작하지만, moving target처럼 dynamic한 workload에 대해서는 오히려 과거의 누적 hit count metric이 현재의 workload 패턴을 왜곡하는 문제점을 가지고 있음. (temporal locality와 spatial locality가 깨지는 순간이 여러번 존재할 수록 기존의 naive I/O prediction 방식으로 성능 향상은 어려워짐)\n\n\n\n\n=== I/O Workload Analyzer Engine ===\n* I/O Trace 및 다양한 시스템 정보를 기반으로 I/O를 prediction하는 방법 및 구조\n\n== Disclosure of Invention :: Template ==\n\n<!--\n== PATENT-BRIAN-2013-00X ==\n-->\n\n=== # RAM-SSD Hybrid Page Cache Architecture ===\n=== # 발명의 이용분야 ===\n=== # 배경 / 기존 기술의 문제점 ===\n=== # 본 발명의 특징 / 효과 ===\n=== # 대표 청구항 ===\n=== # 대표 도면 ===\n=== # 도면 목록 ===\n=== # 기술 상세 ===\n=== # 침해 적발 ===\n=== # 선행 기술 ===\n=== # Memo / Questions ===','utf-8');
/*!40000 ALTER TABLE `mw_text` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `mw_trackbacks`
--
