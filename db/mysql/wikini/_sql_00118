INSERT INTO `mw_text` VALUES (1920,'== ## bNote-2013-04-26 ==\n\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 msec // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 msec // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5\n:- Seek Average, Write (ms): <9.5\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1921,'== ## bNote-2013-04-26 ==\n\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 msec // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 msec // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1922,'== ## bNote-2013-04-26 ==\n\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~100 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~100 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1923,'== ## bNote-2013-04-26 ==\n\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1924,'== ## bNote-2013-04-26 ==\n\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\n \n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n \n\n \n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI SDN]\n\n\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1925,'== ## bNote-2013-04-26 ==\n\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI SDN]\n\n\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1926,'== ## bNote-2013-04-26 ==\n\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1927,'== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1928,'== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1929,'== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n\n\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8'),(1930,'== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 msec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 msec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8');
INSERT INTO `mw_text` VALUES (1931,'== ## bNote-2013-04-29 ==\n\n=== 경쟁사분석 ===\n\n* [http://www.computerweekly.com/news/2240182642/Fusion-io-buys-NexGen-to-join-hybrid-flash-array-fray Fusion IO Buys NexGen to Join Hybrid Flash Array // 2013-04-24]\n\n* [http://www.storagereview.com/fusionio_announces_nexgen_storage_acquisition Fusion-io Announces NexGen Storage Acquisition // 2013-04-24]\n\n* [http://www.theregister.co.uk/2013/04/24/fusion_io_nexgen/ Fusion-io buys NexGen - Gets hybrid flash/disk array startup // 2013-04-24]\n\n* [http://venturebeat.com/2013/04/24/fusion-io-acquires-hybrid-storage-appliance-vendor-nexgen-storage-for-114m/ Fusion-io acquires hybrid storage appliance vendor NexGen Storage for $114M // 2013-04-24]\n\n== ## bNote-2013-04-26 ==\n\n=== Consistent Hashing ===\n\n* [http://www.tom-e-white.com/2007/11/consistent-hashing.html Consistent Hashing Illustrated ((B.GOOD))]\n\n* [http://amix.dk/blog/post/19367 Consistent Hashing Simply in Python]\n\n=== SDN ===\n\n==== SDN의 정의 및 발생 배경 ====\n\n* [http://katesfam.blogspot.kr/2012/01/sdn.html SDN은 무엇인가? 그리고 왜 대두되었는가?]\n \n <pre>\n\nSDN에 대해 잘 정리한 글이 있어서 보내드립니다.\n\nhttp://katesfam.blogspot.kr/2012/01/sdn.html\n\n \n\n\n\n----\n\n \n\nSDN은 무엇인가? 그리고 왜 대두되었는가?\n\n \n\n \n\n1. SDN은 무엇인가?\n\n\n수년 동안 컴퓨터 과학자들은 네트워크의 속도와 안정성, 에너지 효율, 보안 등을 획기적으로 개선시킬 수 있는 방법을 꿈꿔왔다. 그러나 그 방법을 설계하거나 고안하더라도, 실제로 대규모(large-scale)로 실험하거나 검증하는 것은 불가능했다. 인터넷의 코어(core)를 구성하는 라우터나 스위치들이 이른바 완전히 닫혀 있어서 그 위에서 새로운 소프트웨어나 프로그램을 실험하는 것이 원천적으로 봉쇄되었기 때문이다.\n\n \n\n이러한 연유로 연구되어온 많은 기술 중 SDN은 Software Defined Networking을 의미하며 우리말로 소프트웨어 정의 네트워킹이라 부른다. SDN은 OpenFlow라는 기술 혹은 소프트웨어를 통하여 널리 알려졌다. OpenFlow와 SDN은 뗄레야 뗄 수 없는 관계이다. SDN이 물론 더 큰 개념으로 네트워크 구조 혹은 새로운 패러다임이며, OpenFlow는 SDN을 위한 “인터페이스 표준 기술”로 정의된다. SDN을 지원하는 기술 중에서 학교, 연구소, 기업 등으로부터 가장 관심을 받는  OpenFlow는 별도로 설명하기로 하고 (이미 많은 참고자료가 나와 있기도 하다), 여기서는 먼저 SDN이 무엇인지, 그리고 왜 필요성이 부각되었는지에 대하여 몇 가지 레퍼런스를 바탕으로 다루어 보려 한다.\n\n \n\n먼저 위키피디어의 정의를 살펴보자. Kate Greene이 2009년도3/4월 판 MIT 테크니컬 리뷰에서 소개한 용어로 알려져 있는 SDN은 네트워크 제어 기능(control plane)이 물리적 네트워크와 분리되어 있는 “네트워크 구조”를 말한다. 위키피디어에 따르면  SDN을 특징짓는 두 가지 중요한 포인트는 다음과 같다. 첫째, 네트워크 제어 기능을 데이터 전달 기능(data plane)과 분리하여 구현해야 한다. 둘째, 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리하여 전형적인 낮은 성능의 CPU가 장착된 하드웨어 스위치에 더 이상 위치시키지 않는다. 다시 말해서 SDN이라면 기본적으로 네트워크 제어 기능이 기존의 스위치나 라우터 등의 하드웨어와 별도로 분리되어야 하고, 데이터 전달 기능과도 역시 분리되어 개발 및 실행될 수 있는 네트워크 구조를 가져야 한다.\n\n \n\n분리된 SDN의 제어 기능은 필연적으로 네트워크 스위치(하드웨어) 상의 데이터 경로와 상호작용할 수 있는 기능을 가져야만 한다. 이러한 상호작용 혹은 통신 메커니즘 중의 하나가 바로 OpenFlow 기술이다. OpenFlow는 흔히 SDN과 동일한 것으로 혼동되기도 하지만, 사실 SDN을 구성하는 하나의 요소로 제어 기능을 가진 머쉰과 네트워킹 스위치간의 통신을 담당하는 표준 인터페이스이다. 그리고, SDN의 범주 안에서 OpenFlow를 반드시 사용해야 한다는 아무런 제약이나 요구사항도 없다. 현재 SDN과 OpenFlow의 정의, 마켓팅 등의 이슈는 개방형 네트워킹 재단(Open Networking Foundation; ONF)에서 관리되고 있다. \n\n \n\n그렇다면 ONF에서는 SDN을 어떻게 바라보고 있을까? 일단 ONF가 무엇인지부터 살펴보자. ONF는 (미연방세법을 따르며) 비영리, 상호 이익을 바탕으로 하는 국제 기구로 SDN의 개발과 활용을 촉진하는 것을 목표로 삼고 있다. ONF의 이사회는 여덟 명의 멤버로 구성되는데 여섯 개의 설립 회사가 각각 한 명씩 지정한 여섯 명의 이사와 두 명의 창립자이다. 여섯 개의 설립 회사는 대규모 네트워크 운영자 및 (잠재) 사용자 그룹을 대표하는 도이치 텔레콤(Deutsche Telecom), 페이스북(Facebook), 구글(Google), 마이크로소프트(Microsoft), 버라이즌(Verizon)과 야후(Yahoo)이며, 두 명의 창립자는 UC 버클리의 Scott Shenker와 스탠포드 대학의 Nick Mckeown이다. 그리고 이외에 사무총장(Executive Director) Dan Pitt이 ONF를 총괄 관리한다.\n\n \n\nONF가 SDN을 바라보는 관점은 크게 두 가지의 기본적인 원칙을 바탕으로 하고 있다.\n\n \n\n먼저 SDN은 소프트웨어 정의 포워딩(Software Defined Forwarding)을 해야 한다. 이것은 스위치와 같은 하드웨어가 수행하는 데이터 포워딩 기능이 반드시 개방형 인터페이스와 소프트웨어를 통해서 제어되어야만 한다는 것을 의미한다. 하드웨어는 소프트웨어로부터 [헤더 템플릿, 포워딩 액션] 셋을 받아 특정한 액션(action)을 실행한다. 예를 들면 어떤 네트워크 포트로 패킷을 “전달(forwarding)”하거나 혹은 “폐기(drop)”할 수 있다. 다만 해당 특정 액션은 [헤더 템플릿, 포워딩 액션]의 “헤더 템플릿”에 상응하는 패킷에 대해서만 실행된다. 여기서 헤더 템플릿은 “모든 패킷” 혹은 “어떤 패킷의 그룹”등을 의미하는 와일드 카드를 포함할 수 도 있다. 앞서 언급되었듯이 SDN의 소프트웨어 정의 포워딩은 반드시 개방형 인터페이스와 소프트웨어를 포함하는데, OpenFlow 기술이 “개방형 인터페이스”에 해당된다.\n\n \n\n그리고, 두 번째 원칙은 SDN이 추상화된 글로벌 관리 혹은 글로벌 관리 추상화(Global Management Abstraction)를 목표로 한다는 것이다. SDN은 기본적인 글로벌 관리 추상화를 지원함으로서 보다 선도적인 네트워크 관리 툴이 개발될 수 있도록 해야 한다. 예를 들면 이런 추상화 도구들은 네트워크의 글로벌 뷰, 네트워크 이벤트(토폴로지 변화나 새로운 플로우 생성 등)에 따른 반응, 그리고 네트워크 요소를 제어할 수 있는 기능 등을 포함할 수 있다. (네트워크 요소 제어는 해당 엔트리를 하드웨어의 포워딩 테이블에 넣는 방법을 사용한다.)\n\n \n\n따라서, ONF 가 바라보는 SDN은 두 가지, 즉,  소프트웨어 정의 포워딩과 글로벌 관리 추상화가 핵심이다. 그리고, 이를 위해서 개방형 인터페이스(예: OpenFlow), 제어 소프트웨어, 글로벌 네트워크 관리 툴 등의 세부적인 기능이 언급되었다.\n\n \n\n여기서 잠시 위키피디어로 돌아가보자. 위키피디어에서 언급한 Kate Greene (과학기술 저널리스트)이 작성한 테크니컬 리뷰의 내용을 보면 SDN이 무엇인지 개괄적으로 잘 정리되어 있다. 이 기사에 따르면 ONF의 창립자 중 하나이자 이사회 멤버이며, OpenFlow 기술과 표준을 개발한 Nick McKeown이 다음과 같이 말한다. “오늘날 보안, 라우팅, 에너지 효율 관리 등은 단지 기계덩어리인 네트워크 장비에 의해 좌지우지됩니다. 그건 정말 바꾸기 힘들지요. 이것이 바로 인터넷 인프라가 40년 동안이나 변하지 않은 이유입니다.” 일반적으로 데이터 패킷이 스위치 (혹은 라우터)에 도착하면 스위치의 펌웨어가 해당 패킷의 목적지 주소를 보고 그 패킷을 이미 정해진 규칙에 따라 포워딩(forwarding)한다. 정해진 규칙은 네트워크 운영자도 제어하기 어렵다. 같은 목적지를 갖는 모든 패킷은 같은 경로를 이용하고 언제나 같은 방식으로 다루어진다. 이것이 현대 인터넷의 일반적인 패킷 포워딩 방식이다.\n\nSDN은 무엇인가? 라는 질문의 답은 바로 현재 인터넷이 가지고 있는 “항상 같은 방식이며 제어가 어려운” 패킷 포워딩 방식을 바꾸는 것으로 부터 시작한다. OpenFlow의 예를 들면, 그 전에는 거의 아무도 손대기 어려웠던 종단간 네트워크 경로를 컴퓨터 과학자들이 쉽게 변경할 수 있도록 지원하여 e-mail보다 비디오 어플리케이션이 우선 데이터를 받을 수 있도록 하거나 다양한 트래픽을 각자 다른 경로로 보낼 수도 있고, 어떤 트래픽은 보안 목적으로 격리할 수 있도록 해준다.\n\n \n\n그렇다면 패킷 포워딩 방식을 바꾸는 것이 바로 SDN인가? 그렇지 않다. 이것은 SDN이라는 큰 구조를 구성하는 하나의 요소일 뿐이다. OpenFlow가 바로 패킷 포워딩 방식을 표준화된 방법으로 바꿀 수 있는 하나의 콤포넌트이다. SDN은 아키텍쳐 혹은 프레임을 제공하는 큰 개념이자 구조 혹은 패러다임으로, 하드웨어와 어플리케이션, 하드웨어 추상화 계층, 하드웨어와 분리된 제어 기능(control plane, controller 등으로 불리운다.), 하드웨어 추상화 계층과 통신하는 표준 기능 등을 모두 포함한다.\n\n \n\nSDN 구조에서, 하드웨어는 스위치나 라우터 등이며, 시스코, 쥬니퍼, HP, NEC 등이 개발하고 현재 인터넷 공급자들이 서비스를 제공하기 위하여 설치하고 운영하는 하드웨어 박스(box)를 의미한다. Nick이 말했듯이 오늘날의 인터넷이 거의 변화하지 못한 가장 큰 원인을 제공하는 주범들이다. SDN은 이 기계덩어리에 하드웨어 추상화를 위한 계층을 더해준다. 즉, OpenFlow와 같이 표준화된 인터페이스를 통하여 하드웨어에 접근하고, 소프트웨어에 기반하여 하드웨어를 “통제”할 수 있는 기반을 제공하는 것이다. 이 추상화 계층은 OpenFlow의 플로우 테이블과 같은 형태로 하드웨어에 구현되어야 한다. 따라서 하드웨어 벤더들의 지원과 협력이 필수적이다. (현재 약 16개의 주요 네트워크 벤더들이 구현했거나 구현중이다. SDN을 지향하는 OpenFlow가 가장 선두에서 탄력받는 기술로 주목받고 있는 배경이기도 하다.) 추상화 계층을 구현함에 있어서 가장 중요한 것은 표준화된 인터페이스를 지원하는 것이고, 두 번째는 각 개별 벤더가 원하는 “독립성”을 보장해 주는 것이다. 개별 벤더의 고유 기술이나 고유 기능은 자치적으로 보장되면서 SDN을 위한 표준화된 통로를 제공하는 것은 벤더 고유의 기술을 보호하면서도 호환성을 유지하는데 있어서 필수적이며, OpenFlow의 경우 이를 매우 잘 준수하고 있다.\n\n \n\n다음으로 무엇보다 중요한 요소는 바로 하드웨어와 분리된 제어 기능이다. Controller로 불리기도 하는 이 제어 기능은 스위치나 라우터가 아닌 별도의 머쉰 상에서 구현된다. 머쉰은 PC가 될 수도 있고 성능 좋은 서버가 될 수도 있다. 이 제어 기능은 두 가지 SDN의 다른 두 가지 콤포넌트와 상호작용한다. 한 가지가 어플리케이션이고 다른 한 가지는 하드웨어, 좀 더 정확히는 하드웨어에 구현된 추상화 계층이다. 따라서 제어 기능을 통해서 어플리케이션은 네트워크의 다양한 정보를 얻을 수 있고, 반대로 네트워크 역시 어플리케이션 요구 사항 등의 정보를 얻을 수 있다. 이러한 핵심적인 역할 때문에, 제어 기능은 종종 네트워크 운영 체제(Network OS)라고 불리우기도 한다.\n\n \n\n제어 기능은 주로 API와 같은 방법을 통해서 어플리케이션이 원하는 기능을 제공한다. 반대의 경우도 거의 같다. 어플리케이션과 제어 기능 간의 통로인 셈이다. 그렇다면 제어 기능과 하드웨어 추상화 계층의 통신은 어떻게 이루어질까? OpenFlow가 이 질문에 대한 해답이며, 이미 많은 연구가 진행되어 있다.\n\n \n\n \n\n2. SDN이 대두된 이유\n\n \n\n지금까지 위키피디어, ONF, 테크니컬 리뷰 등을 인용하고 몇 가지 살을 붙여 SDN이 무엇인지 정리해 보았다. SDN은 새로운 네트워크 구조이며 패러다임이다. 그럼 이제부터 SDN이 왜 대두되었는지 알아보기로 하자.\n\n \n\n가장 최근에 ONF가 개최한 컨퍼런스인 Open Networking Summit(2011년 10월)에서 ONF의 또 다른 창립자인 Scott Shenker가 발표한 내용을 보면, 인터넷이 이렇게 크게 성공한 가장 큰 이유가 바로 “계층화(layering)”에 있다는 것을 알 수 있다. 어플리케이션(WWW, e-mail 등)은 신뢰성/비신뢰성 트랜스포트 계층(TCP/UDP)위에서 돌아가고, 트랜스포트 계층은 최선형 글로벌 패킷 전달 계층(IP)위에서 동작되며, IP는 최선형 로컬 패킷 전달 계층(Ethernet, PPP 등)위에서, 다시 로컬 패킷 전달 계층은 물리 계층(copper, fiber, radio등) 위에서 돌아가는 것이 바로 계층화이다. 즉, 서로 다른 계층이 독립적으로 동작하되 상/하위 계층과 상호 호환되는 방식으로 일종의 혁신을 이룬 것이다. 덕분에 인터넷은 교육/연구망으로 시작되었으나, 상업적으로도 엄청난 성공을 거두었고 지금까지 가장 널리 사용되고 있다. 그러나, 초창기 개발된 인터넷 구조나 모델이 아직도 거의 그대로 사용되고 있는 형편으로, 상업적인 성공이 또 다른 인터넷의 혁신으로 이어지지 못했다. 왜 그럴까?\n\n \n\n이 질문에 답하기 전에 먼저 다른 분야를 한 번 살펴보자. 예를 들어 컴퓨터 운영체제(OS), 데이터베이스(DB), 분산 시스템 등은 소프트웨어의 연구 개발을 통해 발전해 왔다. 학교에서 배우는 기본적 원리들을 바탕으로 소프트웨어를 개발하고 진화시킨 것이다. 이러한 소프트웨어는 우리가 흔히 알고 있는 고급 프로그래밍 언어로 작성할 수 있으며, 새로운 기능이 필요한 경우 기존에 개발된 소프트웨어를 바탕으로 새로운 버젼으로 계속해서 발전할 수 있다. LINUX, Windows, Mac OS 등이 이런 방식으로 진화해온 대표적인 OS 이다. 데이터베이스나 분산 시스템도 마찬가지이다. 그리고 이러한 소프트웨어 기반의 시스템들은 대부분 편리하고 쉬운 유저 인터페이스를 통해 쉽게 관리 가능한 환경을 가지고 있다.\n\n \n\n그렇다면 네트워크는 어떤가? 일단 학교에서 OSI 7 계층 부터 시작하여 TCP, IP 등등의 여러 프로토콜에 대해서 배운다. 이들의 기본적 원리나 알고리즘에 대해서도 배우지만 대부분 동작 원리 등 실용적인 부분에 집중된다. 물론 이른바 단말 시스템(end-system)에서 돌아가는 TCP 등의 일부 프로토콜은 기능이 향상된 버젼이 개발되었거나 개발이 진행 중이다. 하지만, 단말과 단말 사이에서 데이터 전송과 전달을 담당하는 액세스/코어 네트워크의 프로토콜이나 기타 기능들은 이미 대부분 개발이 끝나서 적용 및 서비스 되고 있는 단계이기 때문에 새롭게 수정하거나 개발하기 어렵다. 물론 네트워크 벤더의 경우 추가적인 기술 개발과 적용이 가능하지만 DB나 운영체제 등과 비교할 때 많은 진보가 일어나지는 않았다. 네트워크 분야의 경우, 소프트웨어와 프로그래밍을 바탕으로 한 새로운 기술의 개발과 진화가 다른 컴퓨터 과학 분야와 비교할 때 그 발전이 더디게 진행되어 온 것은 분명한 사실이다. 네트워크 관리 환경은 어떠한가? 일부 운영자나 엔지니어에게 종속되어 있는데다가 그 마저도 사용하기가 쉽지 않다. 전문적인 지식이나 기술을 요구하는 경우도 많다. 최근 몇 몇 연구들이 이러한 관리 환경을 개선하는데 그 촛점을 맞추고 있긴 하지만 다른 분야에 비해서 부족한 상태로, 매우 불편한 사용자 인터페이스를 가지고 있다.\n\n \n\n“구조는 단순하지만 관리가 복잡하고 인터페이스는 어렵다.” 이것이 현재의 인터넷이 가지고 있는 가장 큰 문제로 귀결된다. SDN이 대두된 이유는 바로 이 화두를 타파하기 위해서이다.\n\n \n\n단순한 구조는 물론 장점이다. 덕분에 인터넷이 오늘날의 압도적 지위를 누리게 되었다. 하지만 단순성을 유지하기 위하여 새로운 기술을 적용하거나 소프트웨어를 개발하는 측면에서 다른 분야에 비해 큰 제약을 가져야만 했다. 이와 같은 단점을 보완하기 위하여 SDN은 제어 프레임워크, 혹은 제어 기능을 분리하여 소프트웨어의 개발을 촉진시키고자 한다. 즉, 소프트웨어를 기반으로 인터넷이 보다 빠른 속도로 진화할 수 있도록 하자는 것이다. 그리고, SDN은 관리의 복잡성을 해소하기 위하여 제어 기능을 기존 하드웨어에서 분리시키고, 사용자 인터페이스를 매우 단순하고 편리하게 만듦으로써 엔지니어, 운영자 뿐만 아니라 일반 사용자도 쉽게 네트워크를 관리하고, 가상 네트워크를 생성하여 이용할 수 있도록 한다.\n\n \n\n참고로, 미래인터넷 포럼(FIF)의 테스트베드 워킹그룹 이슈 분석서 #2에서 Nick의 발표 내용을 정리한 부분을 보면, SDN이 어떻게 인터넷이 가지고 있는 문제를 해결하고 혁신을 가속화할 수 있는지에 대하여 잘 알 수 있다.\n\n\nNick은 SDN을 기반으로 한 새로운 패러다임을 만들어 내어서 아래와 같은 혜택들을 누리는 네트워크 장치 생태계를 만드는 것이 필요하다고 역설한다.\n\n\n    1.     데이터 전달(Forwarding) 추상화에 따라서 OpenFlow 표준에 의해 검증된   하드웨어를 이용하고, 또한 이에 연동하여 소프트웨어 기반으로 제공되는 네트워킹 특성이 요구되는 모든 절차들에 대해서 각각의 절차마다 충분하게 증빙되어 있는 견실한 네트워킹을 실현할 수 있는 토대를 구축할 수 있다.\n    2.     장비 사용자들이 자신의 필요에 따라 네트워킹을 유연하게 구성(customize)하고 불필요한 구성요소들은 과감하게 제거하면서 자신만을 위해서 가상화된 네트워크를 생성하기 쉽도록 지원한다.\n    3.     하드웨어 추상화(abstraction)에 따라 확장성을 고려한 상태에서 공통화된(즉 commodity 형식으로) 하드웨어를 구입하고, 또한 소프트웨어도 분리해서 구입하도록 하여 기존의 폐쇄적인 네트워크 장비 공급자 체인을 벗어나서 자체 개발, 외주 개발, 오픈 소스 형식을 모두 포함하는 다변화된 공급자 체인으로 체질 개선을 유도할 수 있다.\n    4.     소프트웨어를 개발하는 속도로 혁신이 일어나도록 하고, 표준은 구현된 소프트웨어의 확산을 위해 뒤따라가는 방식을 취하고, 소프트웨어적인 개방성에 근간하여 기술의 공유 협력을 쉽도록 함으로써 혁신의 속도를 가속하도록 지원한다.\n\n \n\n다른 내용도 모두 중요하지만, 특히 4번에 주목하자. 소프트웨어를 개발하는 속도로 혁신이 일어나게 하고 표준은 이를 뒤따르게 하자는 것이야 말로 SDN이 왜 대두되었는지 설명하는 핵심 중의 핵심이라 할 수 있다.\n\n \n\n내용이 두서없이 길어진 듯 하다. 이제 정리해보자. SDN은 아직도 정의되고 있는 단계이다. 본문에서 언급한 여러 레퍼런스를 보면 분명히 주된 맥락은 있지만 모호하고 추상적인 부분도 있는 것이 사실이다. 따라서 앞으로 SDN의 모습은 계속해서 변화될 가능성이 틀림없이 존재한다. 그렇지만 주된 맥락을 고려할 때 SDN은 현재 시점에서 다음과 같이 정의될 수 있을 것이라 생각한다. \n\n\n\"SDN은 이른바 소프트웨어를 통해서 현재의 인터넷이 가지는 구조적 문제를 근본적으로 해결하고 혁신할 수 있도록 대두된 새로운 네트워크 구조 혹은 패러다임으로써, 어플리케이션, 네트워크 OS, 하드웨어 추상화, 표준화된 인터페이스 및 하드웨어를 모두 아우르는 개념\"이다.\n\n</pre>\n\n==== SDN 관련 소식 ( Open Daylight ) ====\n\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트\']\n\n <pre>\n\n[ Open Daylight 출범으로 본 SDN 물결의 변화 ] \n\n\n* 시스코, 주니퍼 등 벤더 중심의 SDN 연합체인 Open Daylight 출범(\'13년 4월 초)\n\n \n\n\n\n* 리눅스재단이 주도, 시스코, 주니퍼, IBM, MS, 레드햇,\n\n빅스위치, 브로케이드, 시트릭스 등등이 Platinum 스폰서로 참여.\n\n\n\n \n\n* 의미\n\n  : 학계, 구글, AT&T, NTT 등 서비스 업체에 의해 주도 되었던 기존 SDN 움직임과는 달리,\n\n    Open Daylight는 IT의 Big Vendor들이 주도하는 SDN 움직임이라는 차이점이 있음\n\n    (시스코는 오픈네트워크환경(ONE) 컨트롤러를 Open Daylight에 기증하는 등,\n\n     기존의 SDN에 대한 미온적인 입장을 버리고 적극적으로 SDN 물결에 동참)\n\n \n\n\n\n* Open Daylight의 프로젝트 구성\n\n   - Flexible 컨트롤러 프로젝트\n\n   - 가상 네트워크 프로젝트\n\n   - Java 기반 프로토콜 플러그인 프로젝트\n\n   - 프로그램 가능한 인터페이스 프로젝트\n\n   - SDN 응용 프로젝트 ++\n\n\n(++) SDN 응용의 중요성:\n\nSDN 컨트롤러 자체만으로는 의미가 크지 않음.\n\nSDN을 적극적으로 활용하는 응용들이 많아져야 SDN 생태계가 활성화될 수 있음\n\n\n\n \n\n* Open Daylight은 올해(\'13년) 3분기에 정식 코드 공개 예정\n\n\n\n \n\n* Open Daylight의 라이센스는 EPL(Eclipse Public License)로서,\n\n   코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 됨.\n\n\n\n* 관련 기사:\nSDN 국면전환을 꿈꾸다 \'오픈데이라이트\' [ZDnet 4/22]\nhttp://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700\n\n\n\n \n\n \n\n--\n\n\nZDnet KR - All\n SDN 국면전환을 꿈꾸다 \'오픈데이라이트\' \n\n[지디넷코리아] 세계 IT거인들이 집결한 소프트웨어정의네트워킹(SDN) 연합체 ‘오픈데이라이트’가 출범했다. 시스코, IBM, 레드햇, 마이크로소프트(MS), 빅스위치 등 데이터센터 관련업체 대부분이 참여한 범 개방형 네트워크 연합체다. \n\n오픈데이라이트는 이달 7일 공식 출범을 선언하고 오픈소스 기반의 표준 SDN 프레임워크를 개발하겠다고 밝혔다. \n\n리눅스재단이 주도하며, 시스코, IBM, MS, 레드햇, 빅스위치, 브로케이드, 주니퍼네트웍스, 에릭스, 시트릭스 등이 플래티넘 스폰서로 참여했다. 이밖에 VM웨어, NEC 등이 골드 스폰서로, HP, 델, 아리스타, 인텔, 누아지네트웍스(알카텔루슨트), 플럼그리드 등이 실버 스폰서로 등록했다. \n\n오픈데이라이트는 오픈소스 SDN 컨트롤러와 가상 오버레이 네트워크, 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 개발프로젝트를 진행한다. 오는 3분기 정식 코드가 공개될 예정이다. \n\n그동안 SDN 분야는 학계와 구글, AT&T, NTT 등 서비스업체를 중심으로 발전했다. 벤더 종속없는 네트워크 환경을 구축해보자는 움직임에서 출발한 SDN은 오픈플로란 오픈소스 프로토콜을 탄생시키기에 이른다. SDN 바람 속에서 기존 벤더들은 끌려가는 듯한 인상을 줬다. \n\n오픈데이라이트는 그동안 주도권을 쥐지 못했던 벤더들이 뭉쳐 SDN 흐름을 주도하려는 노림수다. 때문에 기존 개방형 네트워크를 주도해온 진영으로부터 의심의 눈초리를 받는 것도 사실이다. \n \n \n■오픈데이라이트 주도 시스코 ‘태도변화 or 전략’ \n\n오픈데이라이트는 공식 출범 이전부터 화제였다. 당초 SDN 분야에 미온적인 이미지를 줬던 시스코가 주도적인 역할을 담당한다는 소문 때문이었다. 네트워크업계 독불장군의 대명사였던 시스코의 참여만으로 관심을 끌기 충분했다. \n\n시스코는 그동안 업계표준 작성을 위한 각종 연합체와 대립하면서, 독자 행보를 고집했었다. 그러던 시스코도 최근 2년 사이 아파치, 오픈스택, 리눅스 등 오픈소스 재단을 적극 지원하는 등 변화된 모습을 보이긴 했다. \n\n데이비드 옌 시스코 데이터센터그룹 수석부사장은 최근 텔레프레즌스를 통한 기자간담회에서 오픈데이라이트의 의의를 “업계리더들이 리눅스 재단 아래서 형성한 오픈소스 프로젝트로, 기업들이 SDN을 채택하고 혁신하도록 하는 걸 목표로 한다”라며 “기업의 SDN 도입을 실현하기 위해 벤더들이 지원 프레임워크를 구축하게 된다”라고 설명했다. \n\n그에 따르면, 오픈데이라이트는 업계 전문업체들이 머리를 맛대고 SDN 환경의 기업 도입을 앞당기기 위한 움직임이다. 그동안 중구난방으로 개발됐던 SDN관련 기술을 통합해 어디서나 활용가능한 개방형 표준을 만든다는 것이다. \n\n오픈소스의 정신과 이점을 살려 자유로운 참여를 보장함으로써, SDN 프레임워크 개발속도와 완성도를 빠르게 높이겠다는 의도도 있다. \n \n▲ 오픈데이라이트 프레임워크 1.0 버전 \n \n공식적으로 오픈데이라이트는 컨트롤러 프로젝트를 중심으로, 가상 네트워크, 자바 기반 프로토콜 플러그인, 애플리케이션, 아키텍처 및 프로그램 가능한 인터페이스 등의 프로젝트로 구성된다. \n\n현재 다운로드 가능한 오픈데이라이트 컨트롤러는 1.0 버전이다. 이를 기반으로 노스바운드API로 오픈스택, 클라우드스택 등과 연동되며, 사우스바운드 API로 오픈플로 네트워크 환경을 제어한다. 시스코가 자사의 오픈네트워크환경(ONE) 컨트롤러를 기증했다. \n\n데이비드 옌 부사장은 “현재 사우스바운드 API모듈을 통해 오픈플로 1.0 아키텍처에 추가함으로써 사용할 수 있다”라며 “자바 번들에 들어가는 HA 모듈을 시스코에서 기증했고, 다른 벤더와 고객사들이 여러 애플리케이션 모듈을 자유롭게 개발해 사용하고, 프로젝트에 기여하게 된다”라고 강조했다. \n\n오픈플로 컨트롤러 ‘플러드라이트’를 보유한 빅스위치도 컨트롤러 고도화에 기여한다. 시스코에서 기증한 컨트롤러 코드를 기초로 하지만, 자유롭게 코드를 수정할 수 있기 때문이다. 여기에 IBM, MS, 레드햇, HP, 델, 브로케이드, 주니퍼, 아리스타, 인텔 같은 회사의 소속 개발자가 다양한 애플리케이션과 운영사례를 개발해 기여한다. \n\n오픈데이라이트의 라이선스는 자바영역에서 주로 활용되는 EPL(Eclipse Public License)이다. 코드를 수정해 사용하거나 별도 애플리케이션을 개발했더라도, 코드 자체를 공개하지 않아도 된다. \n\n■오픈데이라이트는 ONF를 하위로 끌어내리려는 노림수? \n\n오픈네트워킹파운데이션(ONF) 주도의 오픈플로는 향후에도 별도로 존재한다. 오픈데이라이트는 사우스바운드API에 집중했던 ONF에 비해 노스바운드API와 전반적인 클라우드 매니지먼트 자동화란 큰 틀에서 접근한다. \n\n옌 부사장은 “오픈데이라이트 프로젝트의 목표는 두 가지로 첫 번째는 컨트롤러, 사우스바운드 및 노스바운드 API, 관련 툴과 서비스 기능을 포함하는 완벽한 SDN 컨트롤러 스택을 개발”이라며 “이 보다 더 광범위한 목표가 바로 애플리케이션, 툴, 서비스 전달은 물론 시장 지원도 가능한 컨트롤러 스택 전반을 구축할 수 있는 생태계를 마련하려는 것”이라고 강조했다. \n\n오픈플로진영은 그동안 컨트롤 플레인과 데이터 플레인을 구별하고, 하부 데이터 플레인의 관리분야에 집중했다. ONF가 클라우드 플랫폼 상의 네트워크 환경 관리를 위한 애플리케이션 개발에 눈을 돌리기 시작한 건 최근의 일이다. \n\n오픈데이라이트는 ONF의 오픈플로 버전 고도화를 반영하는 방향으로 접근할 것으로 예상된다. \n\n데이비드 옌 부사장은 “ONF는 오픈데이라이트 프로젝트의 공식 멤버는 아니지만, 프로젝트 태동 초기 단계부터 관여해왔다”라며 “오픈데이라이트와 ONF 모두 유사한 목표를 갖고 있기 때문인데, 오픈데이라이트 프로젝트의 초창기 목표 중 하나는 ‘사우스바운드’ 오픈플로우 플러그인이 될 것”이라고 설명했다. \n\n오픈데이라이트의 첫 코드 공개와 별도로, 시스코는 개발자 활용이 가능한 코드를 포스팅하고 있다. \n\n옌 부사장은 “오픈데이라이트 코드 자체의 가용성 측면에서만 본다면 시스코의 경우는 이미 개발자들이 활용 가능하도록 코드 포스팅을 시작했다”라며 “이에 첫 번째 공식 릴리즈, 즉 구현 가능한 완벽한 패키지는 올해 3분기 정도에는 나올 수 있을 것으로 기대하고 있다”고 전망했다. \n\n그는 “시스코는 올해 6월 시스코ONE 컨트롤러 SW 발표 후 추가적인 모듈을 공개할 계획”이라며 “트러블 슈팅, 인증, 슬라이싱 등을 위한 애플리케이션이 포함될 예정”이라고 밝혔다. \n\n6월말 개최될 ‘시스코라이브’ 행사에서 SDN 컨트롤러를 위한 모듈을 공개한다는 것이다. 그는 크게 3가지 정도의 모듈이 공개될 것으로 설명했다. \n\n구체적으로 우선, 네트워크 슬라이싱이다. 공유된 물리적 네트워크를 논리적 네트워크로 파티션하는 기술이다. 다음은 네트워크 태핑으로 모니터링, 분석, 디버깅 등을 네트워크 플로 상에서 할 수 있게 하는 기술이다. 세 번째는 세 번째는 커스텀 포워딩으로, 어떤 조건을 구체적으로 설정해놓고, 그 조건을 만족시킬 경우 네트워크 패킷이 엔지니어링된 경로 통해 바로 포워딩되는 기술이다. \n\n■벤더 중심의 SDN \'꼼수인가, 반성인가\'\n\n오픈데이라이트의 출범은 벤더 중심의 SDN이란 큰 틀로 읽힌다. 고객에 빼앗긴 시장 주도권을 되찾아야 한다는 위기감의 발로임을 부인할 수는 없다. \n\n실제로 오픈플로가 발전하면서 그 개발을 주도했던 서비스업체들이 각자 개발한 SDN 기술을 솔루션 및 서비스 형태로 사업화하려는 움직임을 보이고 있다. IT업체의 먹잇감을 고객이 취하겠다고 달려드는 형국이다.\n\n오픈데이라이트를 통해 벤더는 기술을 선도하는 건 자신들임을 증명할 수 있다. 경쟁적인 개발참여를 통해 기업에서 개발해낸 오픈데이라트 성과보다 항상 앞서가는 모습을 보이면 가능하다. \n \n▲ 오픈데이라이트 참여사 \n \n네트워크 장비업체들이 자신들의 이익을 빼앗기지 않으려 지연전략을 펴는 것이란 삐딱한 시각도 존재한다. \n\n기존 네트워크는 제공업체의 장비마다 제각각인 하드웨어에 기능이 좌우됐다. 멀티 벤더로 네트워크 환경을 구현하려는 기업은 장비업체에서 제공하는 성능과 기능이 저마다 달라 인프라 관리 자동화는커녕 통합적인 관리조차 불가능했다. \n\nSDN과 오픈플로는 네트워크 상의 하드웨어 종속에서 벗어나 SW로 모든 네트워크 환경을 구성함으로써 벤더 종속에서 탈피하자는 의도에서 발전하고 있다. 이는 기존 네트워크업체의 차별성을 무너뜨리고, 저가 장비 판매 중심으로 장비업체를 몰아넣는다. 그러므로 장비업체가 SDN과 오픈플로를 달가워할 이유는 별로 없다. \n\n그러나 벤더의 자존심을 건 밥그릇 지키기로 치부하기엔 무리가 있다. 오픈데이라이트를 통해 개발된 기술이 어느 참여업체에도 소유권이 없기 때문이다. \n\n데이비드 옌 부사장은 “어떤 기부가 프로젝트를 촉진시킬 수 있을지, 무엇을 씨드 코드로 삼을지, 누가 활동을 리드할지에 대한 궁극적인 결정은 TSC(The Technical Steering Committee)가 하게 된다”라며 “TSC가 오픈데이라이트 프로젝트를 위한 모든 기부 제안과 기술 방향에 대한 의사결정을 주관하므로, 특정 벤더 소유의 코드가 일단 기부가 되면 이는 커뮤니티의 범용 코드가 되고 커뮤니티는 어떤 방향을 취할지 또 결정하게 되는 과정을 거치게 된다”라고 설명했다. \n\n그는 “오픈소스다 보니 모든 사람들이 오리지널 코드 액세스 갖고 있으며, 어느 벤더도 이 소프트웨어의 기본을 독점할 수 없다”라며 “벤더들은 오픈소스 프레임워크에 기여하는 모듈을 제공하고, 고부가가치 앱을 만들어내면서 수익을 창출하게 될 것”이라고 덧붙였다. \n\n지연전략에 대해서도 오픈데이라이트 TSC의 결정에 따라 어느 누구도 주도하기 힘든 구조다. 한 회사가 코드를 늦게 개발하거나 일부러 헝클어 놓는 건 불가능하다는 설명이다. \n\n그는 “컨트롤러의 경우도 시스코가 기본 코드를 제공했지만, 어느 회사도 컨트롤러 코드를 개선해 기여할 수 있다”라며 “모든 컨트롤러는 서로 다른 다수의 컨트롤러로부터 얻게 되는 코드들의 종합 반영본으로 발전하게 될 것”이라고 답했다. \n\n이어 “다양한 소스에서 전문적인 기술과 경험을 뽑아내 궁극적으로는 최상의 결정과 더불어 지속적인 발전을 이뤄갈 수 있는 것이 오픈소스의 최대 이점”이라고 강조했다. \n\n현재까지 나온 발언들은 종합해보면 오픈데이라이트의 방향성 자체는 나쁘지 않다. 구체적인 개선과 성과가 이어질 경우 최종사용할 고객사 입장에선 고도화된 오픈소스 네트워크를 쉽게 구축하고, 어느 벤더에서건 지원을 받을 수 있게 되는 탓이다. \n\n또한, 오픈데이라이트에 대해 벤더가 주도권을 되찾으려 한다는 시각도 비관적인 입장을 일단 배제하는 게 옳아 보인다. \n\n확실히 현재의 SDN과 오픈플로는 점차 파편화될 기미를 보이고 있으며, 중구난방식의 개발이 이뤄지고 있다. 오랜 네트워크 기술 개발경험을 통해 능숙한 역량을 보유한 벤더가 공통의 표준을 형성한다는 건 주도권 되찾기보다 솔루션 완성도 높이기를 위한 선순환 구조 형성 측면으로 봐야할 것으로 보인다. \n\n \n\n-- 이상 --\n\n \n\n \n\n------- Original Message -------\n\nSender : 심은수<eunsoo.shim@samsung.com> 상무/Lab장/Intelligent Computing Lab(기술원)/삼성전자\n\nDate : 2013-04-25 12:41 (GMT+09:00)\n\nTitle : EMC·IBM 업은 레노버, 기업시장 강자 부상?\n\n \n\n스토리지 서버에 애플리케이션을 실행시킨다는 대목이 눈에 띕니다.\n\n이 접근의 의미, 장/단점에 대해서 생각해 볼 필요가 있습니다.\n\n \n\nhttp://media.daum.net/digital/newsview?newsid=20130425090106567\n\n \n\n감사합니다.\n\n \n\n심은수 드림\n\n</pre>\n\n\n\n\n==== References ====\n\n* [http://ettrends.etri.re.kr/PDFData/27-2_129-136.pdf ETRI - SDN 미래 네트워킹 기술]\n\n=== Disk Performance / Speed Specifications ===\n\n==== Samsung SSD spec (128GB 2.5-inch SSD 840 Pro Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 128GB\n\n* Performance\n:- Sequential Read Speed: Up to 530 MB/s\n:- Sequential Write Speed: Up to 390 MB/s\n:- Random Read Speed: Up to 97,000 IOPS (4KB/IO) // Read Latency: 10.31 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(97000))\"\n:- Random Write Speed: Up to 90,000 IOPS (4KB/IO) // Write Latency: 11.11 usec (80~200 usec, NCQ, Non-blocking) // python -c \"print (float(1 * (10 ** 6)) / float(90000))\"\n\n* Power Consumption (W)\n: 0.15W\n\n==== Intel SSD spec (320 Series) ====\n\n* Interface\n:- SATA 6Gb/s\n\n* Capacity\n: 120GB\n\n* Performance\n:- Sequential Read Speed: up to 270 MB/s \n:- Sequential Write Speed: up to 130 MB/s\n:- Random Read Speed: 38,000 IOPS (4KB/IO) // Read Latency: 26.32 usec // python -c \"print (float(1 * (10 ** 6)) / float(38000))\"\n:- Random Write Speed: 14,000 IOPS (4KB/IO) // Write Latency: 71.43 usec // python -c \"print (float(1 * (10 ** 6)) / float(14000))\"\n\n==== Seagate HDD spec (Barracuda 2TB) ====\n\n* Model Number\n:- ST2000DM001\n\n* Interface\n:- SATA 6Gb/s NCQ\n\n* Performance\n:- Spindle Speed (RPM): 7200\n:- Cache, Multisegmented (MB): 64\n:- SATA Transfer Rates Supported (Gb/s): 6.0/3.0/1.5\n:- Seek Average, Read (ms): <8.5 // 117 IOPS\n:- Seek Average, Write (ms): <9.5 // 105 IOPS\n:- Average Data Rate, Read/Write (MB/s): 156\n:- Max Sustained Data Rate, OD Read (MB/s): 210\n\n* Configuration/Organization\n:- Heads/Disks: 6/3\n:- Bytes per Sector: 4096\n\n* Reliability/Data Integrity\n:- Annualized Failure Rate (AFR): <1%\n:- Power-On Hours: 2400\n\n* Power Management\n:- Startup Power (A): 2.0\n:- Operating Mode, Typical (W): 8.0\n:- Idle2 Average (W): 5.40\n:- Idle Average (W): N/A\n:- Standby Mode (W): 0.75\n:- Sleep Mode (W): 0.75\n\n== ## bNote-2013-04-25 ==\n\n=== News / Articles ===\n\n* [http://www.zdnet.co.kr/news/news_view.asp?artice_id=20130422135700 SDN 국면 전환을 꿈꾸다 \'오픈데이라이트 (Open Daylight)\' // 2013-04-22]\n* [http://www.bloter.net/archives/150410?utm_source=feedly Facebook, Datacenter 운영 현황 공개 // 2013-04-19]\n\n\n=== Bayesian Inference with R (r_stat) ===\n\n* [http://books.google.co.kr/books?hl=en&lr=&id=AALhk_mt7SYC&oi=fnd&pg=PP5&dq=famous+R+package+bayesian+inference&ots=XvK-GIW-Ji&sig=TK-Xz5xQ1urvG6vge2YV9BAnlPo&redir_esc=y#v=onepage&q&f=false Book - \"Bayesian Computation with R\", 2nd Ed., Jim Albert]\n* [http://books.google.co.kr/books?hl=en&lr=&id=GTJUt8fcFx8C&oi=fnd&pg=PP1&dq=famous+R+package+bayesian+inference+example&ots=Iy1FKoP4ux&sig=y1_93HNmPIMDaRCCdzyzvSlReAU&redir_esc=y#v=onepage&q=famous%20R%20package%20bayesian%20inference%20example&f=false \"Bayesian Methods for Data Analysis\", 3rd Ed., Bradley P. Carlin, Thomas A. Louis]\n* [http://www.bayesian-inference.com/index Bayesian-Inference // LaplacesDemon - a complete environment for Bayesian inference in R // Statisticat, LLC.]\n* [http://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf \"Bayesian Inference\", Statisticat, LLC]\n\n== ## bNote-2013-04-24 ==\n\n=== Paper References ===\n\n* [http://infolab.stanford.edu/~ragho/hive-icde2010.pdf Hive - A Petabyte Scale Data Warehouse Using Hadoop // Facebook]\n* [http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//pubs/archive/36632.pdf Dremel: Interactive Analysis of Web-scale Datasets // VLDB 2010 // Google]\n* [http://www.cs.berkeley.edu/~istoica/classes/cs294/11/papers/pacman-draft.pdf PACMan: Coordinated Memory Caching for Parallel Jobs]\n* [http://www.cs.berkeley.edu/~matei/talks/2012/hadoop_summit_spark.pdf Spark and Shark // AMPLab UC Berkeley]\n* [http://grid.hust.edu.cn/xhshi/paper/MR-Scope.pdf MR-Scope: A Real-time Tracing Tool for MapReduce]\n* [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5493490&tag=1 An Analysis of Traces from a Production MapReduce Cluster // CCGRID 2010]\n* [http://bnrg.eecs.berkeley.edu/~randy/Courses/CS268.F08/papers/42_osdi_08.pdf Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008 // UC Berkeley]\n* [http://webhdd.ru/library/files/RebalanceDesign6.pdf Rebalance an HDFS Cluster]\n* [http://www.ibm.com/developerworks/web/library/wa-introhdfs/ An introduction to the Hadoop Distributed File System -- HDFS Data Block Rebalancing]\n* [http://www.stanford.edu/~cdel/epic.talk.workloads.pdf Data Center Workload Characterization]\n* [http://seelab.ucsd.edu/virtualefficiency/related_papers/42_caecw05.pdf Data Center Workload Monitoring, Analysis, and Emulation]\n* [https://amplab.cs.berkeley.edu/projects/real-life-workloads/ AMPLab UC Berkeley - Real-life Workloads]\n* [http://davidmeisner.org/wp-content/uploads/2011/04/meisner-exert10.pdf Stochastic Queuing Simulation for Data Center Workloads]\n* [http://research.microsoft.com/en-us/um/people/srikanth/data/imc09_dcTraffic.pdf The Nature of Datacenter Traffic: Measurements & Analysis // MSR]\n* [http://nowlab.cse.ohio-state.edu/publications/tech-reports/2005/vaidyana-caecw05-tr.pdf Workload-driven Analysis of File Systems in Shared Multi-tier Data Centers over InfiniBand // Ohio State University]\n* [http://research.microsoft.com/pubs/81782/2009-06-19%20Data%20Center%20Tutorial%20-%20SIGMETRICS.pdf What Goes Into a Data Center? // MSR]\n* [http://delivery.acm.org/10.1145/1780000/1773400/p34-mishra.pdf?ip=202.20.193.254&acc=ACTIVE%20SERVICE&key=986B26D8D17D60C855C5A4E2351BBB67&CFID=209231705&CFTOKEN=89669612&__acm__=1366870790_f6ca461a6119bb2a2d6f017ca1bc9ce7 Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters // ACM SIGMETRICS Performance Evaluation Review Vol. 37, Issue 4, 2010-03 // Google]\n\n=== White Paper from EMC (Benchmark) ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX // 2011-04 // ((B.GOOD))]\n* [http://www.emc.com/collateral/hardware/white-papers/h11210-p690-emc-vnx7500-scaling-performance-oracle-11g-vsphere-wp.pdf EMC VNX7500 Scaling Performance for Oracle 11gR2 RAC on VMware vSphere 5.1 // 2012-12 ((B.GOOD))]\n* [http://www.compucom.com/sites/default/files/Whitepaper-Deploying-Oracle-Database-Apps-on-EMC-VNX.pdf Deploying Oracle Database Applications on EMC VNX Unified Storage // 2011-04]\n* [http://www.emc.com/collateral/hardware/white-papers/h8850-oracle-performance-vnx-fastcache-wp.pdf EMC Performance for Oracle (EMC VNX, Enterprise Flash Drives, FAST Cache, VMware vSphere // 2011-12]\n* [http://www.emc.com/collateral/white-papers/h11209-p773-osc-integration-vmax-mgt-virtualized-oracle-ebs-wp.pdf EMC Oracle VM Storage Connect Integration Module - Efficient Infrastructure Management for a Virtualized Oracle E-Business Suite // 2013-03]\n* [http://www.emc.com/collateral/analyst-reports/esg-20091208-fast.pdf ESG Whitepaper - Automate and Optimize a Tiered Storage Environment - FAST // 2009-12]\n* [http://www.emc.com/collateral/hardware/white-papers/h8091-leveraging-fast-sql-wp.pdf White Paper - Leveraging EMC Fully Automated Storage Tiering (FAST) and FAST Cache for SQL Server Enterprise Deployments // 2010-11]\n* [http://www.emc.com/collateral/software/white-papers/h10938-vnx-best-practices-wp.pdf EMC VNX Unified Best Practices for Performance // 2012-08]\n* [http://www.emc.com/collateral/white-papers/h11122-vmax10k-fastvp-tiering-oracledb-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX 10K // 2012-09]\n* [http://www.theregister.co.uk/2013/03/05/emc_xtremsf/ EMC declares war on all-flash array, server flash card rivals - Rolls out XtremIO array, renamed VFCache - XtremSF Server Flash, XtremSW Cache Software, XtremIO all-flash array // 2013-03-05]\n\n== ## bNote-2013-04-23 ==\n\n\n=== Real Trace: MS Exchange ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' f030.infile_A.iowa.anal_s0010 > summary\na1mjjung@secm:[iowa] $ cat summary \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  88\n__valu__sig__ _n_o_sigaddrs :  9989\n__valu__sig__ _sigioc_acc :  7266636\n__valu__sig__ _sigaddrs_efficiency :  727.463810191\n__valu__sig__ _n_o_addr_total :  8322343\n__valu__sig__ _ioc_total :  28866005\n</pre>\n\n=== Real Trace: MSN FileServer ===\n\n <pre>\na1mjjung@secm:[iowa] $ grep \'__valu__sig__\' iowa.anal_s0010.A.out > summary\na1mjjung@secm:[iowa] $ cat summary  \n__valu__sig__ _ioc_percent :  25\n__valu__sig__ _sighitcnt :  18\n__valu__sig__ _n_o_sigaddrs :  239328\n__valu__sig__ _sigioc_acc :  7571590\n__valu__sig__ _sigaddrs_efficiency :  31.6368749164\n__valu__sig__ _n_o_addr_total :  7425792\n__valu__sig__ _ioc_total :  29345085\n</pre>\n\n=== I/O Intensiveness Analysis (3D plot) ===\n\n* pre-processing for 3D-plot (access count per iomw)\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .bdx.0100.y.iowa_anal.sh \n#!/bin/sh\n\n_iowa_anal_cmd=\"bsc.iowa.lsp.anal_s0010\";\n\n_file_010=\"f010.T021.msnfs.R.out\";\n_file_020=\"f020.infile_R\";\n_file_030=\"f030.infile_R.iowa.anal_s0010\";\n_file_040=\"f040.iomw_acs_cnt.sorted_by_acs_cnt\";\n\ncat $_file_010 | awk \'{ print $5, \",\", $14}\' > $_file_020\ncat $_file_020 | $_iowa_anal_cmd -c 25 -w 600000000 -p 60000000 > $_file_030\ncat $_file_030 | grep __list__iomw_acs_cnt | awk \'{ print $9, $3, $6 }\' | sort -n > $_file_040\n\n</pre>\n\n* gnuplot command\n\n:* iowa.anal - Reads\n <pre>\n\na1mjjung@secm:[iowa.R] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Reads (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n:* iowa.anal - Writes\n <pre>\n\na1mjjung@secm:[iowa.W] $ cat .plot_acs_cnt.gp \nclear\nunset key\nset title \"I/O intensiveness - Writes (MSN FileServer 6H)\"\nset xlabel \"time (10-minute)\"\nset ylabel \"address (LBA)\"\nset zlabel \"hit count per addr\"\nshow view\nset view 45, 60\nsplot \'./f040.iomw_acs_cnt.sorted_by_acs_cnt\' u 3:2:1 with points palette pointsize 1 pointtype 7\n\n</pre>\n\n\n* References\n\n:* [http://psy.swansea.ac.uk/staff/carter/gnuplot/gnuplot_3d.htm]\n:* [http://lowrank.net/gnuplot/plot3d-e.html]\n\n== ## bNote-2013-04-18 ==\n\n=== EMC FAST (VP, Cache) Technology Study ===\n\n* [http://www.emc.com/collateral/hardware/white-papers/h8131-storage-tiering-oracle-vmax-wp.pdf Implementing FAST VP and Storage Tiering for Oracle Database 11g and EMC Symmetrix VMAX]\n: Shows performance improvement by FAST VP\n\n== ## bNote-2013-04-17 ==\n\n=== Proactive Data Placement Research Planning ===\n\n== ## bNote-2013-04-16 ==\n\n=== Git on the Server - Setting Up the Server ===\n\n\n* Reference\n: [http://git-scm.com/book/ch4-4.html 4.4 Git on the Server - Setting Up the Server // git-scm.com]\n\n\n* 4.4 Git on the Server - Setting Up the Server\n\'\'\' Setting Up the Server \'\'\'\n\n: Let\'s walk through setting up SSH access on the server side. In this example, you\'ll use the authorized_keys method for authenticating your users. We also assume you\'re running a standard Linux distribution like Ubuntu. First, you create a \'git\' user and a .ssh directory for that user.\n\n <pre>\n$ sudo adduser git\n$ su git\n$ cd\n$ mkdir .ssh\n</pre>\n\n: Next, you need to add some developer SSH public keys to the authorized_keys file for that user. Let\'s assume you\'ve received a few keys by e-mail and saved them to temporary files. Again, the public keys look something like this:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCB007n/ww+ouN4gSLKssMxXnBOvf9LGt4L\nojG6rs6hPB09j9R/T17/x4lhJA0F3FR1rP6kYBRsWj2aThGw6HXLm9/5zytK6Ztg3RPKK+4k\nYjh6541NYsnEAZuXz0jTTyAUfrtU3Z5E003C4oxOj6H0rfIF1kKI9MAQLMdpGW1GYEIgS9Ez\nSdfd8AcCIicTDWbqLAcU4UpkaX8KyGlLwsNuuGztobF8m72ALC/nLF6JLtPofwFBlgc+myiv\nO7TCUSBdLQlgMVOFq1I2uPWQOkOWQAHukEOmfjy2jctxSDBQ220ymjaNsHT4kgtZg2AYYgPq\ndAv8JggJICUvax2T9va5 gsg-keypair\n</pre>\n\n: You just append them to your authorized_keys file:\n\n <pre>\n$ cat /tmp/id_rsa.john.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.josie.pub >> ~/.ssh/authorized_keys\n$ cat /tmp/id_rsa.jessica.pub >> ~/.ssh/authorized_keys\n</pre>\n\n: Now, you can set up an empty repository for them by running git init with the --bare option, which initializes the repository without a working directory:\n\n <pre>\n$ cd /opt/git\n$ mkdir project.git\n$ cd project.git\n$ git --bare init\n</pre>\n\n: Then, John, Josie, or Jessica can push the first version of their project into that repository by adding it as a remote and pushing up a branch. Note that someone must shell onto the machine and create a bare repository every time you want to add a project. Let\'s use gitserver as the hostname of the server on which you\'ve set up your \'git\' user and repository. If you\'re running it internally, and you set up DNS for gitserver to point to that server, then you can use the commands pretty much as is:\n\n: # on Johns computer\n <pre>\n$ cd myproject\n$ git init\n$ git add .\n$ git commit -m \'initial commit\'\n$ git remote add origin git@gitserver:/opt/git/project.git\n$ git push origin master\n</pre>\n\nAt this point, the others can clone it down and push changes back up just as easily:\n\n <pre>\n$ git clone git@gitserver:/opt/git/project.git\n$ cd project\n$ vim README\n$ git commit -am \'fix for the README file\'\n$ git push origin master\n</pre>\n\n: With this method, you can quickly get a read/write Git server up and running for a handful of developers.\n\n: As an extra precaution, you can easily restrict the \'git\' user to only doing Git activities with a limited shell tool called git-shell that comes with Git. If you set this as your \'git\' user\'s login shell, then the \'git\' user cannot have normal shell access to your server. To use this, specify git-shell instead of bash or csh for your user\'s login shell. To do so, you will likely have to edit your /etc/passwd file:\n\n <pre>\n$ sudo vim /etc/passwd\n</pre>\n\n: At the bottom, you should find a line that looks something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/bin/sh\n</pre>\n\n: Change /bin/sh to /usr/bin/git-shell (or run which git-shell to see where it’s installed). The line should look something like this:\n\n <pre>\ngit:x:1000:1000::/home/git:/usr/bin/git-shell\n</pre>\n\nNow, the \'git\' user can only use the SSH connection to push and pull Git repositories and cannot shell onto the machine. If you try, you will see a login rejection like this:\n\n <pre>\n$ ssh git@gitserver\nfatal: What do you think I am? A shell?\nConnection to gitserver closed.\n</pre>\n\n== ## bNote-2013-04-15 ==\n\n=== Sorting Algorithms ===\n\n* [[Sorting algorithms]]\n* [http://corte.si/posts/code/visualisingsorting/index.html Visualising Sorting Algorithms]\n\n== ## bNote-2013-04-11 ==\n\n=== Failure trend in a data center ===\n\n==== 꽤 충실한 내용의 블로그 ((B.GOOD)) ====\n\n* URL: [http://bart7449.tistory.com/m/post/view/id/258 현실에서의 메모리와 디스크의 오류 // 2010-10-04]\n\n\n\n=== 수퍼컴 협력 ===\n\n* TAT 단축\n\n:- 40시간 걸리던 작업이 32분만에 완료 (75배 TAT 단축)\n (32 * 75) / 60 = 40 시간 \n\n:- 18시간 걸리던 작업이 27분만에 완료 (40배 TAT 단축)\n (27 * 40) / 60 = 18시간\n\n* 업무 협조 요청 (to 김혁호 책임)\n\n <pre>\n\nI/O Workload 분석 & 시뮬레이션 환경 병렬화\n\n ㆍ배경 및 목적\n① I/O Workload 분석 & 시뮬레이션 환경 병렬화\n     - 다양한 종류의 Trace Log 데이터 Set에 대한 분석 필요\n     - 하나의 데이터 Set에 대해서도 다양한 Parameter 설정 별 분석 수행\n   ② 데이터 전송 자동화\n     - 분석 케이스 별로 산출되는 대규모 Data Output들 중, 특정 위치의\n       데이터에 대한 자동적 백업 (to 별도 파일서버)\n\n ㆍ추진 방향\n   ① Parameter 설정 별 동시 병렬 분석 구조 구현 (Parameter Sweeping)\n   ② 슈퍼컴-파일서버 간 데이터 자동 백업 구현 (특정 디렉토리 대상)\n      예) 특정 디렉토리 내 데이터를 파일서버로 정기적 백업 (by cronjob)\n\n ㆍ추진 일정\n   ① 단계별 소요시간 (Workload Analysis 기반 Data Placement)\n      [Step 1] Trace Data 수집                         : 5주\n      [Step 2] 분석 위한 전처리(Data Parsing/Transform)  : 2주\n      [Step 3] I/O Workload Outlook 분석               : 4주 (2+2)\n      [Step 4] Dominant I/O 패턴 추출                   : 8주 (3+5)\n      [Step 5] I/O 패턴 예측 모델링/학습/시뮬레이션 검증    : 10주 (3+7)\n      [Step 6] Data Placement 알고리즘 구현 및 검증       : 12주\n      ※ 상기 소요 시간은 수퍼컴에서의 작업 시간임\n        (이미 수퍼컴으로 PC 서버 대비 40~75배의 TAT 단축됨)\n      ※ Workload Analysis 작업 Set (24주): Step 2 ~ Step 5\n   ② 협업 업무 및 소요시간\n      - 상기 3, 4, 5 단계의 Parameter Sweeping 부분 병렬화 협력\n        : 22주 → 8주로 단축예상 (수퍼컴 이전 대비 110~200배 TAT 단축)\n\n ㆍ추진 효과\n   ① 당사 자체적인 I/O Workload 분석 및 성능 시뮬레이션 시스템 확보\n   ② Workload에 최적화된 Data Management 알고리즘 개발로\n      데이터센터 및 분산 스토리지 시스템의 성능 향상 기대\n   ③ I/O Workload 분석 및 시뮬레이션 작업 TAT 개선\n\n [참고1]\n ㆍ전체 Simulation 단계 중, Preprocessing단계에서 슈퍼컴 파일시스템의\n   Real I/O Trace Log Data가 필요하며, Analysis(Outlook, Modeling)\n   단계에서 Algorithm 병렬화를 통한 TAT 단축 필요\n \n [참고2]\n ㆍ과제 Workflow : 첨부파일 참조\n \n\n\n\n</pre>\n\n== ## bNote-2013-04-10 ==\n\n=== IOWA:: MSN FileServer I/O Trace ===\n\n==== T034 ====\n\n* # of reads/writes (total I/Os): 982166\n* # of reads: 811784\n* # of writes: 170382\n\n\n <pre>\na1mjjung@secm:[T033.discovery.full_path] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskRead\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n\na1mjjung@secm:[T033.discovery.full_path] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | grep \'_iorw_ DiskWrite\' > _t034/T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ pwd\n/home/X0101/a1mjjung/x/iowa.sidewinder/sidewinder/microsoft_msn_filesrvr_6h/MSNStorageFileServer/tdir/T033.discovery.full_path/_t034\n\n\na1mjjung@secm:[_t034] $ tail -10 ../../T031.msnfs.fld_dstr.full_path.out \n 382331  _path_ _Disk8__s4_s5_s6_\n 403592  _path_ _Disk9__s0_s1_s13_\n 413900  _path_ _Disk8__s0_s1_s7_\n 418544  _path_ _Disk9__s3_s4_s6_\n 428969  _path_ _Disk8__s0_s1_s9_\n 450260  _path_ _Disk9__s0_s1_s7_\n 466085  _path_ _Disk9__s3_s4_s5_\n 600647  _path_ _Disk9__s0_s1_s3_\n 811630  _path_ _Disk8__s0_s1_s2_\n 982166  _path_ _Disk9__s0_s1_s2_\n\n\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\n811784 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out\na1mjjung@secm:[_t034] $ wc -l T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n170382 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out\n</pre>\n\n\n <pre>\na1mjjung@secm:[_t034] $ head -10 T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out \n_iorw_ DiskRead   , _time_ 248425 , _prid_ p0_2004 , _thid_           540   , _addr_  100276969472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 263287 , _prid_ p0_2004 , _thid_           540   , _addr_  97312505856  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 281149 , _prid_ p0_2004 , _thid_           540   , _addr_  92908216320  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 305383 , _prid_ p0_2004 , _thid_           540   , _addr_  98594537472  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 320338 , _prid_ p0_2004 , _thid_           540   , _addr_  100699373568  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 325746 , _prid_ p0_2004 , _thid_           540   , _addr_  100944601088  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 330001 , _prid_ p0_2004 , _thid_           540   , _addr_  94236082176  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 339520 , _prid_ p0_2004 , _thid_           540   , _addr_  92404563968  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 344061 , _prid_ p0_2004 , _thid_           540   , _addr_  94653767680  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n_iorw_ DiskRead   , _time_ 399820 , _prid_ p0_2004 , _thid_           540   , _addr_  157423190016  , _iosz_  8192  , _fobj_    0xfffffadf3ad4ec10   , _path_ _Disk9__s0_s1_s2_\n</pre>\n\n\n* _thid_ based T034 analysis\n\n <pre>\na1mjjung@secm:[_t034] $ cat T033.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n249\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n245\n\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.W.out | awk \'{print $11}\' | sort | uniq -c | sort | wc -l\n240\n</pre>\n\n <pre>\na1mjjung@secm:[_t034] $ cat T034.msnfs.discovery.full_path._path___Disk9__s0_s1_s2_.R.out | awk \'{ print $11 }\' | sort | uniq -c | sort | tail -10 \n   8602 540\n   9006 8716\n   9254 7792\n   9603 9440\n   9692 8788\n  10393 10948\n  10842 10000\n  11079 8172\n  12332 11240\n  51747 4060\n</pre>\n\n=== R plot ===\n\n* [http://www.cyclismo.org/tutorial/R/plotting.html plotting in R // R tutorial]\n\n=== Beautiful graphs in Gnuplot ===\n\n* [http://labs.guidolin.net/2010/03/how-to-create-beautiful-gnuplot-graphs.html How to create beautiful Gnuplot graphs (tips and tricks) // GuidoLabs]\n:- [[exemplary .gnuplot configuration file for beautiful gnuplot graphs]]\n:- [http://www.dafont.com/sv-basic-manual.font?text=fdgdfd SV Basic Manual Font]\n\n=== Summary of the ways to call external programs (and pros/cons) ===\n\n* os.system(\"some_command with args\") [http://docs.python.org/lib/os-process.html os.system() // Python tutorial]\n: passes the command and arguments to your system\'s shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example,\n os.system(\"some_command < input_file | another_command > output_file\")\n: However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, etc. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.\n\n* stream = os.popen(\"some_command with args\") [http://docs.python.org/lib/os-newstreams.html os.popen() // Python Tutorial]\n: will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don\'t need to worry about escaping anything.\n\n* The Popen class of the subprocess module. [http://docs.python.org/lib/node528.html Popen class // Python Tutorial]\n: This is intended as a replacement for os.popen but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you\'d say\n print Popen(\"echo Hello World\", stdout=PIPE, shell=True).stdout.read()\n: instead of\n print os.popen(\"echo Hello World\").read()\n: but it is nice to have all of the options there in one unified class instead of 4 different popen functions.\n\n* The call function from the subprocess module. [http://docs.python.org/lib/node529.html call() // Python Toturial]\n: This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives you the return code. For example: \n return_code = call(\"echo Hello World\", shell=True)\n\n* The last resort (not-recommended)\n: The os module also has all of the fork/exec/spawn functions that you\'d have in a C program, but I don\'t recommend using them directly.\n\n* <span style=\"color:blue\">\'\'\'The subprocess module should probably be what you use.\'\'\'</span>\n\n----\n=== Calling an external command in Python ===\n\n* How can I call an external command in Python?\n:->\n: Look at the subprocess module in the stdlib:\n\n from subprocess import call\n call([\"ls\", \"-l\"])\n\n: The advantage of subprocess vs system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...). I think os.system is deprecated, too, or will be ... [http://docs.python.org/library/subprocess.html#replacing-older-functions-with-the-subprocess-module related part of the python tutorial]\n: But for quick/dirty/one time scripts, os.system is enough, though.\n\n----\n=== String edit in python ===\n\n* sed to python [http://objectmix.com/python/387782-sed-python-replace-q.html]\n\nFor some reason I\'m unable to grok Python\'s string.replace() function.\n:-> replace() does not work with regular expressions. Try the following.\n import re\n p = re.compile(\"^.*\\[\")\n q = re.compile(\"].*$\")\n q.sub(\'\',p.sub(\'\', line))\n\nJust trying to parse a simple IP address, wrapped in square brackets, from Postfix logs.\n\nIn sed this is straightforward given:\n line = \"date process text [ip] more text\"\n sed -e \'s/^.*\\[//\' -e \'s/].*$//\'\n\nyet the following Python code does \'\'\'nothing\'\'\':\n line = line.replace(\'^.*\\[\', \'\', 1)\n line = line.replace(\'].*$\', \'\')\n\nIs there a decent description of string.replace() somewhere?\n:-> use re.sub()\n\n----\n\n=== Python string translate() method ===\n\n* [http://www.tutorialspoint.com/python/string_translate.htm Python string translate() method]\n: the method translate() returns a copy of the string in which all characters have been translated using table (constructed with the maketrans() function in the string module), optionally deleting all characters found in the string deletechars.\n\n* The following example shows the usage of translate() method. Under this every vowel in a string is replaced by its vowel position:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab);\n</pre>\n\n <pre>\nth3s 3s str3ng 2x1mpl2....w4w!!!\n</pre>\n\n* Following is the example to delete \'x\' and \'m\' characters from the string:\n\n <pre>\n#!/usr/bin/python\n\nfrom string import maketrans   # Required to call maketrans function.\n\nintab = \"aeiou\"\nouttab = \"12345\"\ntrantab = maketrans(intab, outtab)\n\nstr = \"this is string example....wow!!!\";\nprint str.translate(trantab, \'xm\');\n</pre>\n\n <pre>\nth3s 3s str3ng 21pl2....w4w!!!\n</pre>\n\n== ## bNote-2013-04-09 ==\n\n=== Straggler-immune Data Placement for Distributed File System ===\n* [[Bnote patidea 2013]]\n\n\n=== 과제 목표 평가 방법 객관화/구체화 ===\n\n* 데이터 Access 성능 목표 달성 기준\n: Realistic enterprise workload 인가 시, (*)\n: Data placement 및 RACS-1 기술이 적용되지 않은 vanilla SW-RAID 대비\n: 80% 속도 향상 (in IOPS) (**)\n:: (*) Realistic enterprise workload라고 했을 때, 아래 workload 인가 방안의 Case A,B,C가 해당될 수 있겠다고 보고 있으며, \'13년 9월 쯤을 고려했을 때, 현실적으로는 Case C로 가고, workload type은 DB 혹은 fileserver 쪽으로 가는 것을 생각하고 있습니다. (\'14년 정도에는 Case B나 Case A도 생각해볼 수 있을 것 같습니다)\n:: (**) metric에 대한 부분인 \"SW-RAID 대비 속도 향상 비율: 80%\"은 MBO에 이대로 명시가 되어 수정이 어렵다고 생각하여 그대로 두었습니다.  다만, 속도를 향상시키는 요소 기술로서 동작하는 것은 RACS-1 뿐만 아니라 Data Placement도 가능하겠으므로, 이를 염두에 두고 아래 내용을 작성하였습니다.\n\n\n* Workload type\n: 대표적인 enterprise workload type인 DB, FileServer, Web 중 택일하거나\n: Scientific Computing (R, Matlab, Hadoop 등)을 선택할 수 있겠음\n: VDI workload를 고려할지에 대해서는 추가 고민 필요 (아직까지는 고려하지 않고 있음)\n\n\n* Workload 인가 방안\n:- 대표적인 enterprise workload로 성능 benchmark 필요\n::- Case A) [최선] real enterprise workload 사용\n::- Case B) [차선] enterprise workload에 대한 real trace에 기반한 real workload replay 활용 (workload replayer 구현 필요)\n::- Case C) [차차선] TPC-C, filebench 등과 같이 real workload를 모방한 realistic synthesized workload 사용\n::- Case D) [차차차선] (비추천), iozone 등과 같은 random/sequential read/write I/O pattern 생성기 사용\n\n\n\n* Workload 인가 방식에 따른 환경 구성\n: Case A, B, C 모두 storage system과 network 구성은 동일하며, client 구성 방식에서 차이 존재\n::- storage system: target storage system 1 box (comprised of controller + disk arrays)\n::- network: switching hub를 통해 1G Ethernet으로 연결 (혹은 상황에 따라 10G Ethernet으로 연결)\n\n:- Case A: real workload 인가 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case B: real workload replay 방식을 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC N 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n:- Case C: TPC-C 혹은 filebench를 이용하는 경우\n::- client: benchmark S/W가 구동되는 PC 1 대 (최소 사양: CPU 4-core, RAM 8GB)\n\n\n* Storage system interface exposed\n: SAN, NAS 방식 중 결정 필요\n\n\n* 가상화 이슈\n: 기본적으로 Hypervisor (Xen, VMware 등)를 사용 하지 않는 환경으로 구성\n\n\n* 성능 측정 방법\n:- 1-day (case A), 1-week (case B) 동안 workload를 인가하여 계산된 IOPS로 판별\n:- 가급적 경쟁사 제품의 성능측정 tool에서 제공하는 metric과 동일하게 가는 것이 좋을 것으로 보임\n::- Real enterprise workload 인가 시, iostat, sar 등 별도의 성능 측정 모듈 구동 필요\n::- Real workload replayer의 경우, total IOPS metric를 계산할 수 있도록 구현 필요\n::- TPC-C, filebench의 경우 (물론 iozone 역시) total IOPS metric을 계산하여 benchmark 결과로서 제공\n\n== ## bNote-2013-04-08 ==\n\n=== 서울대 산학 특허 처리 완료 ===\n* [[Bnote patidea 2013]]\n\n=== MapReduce Workload Analysis Study ===\n* [[Bnote PaperStudy // An Analysis of Traces from a Production MapReduce Cluster // CCGrid 2010]]\n* [[Bnote PaperStudy // Improving MapReduce Performance in Heterogeneous Environments // OSDI 2008]]\n\n\n\n== ## bNote-2013-04-05 ==\n\n=== Hadoop HDFS Data Placement ===\n\n==== How can I be sure that data is distributed evenly across the hadoop nodes? (2011-02-21) ====\n\n* Article\'s URL\n: [http://stackoverflow.com/questions/5065394/how-an-i-be-sure-that-data-is-distributed-evenly-across-the-hadoop-nodes Question (2011-02-21)]\n\n* Answer 1 (2011-02-21)\n: If your replication is set to 3, it will be put on 3 separate nodes. The number of nodes it\'s placed on is controlled by your replication factor. If you want greater distribution then you can increase the replication number by editing the $HADOOP_HOME/conf/hadoop-site.xml and changing the dfs.replication value.\n\n: \'\'\'I believe new blocks are placed almost randomly.\'\'\' There is some consideration for distribution across different racks (when \'\'\'hadoop is made aware of racks\'\'\'). There is an example (can\'t find link) that if you have replication at 3 and 2 racks, 2 blocks will be in one rack and the third block will be placed in the other rack. I would guess that there is no preference shown for what node gets the blocks in the rack.\n\n: I haven\'t seen anything indicating or stating a preference to store blocks of the same file on the same nodes.\n\n: If you are looking for ways to force balancing data across nodes (with replication at whatever value) a simple option is <span style=\"color:red\">\'\'\'$HADOOP_HOME/bin/start-balancer.sh\'\'\'</span> which will run a balancing process to move blocks around the cluster automatically. This and a few other balancing options can be found in at the Hadoop FAQs\n\n: Hope that helps.\n\n* Answer 2 (2011-02-21)\n: You can open \'\'\'HDFS Web UI on port 50070\'\'\' of Your namenode. It will show you the information about data nodes. One thing you will see there - used space per node.  If you do not have UI - you can look on the space used in the HDFS directories of the data nodes. If you have a data skew, you can run rebalancer which will solve it gradually.\n\n* Answer 3 (2013-03-01)\n: Now with \'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)] patch\'\'\', we can choose the block placement policy, so as to place all blocks of a file in the same node (and similarly for replicated nodes). Read this blog about this topic - look at the comments section.\n\n==== HDFS block replica placement in your hands now (2009-09-14) ====\n\n* Article\'s URL [http://hadoopblog.blogspot.kr/2009/09/hdfs-block-replica-placement-in-your.html HDFS block replica placement in your hands now]\n\n\n: Most Hadoop administrators set the default replication factor for their files to be three. The main assumption here is that if you keep three copies of the data, your data is safe. I have observed this to be true in the big clusters that we manage and operate. In actuality, administrators are managing two failure aspects: data corruption and data availability.\n\n\n: If all the datanodes on which the replicas of a block exist catch fire at the same time, then that data is lost and cannot be recovered. Or if an administrative error causes all the existing replicas of a block to be deleted, then it is a catastrophic failure. This is data corruption. On the other hand, if a rack switch goes down for sometime, the datanodes on that rack are in-accessible during that time. When that faulty rack switch is fixed, the data on the rack rejoins the HDFS cluster and life goes on as usual. This is a data avilability issue; in this case data was not corrupted or lost, it was just unavailable for some time. HDFS keeps three copies of a block on three different datanodes to protect against true data corruption. HDFS also tries to distribute these three replicas on more than one rack to protect against data availability issues. The fact that HDFS actively monitors any failed datanode(s) and upon failure detection immediately schedules re-replication of blocks (if needed) implies that three copies of data on three different nodes is sufficient to avoid corrupted files.\n\n\n: HDFS uses a <span style=\"color:red\">\'\'\'simple but highly effective policy\'\'\'</span> to allocate replicas for a block. If a process that is running on any of the HDFS cluster nodes open a file for writing a block, then <span style=\"color:blue\">\'\'\'one replica\'\'\'</span> of that block is allocated on the same machine on which the client is running. <span style=\"color:blue\">\'\'\'The second replica\'\'\'</span> is allocated on a randomly chosen rack that is different from the rack on which the first replica was allocated. <span style=\"color:blue\">\'\'\'The third replica\'\'\'</span> is allocated on a randomly chosen machine on the same remote rack that was chosen in the earlier step. This means that a block is present on two unique racks. One point to note is that there is <span style=\"color:red\">\'\'\'no relationship between replicas of different blocks of the same file\'\'\'</span> as far as their location is concerned. Each block is allocated independently.\n\n\n: The above algorithm is great for availability and scalability. However, there are <span style=\"color:red\">\'\'\'scenarios where co-locating many block of the same file on the same set of datanode(s) or rack(s) is beneficial\'\'\'</span> for performance reasons. For example, if many blocks of the same file are present on the same datanode(s), a single mapper instance could process all these blocks using the CombineFileInputFormat. Similarly, if a dataset contains many small files that are co-located on the same datanode(s) or rack(s), one can use CombineFileInputFormat to process all these file together by using fewer mapper instances via CombineFileInputFormat. If an application always uses one dataset with another dataset (think Hive or Pig join), then co-locating these two datasets on the same set of datanodes is beneficial.\n\n\n: Another reason when one might want to allocate replicas using a different policy is to ensure that replicas and their parity blocks truly <span style=\"color:red\">\'\'\'reside in different failure domains\'\'\'</span>. The erasure code work in HDFS could effectively bring down the physical replication factor of a file to about 1.5 (while keeping the logical replication factor at 3) if it can place replicas of all blocks in a stripe more intelligently.\n\n\n: Yet another reason, however exotic, is <span style=\"color:red\">\'\'\'to allow HDFS to place replicas based on the HeatMap\'\'\'</span> of your cluster. If one of of the node in the cluster is at a higher temperature than that of another, then it might be better to prefer the cooler node while allocating a new replica. If you want to experiment with HDFS across two data centers, you might want to try out new policies for replica placement.\n\n\n: Well, now you can finally get your hands wet! <span style=\"color:red\">\'\'\'[https://issues.apache.org/jira/browse/HDFS-385 HDFS-385 (Design a pluggable interface to place replicas of blocks in HDFS)]\'\'\'</span> is part of the Hadoop trunk and will be part of the next major HDFS 0.21 release. This feature provides a way for the adventurous developer to write Java code that specifies how HDFS should allocate replicas of blocks of a file. The API is experimental in nature, and could change in the near future if we discover any in-efficiencies in it. Please let the Hadoop community know if you need any changes in this API or if you come across novel uses of this API. \n\n: Posted by Dhruba Borthakur at 10:41 PM\n\n==== References ====\n\n# [http://developer.yahoo.com/hadoop/tutorial/module1.html#data Apache Hadoop - Data Distribution - Yahoo! Developer Network]\n# [http://developer.yahoo.com/hadoop/tutorial/module2.html Apache Hadoop - The Hadoop Distributed File System]\n# [http://www-01.ibm.com/software/data/infosphere/hadoop/hdfs/ What is the HDFS? - IBM]\n# [https://www.ibm.com/services/forms/signup.do?source=sw-infomgt&S_PKG=500016891&S_CPM=is_bdebook1_hdfs Download the entire eBook: Understanding Big Data]\n# [http://www.aosabook.org/en/hdfs.html The Hadoop Distributed File System - The Architecture of Open Source Applications]\n# [https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0CG4QFjAH&url=http%3A%2F%2Fwww.cse.buffalo.edu%2F~okennedy%2Fcourses%2Fcse704fa2012%2F2.2-HDFS.pptx&ei=WRtkUfz4NOTwiAeq1oGoCA&usg=AFQjCNGLoDZhdDfLkPO1RKcLINvTG7iL9Q&sig2=pvXlwiUJr302_D-BnHrISg&cad=rjt The Hadoop Distributed File System // Konstantin Shvachko, Hairong Kuang, Sanjay Radia, Robert Chansler, Yahoo! Sunnyvale, California USA]\n# [http://storageconference.org/2010/Papers/MSST/Shvachko.pdf \"The Hadoop Distributed File System,\" MSST 2010]\n\n== ## bNote-2013-04-04 ==\n\n=== Data Placement 특허 검색 ===\n\n* [http://bit.ly/YWEiwX 34 results @ Google Patent Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n==== automated storage tiering ====\n\n:* Techniques for automated storage management [http://www.google.com/patents/US8239584 EMC, Filing in Dec 2010]\n:: 전형적 automated storage tiering 기술, I/O operation 분석을 수행하고, 그 결과에 따라 다양한 configuration option들 중 하나를 결정하여 적용.\n:: I/O operation으로부터 hint를 어떻게 추출하는가?\n:: Examples\n:::- I/O 패턴이 Ave I/O size = small, 최소 30% 이상의 random writes가 있는 경우 --> RAID 0 or RAID 1 configuration 적용\n:::- I/O 패턴이 30% 이하의 Writes와 최소 30% 이상의 random I/O가 존재하는 경우 --> RAID 5 configuration 적용\n:::- I/O 패턴이 I/O rate > threshold --> SSD tier configuration 적용\n\n:* System and method for automatic storage load balancing in virtual server environments  [http://www.google.com/patents/EP2248003A1?cl=en NetApp, Filing in Dec 2008]\n:: VM들이 포함된 storage network 환경에서 주기적으로 storage load imbalances를 분석하고 조정하는 기술\n\n==== Information Management in a Networked Environment ====\n:* Environment classification and service analysis [http://www.google.com/patents/US8346748 EMC]\n:: 다양한 서비스가 구동되는 Networked 환경에서, 다양한 정보 수집을 통해 여러 service들을 orchestrate하는 기술\n\n==== Storage Capacity Management ====\n:* Storage capacity management system in dynamic area provisioning storage [http://www.google.com/patents/US8296544, Hitachi, Filing in Apr 2010]\n\n==== Power-saving ====\n:* Methods and apparatus to provision power-saving storage system [http://www.google.com/patents/US8155766 Hitachi]\n\n\n----\n\n* [http://bit.ly/YWE9K2 541 results @ Google Patents Search]\n (inassignee:\"EMC\" OR inassignee:\"NetApp\" OR inassignee:\"Hitachi\" OR inassignee:\"International Business Machines Corporation\") (automated storage (tiering OR tiered)) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDiJb 6 results @ Google Patents Search]\n inassignee:\"Emc Corporation\" (storage tier) (frequent access) (analyze OR analysis OR analyzing)\n\n* [http://bit.ly/YWDkRj 29 results @Google Patents Search]\n inassignee:\"Emc Corporation\" (automated storage (tiering OR tiered)) performance\n\n* [http://bit.ly/YWDp7B 28 results @ Google Patents Search] \n inassignee:\"Emc Corporation\" (storage (tiering OR tiered)) (frequent access)\n\n*\n\n== ## bNote-2013-04-03 ==\n\n=== Convolution, Cross-Correlation, Autocorrelation ===\n\n* [http://en.wikipedia.org/wiki/Convolution Convolution ((B.GOOD))]\n \n\n=== 서울대 산학 특허 리뷰 ===\n\n* Naive Bayesian Classifier\n:- [https://en.wikipedia.org/wiki/Naive_Bayes_classifier Naive Bayes classifier]\n:: Examples - sex classification with features of height, weight, foot size\n\n* Mails\n <pre>\n참고로 아래 메일에서,\n\n본 연구에서 사용된 ML의 input/output data model 및\n\n그것의 구체적인 예를 요청드렸었습니다만,\n\n다음과 같은 것을 생각하고 말씀 드렸었습니다.\n\n \n\n\n(여기에 있는 것은 Wikipedia에 나오는 Naive Bayes Classifier의 예제입니다)\n\n(https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n\nsex height (feet) weight (lbs) foot size(inches) \nmale 6 180 12 \nmale 5.92 (5\'11\") 190 11 \nmale 5.58 (5\'7\") 170 12 \nmale 5.92 (5\'11\") 165 10 \nfemale 5 100 6 \nfemale 5.5 (5\'6\") 150 8 \nfemale 5.42 (5\'5\") 130 7 \nfemale 5.75 (5\'9\") 150 9 \n\n\n \n\nTesting\nBelow is a sample to be classified as a male or female.\n\nsex height (feet) weight (lbs) foot size(inches) \nsample 6 130 8 \n\n\n \n\nWe wish to determine which posterior is greater, male or female. For the classification as male the posterior is given by\n\n    ........... (1)\nFor the classification as female the posterior is given by\n\n ............... (2)\n\n \n\n \n\n키, 몸무게, 발 크기 등의 feature set을 가지고 성별을 판별하는 위 예제의 경우,\n\n위 테이블과 같은 식으로 데이터의 값을 구성하여 training을 시켰을텐데,\n\n우리 연구에서는 어떤 형태의 input data가 구성되어 들어갔을지?\n\n사용되었던 실제 값들이 Table로 보여지면 더욱 좋겠습니다.\n\n정상 진행/비정상 진행 판단에 대한 equation은 어떻게 표현 가능한지? (위의 식 (1), (2) 처럼)\n\n등이 기술되면 좋겠습니다.\n\n \n\n그리고 최종적으로 std_slowdown_per_proc 및 std_total_io_per_proc의 2가지 feature가\n\n중요한 영향력을 가진 것으로 판정되었는데,\n\n그 판정 과정도 같이 기술되어야 할 것 같습니다.\n\n \n\n \n\n \n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 21:46 (GMT+09:00)\n\nTitle : Re: Re: 특허 개정안입니다.\n\n \n\n민영씨, 고생이 많으십니다.\n\n \n\n조금 전에 전화로 이야기 나누었던 것처럼,\n\n좀 더 보강할 필요가 있는 부분들을 아래에 정리해보았습니다.\n\n \n\n한 번 보시고, 궁금하신 사항이 있다면 연락 부탁드립니다.\n\n\nMapReduce 성능에 결정적인 영향을 미치는 병목 원인을\n\n자동적으로 파악할 수 있게 하는 기술로서,\n\n \n\n- 수집된 다양한 정보들을 결합하여\n\n    Straggler를 자동으로 찾아내는 분석 과정이 \n\n    한 단계 더 구체적으로 표현될 수 있으면 좋겠습니다.\n\n    (그리고 이를 위한 시스템 구조 그림 역시 필요)\n\n\n  > 시스템 리소스 상황, 하둡 Conf., Block I/O 정보 등,\n\n      수집된 각각의 정보들을 따로따로 분석하는 것이 아니라, 결합하여 분석하게 될텐데,\n\n      이 결합하여 분석하는 방법을 구체적으로 서술 및 도식화 필요.\n\n      만약 사람이 눈으로 보고 뇌로 판단하는 형태가 아니라,\n\n      기계가 자동적으로 처리하도록 SW로 구현을 한다면\n\n      그 처리 흐름은 구체적으로 어떻게 될 것인지?\n\n      (특히 Table 2에 있는 5개의 Node 정보와, 8개의 Hadoop parameter들,\n\n       9개의 I/O 정보들이 구체적으로 어떻게 결합되어\n\n       분석에 사용되는지가 그림으로 표현되면 좋겠습니다.)\n\n\n  > 이 내용을 SW로 구현한다고 했을 때, 그 SW의 모듈 구성은 어떻게 될 것인지?\n\n     그리고, 그 SW는 시스템의 어느 layer에 위치하며,\n\n     시스템에 있는 어떤 interface와 엮이게 될 것인지 등의\n\n     측면에서도 그림이 나와야 할 것 같습니다.\n\n     예를 들어보면, Ganglia의 어떤어떤 interface를 통해서 어떤 정보를 수집하여,\n\n     그것들을 Hadoop conf. 정보 중 어떤 parameter와 결합하여 분석을 하게 될 텐데,\n\n     이를 수행하는 모듈들이 그림으로 표현될 수 있을 것 같습니다.\n  \n\n\n- 그리고 추가적으로 기술되어야 할 항목들이 있습니다.\n\n \n\n(1) 병목 현상 파악을 위한 Machine Learning 알고리즘으로서 어떤 것을 사용했는지?\n\n      이번 연구에서 사용된 Naive Bayesian은 어떤 의미를 갖는 알고리즘인지?\n\n      어떤 입력을 받아서 어떤 결과값을 내어주는 알고리즘이며,\n\n      그 결과값의 해석은 어떻게 할 수 있는지?\n\n      (Supervised Learning이었다면, 어떤 식으로 Supervise를 해주었는지?) \n\n \n\n(2) ML 알고리즘의 input으로 사용하기 위해,\n\n     어떠한 Raw 데이터에 어떤 처리가 이루어졌는지?\n\n     학습 모델을 그림으로 표현 필요.\n\n     input/output 데이터 모델/타입을 그림 혹은 Table로 표현 필요.\n\n     (예를 들어, Raw Data가 Non-numeric 타입이었다고 하더라도,\n\n       SVM이나 K-means등을 사용하기 위해서는, numerical data로\n\n       encoding/representation을 해줄 필요가 있는데,\n\n       이번 ML에서는 어떤 식으로 데이터를 처리했는지?)\n\n\n------- Original Message -------\n\nSender : 정명준<brian.m.jung@samsung.com> 전문연구원/Intelligence그룹(기술원)/삼성전자\n\nDate : 2013-04-03 20:28 (GMT+09:00)\n\nTitle : Re: 특허 개정안입니다.\n\n \n\n성민영씨, 안녕하세요?\n\n보내주신 문서 잘 보았습니다.\n\n \n\n혹시 지금 잠시 통화 가능하신지요?\n\n아니면 통화 가능한 시간을 알려주셔도 좋습니다.\n\n \n\n감사합니다.\n\n정명준 드림.\n\n \n\n \n\n------- Original Message -------\n\nSender : Minyoung Sung<eunice.sung87@gmail.com>\n\nDate : 2013-04-03 16:20 (GMT+09:00)\n\nTitle : 특허 개정안입니다.\n\n \n\n안녕하세요 정전문님, 성민영입니다. \n\n특허 개정안을 첨부하였으니 검토해주시고 피드백 부탁드립니다.\n\n감사합니다.\n\n\n\n-- \n\n성민영 드림\nmysung@dcslab.snu.ac.kr\n \n</pre>\n\n== ## bNote-2013-04-02 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Per \"process_id\" plot\n\n\n\n=== SR-IOV, MR-IOV ===\n\n* [http://searchstorage.techtarget.com/video/I-O-virtualization-video-SR-IOV-MR-IOV-NICs-and-more I/O virtualization video: SR-IOV, MR-IOV, NICs and more ((B.GOOD)) // 2012-09-17]\n* [http://blog.scottlowe.org/2009/12/02/what-is-sr-iov/ What is SR-IOV? ((B.GOOD)) // 2009-12-02]\n\n\n\n=== Linux VM and SBC NAS ===\n\n* NAS (ETRI GloryFS 기반) 사용 방법\n\n <pre>\nFrom: Jaewook Oh [mailto:jaew00k.oh@samsung.com] \nSent: Tuesday, April 02, 2013 5:06 PM\nTo: 정명준\nSubject: Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n----\n\n안녕하세요 전문님,\n \n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n \n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n \nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n \n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n</pre>\n\n== ## bNote-2013-04-01 ==\n\n=== Dominant I/O Pattern Mining ===\n\n* Objectives\n:- To find any interesting relationship between X\'s and Y\'s\n:- To find any cause-and-effect relationship between two or more types of information/data which reside in the different moment of time\n\n==== Processing T031 ====\n:- Analyze the distribution of each field item\n <pre>\na1mjjung@secm:[tdir] $ cat proc_T031.sh \n#!/bin/sh\n##proc_T031.sh\n##_ver=20130401_194105\n\n\n_infile=\"T011.msn_filesrvr.out\";\n\n\n_fld_dstr()\n{\n	if [ \"X$_field_num\" = \"X\" ]; then\n		echo \"_field_num is empty -- EXIT\";\n		exit 1;\n	fi\n	if [ \"X$_field_name\" = \"X\" ]; then\n		echo \"_field_name is empty -- EXIT\";\n		exit 1;\n	fi\n	\n	_logfile=\"T031.fld_dstr.$_field_name.log\";\n	echo -n \">>> Creating \'$_logfile\' ... $(tstamp) -> \";\n	cat $_infile | cut -d \',\' -f $_field_num | sort | uniq -c | sort -n > $_logfile;\n	tstamp;\n}\n\n\n_field_num=3; _field_name=\"process_id\"; _fld_dstr;\n_field_num=4; _field_name=\"thread_id\"; _fld_dstr;\n_field_num=5; _field_name=\"address\"; _fld_dstr;\n_field_num=7; _field_name=\"file_obj\"; _fld_dstr;\n_field_num=8; _field_name=\"full_path\"; _fld_dstr;\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ ./proc_T031.sh \n>>> Creating \'T031.fld_dstr.process_id.log\' ... 20130401_192754 -> 20130401_192825\n>>> Creating \'T031.fld_dstr.thread_id.log\' ... 20130401_192825 -> 20130401_192902\n>>> Creating \'T031.fld_dstr.address.log\' ... 20130401_192902 -> 20130401_192946\n>>> Creating \'T031.fld_dstr.file_obj.log\' ... 20130401_192946 -> 20130401_193029\n>>> Creating \'T031.fld_dstr.full_path.log\' ... 20130401_193029 -> 20130401_193110\n</pre>\n\n <pre>\na1mjjung@secm:[tdir] $ wc -l T031.fld_dstr.*\n  7425792 T031.fld_dstr.address.log\n      670 T031.fld_dstr.file_obj.log\n     2988 T031.fld_dstr.full_path.log\n      119 T031.fld_dstr.process_id.log\n      819 T031.fld_dstr.thread_id.log\n  7430388 total\n</pre>\n\n==== Comparison between T02x and T031 ====\n <pre>\na1mjjung@secm:[tdir] $ wc -l T011.msn_filesrvr.out T02*\n  29345085 T011.msn_filesrvr.out\n  29345085 T020.msn_filesrvr.A.out\n  19729611 T021.msn_filesrvr.R.out\n   9615474 T022.msn_filesrvr.W.out\n  88035255 total\n</pre>\n\n==== Discovery based on T031 (distribution characteristics for each field) ====\n\n* fld_dstr.process_id\n\n <pre>\na1mjjung@secm:[tdir] $ cat T031.fld_dstr.process_id.log \n      1     p10 ( 620)   \n      1     p5 (4292)   \n      1     p6 ( 976)   \n      1     p6 (4748)   \n      1     p7 ( 580)   \n      1     p7 ( 664)   \n      1     p7 (4640)   \n      1     p7 (4912)   \n      1     p8 (4460)   \n      1     p9 (7768)   \n      2     p10 ( 664)   \n      2     p4 (7768)   \n      2     p5 ( 976)   \n      2     p5 (7768)   \n      2     p6 (9748)   \n      2     p7 (3424)   \n      2     p7 (9748)   \n      2     p8 (3424)   \n      2     p8 (5648)   \n      2     p9 ( 676)   \n      3     p6 (3424)   \n      3     p9 (11100)   \n      4     p10 (3908)   \n      4     p9 (3424)   \n      6     p10 (1944)   \n      7     p6 ( 664)   \n      7     p8 (1944)   \n      8     p2 ( 676)   \n      8     p7 (4748)   \n     10     p2 ( 664)   \n     11     p5 ( 664)   \n     11     p8 ( 620)   \n     12     p9 (1944)   \n     13     p11 (1292)   \n     14     p6 ( 380)   \n     14     p6 (10368)   \n     17     p10 (1292)   \n     17     p6 ( 676)   \n     21     p8 (6432)   \n     23     p3 ( 676)   \n     33     p8 ( 676)   \n     34     p8 (7160)   \n     34     p8 (9752)   \n     34     p8 (9924)   \n     34     p9 (1292)   \n     35     p9 (6576)   \n     38     p5 ( 676)   \n     41     p10 (5464)   \n     41     p8 ( 712)   \n     41     p8 (10452)   \n     41     p8 (10908)   \n     41     p8 (3564)   \n     41     p8 (7808)   \n     41     p8 (7904)   \n     41     p8 (8484)   \n     41     p8 (9376)   \n     41     p8 (9956)   \n     41     p9 (10260)   \n     41     p9 (9980)   \n     42     p8 (2164)   \n     42     p8 (6412)   \n     42     p8 (7444)   \n     42     p8 (9408)   \n     42     p8 (9480)   \n     42     p9 (10968)   \n     42     p9 (3612)   \n     42     p9 (5856)   \n     42     p9 (8408)   \n     43     p9 (10592)   \n     43     p9 (8772)   \n     48     p10 (7056)   \n     48     p10 (7780)   \n     48     p8 (11020)   \n     48     p8 (5644)   \n     49     p10 (8588)   \n     49     p10 (9684)   \n     49     p8 (1012)   \n     49     p8 (8812)   \n     49     p9 (4324)   \n     49     p9 (8224)   \n     50     p8 (10088)   \n     55     p8 ( 392)   \n     55     p8 (7144)   \n     55     p9 (3920)   \n     56     p10 (8840)   \n     56     p8 (6680)   \n     56     p9 (10532)   \n     57     p4 ( 676)   \n     58     p3 ( 664)   \n     63     p7 ( 676)   \n     63     p9 (9420)   \n     64     p10 (9300)   \n     65     p10 (10376)   \n     71     p6 (1944)   \n     71     p9 (6436)   \n     72     p4 (1944)   \n     72     p9 (8132)   \n     76     p6 (8052)   \n     78     p9 ( 392)   \n     90     p4 (1216)   \n    118     p7 (1292)   \n    119     p5 (1944)   \n    126     p4 ( 664)   \n    184     p7 (1944)   \n    260     p7 ( 392)   \n    263     p5 (1216)   \n    322     p5 ( 392)   \n    325     p6 ( 392)   \n    477     p3 (10292)   \n    584     p1 (1500)   \n    646     p1 (1216)   \n    826     p2 (1216)   \n    972     p4 (1500)   \n   1428     p3 (1216)   \n   2512     p3 (1500)   \n   2900     p2 (1500)   \n  37866     p2 ( 4)   \n  78975     p1 ( 4)   \n29212972     p0 (2004) \n</pre>\n\n=== EMC Price List ===\n\n* [http://www.kernelsoftware.com/products/catalog/emc.html EMC Price List as of 18 Mar 2013]\n* [http://www.emc.com/collateral/emcwsca/master-price-list.pdf EMC WSCA Contract B27161 Price List // Effective December 1, 2012]\n* [http://storagemojo.com/storagemojos-pricing-guide/emc-price-list/ EMC Price List // StorageMojo]\n\n=== 서울대 산학 특허 리뷰 ===\n\n* Mail Sent\n\n조인순 박사님, 성민영씨, 안녕하세요?\n주말에 정말 고민/고생 많으셨습니다. ^^;;\n이제 \'GOAL\' 라인이 얼마 남지 않았네요~\n조금만 더 같이 노력하면 좋은 결과 얻을 수 있을 거라고 \'강하게\' 믿습니다!!! ^____^\n\n저의 작은 의견을 아래와 같이 보내드리오니\n연구/업무에 참고하시기 바라겠습니다.\n\n전반적으로,\n제안하는 본 발명이, 기존 기술과는 결정적으로 어느 부분이 \'차별화\'되며,\n그 차별점으로 인해 (어떤 원리에 의해서), 어느 정도 수준의 \'문제점 혁신/개선\'이 이루어질 수 있는지가\n보강되면 좋겠습니다.\n\n이렇게 되면 본 발명의 존재 가치에 대한 설득력이 크게 강화될 것 같습니다.\n(설득 대상: 기술원 내부 특허 심사, 그리고 Patent Office)\n\n다음은 좀 더 상세한 의견/가이드라인입니다.\n\n\n1. 비교대상이 되는 기존 기술 비교\n: 현재 버전의 문서에는 아직 미기재되어 있습니다만, 다음 내용이 추가되어야 합니다.\n\n:* 검색 식 및 검색 결과\n::- 검색 식도 나름 자세하게 기술되어야 합니다. (case-by-case 이겠습니다만, 통상적으로 검색 결과가 대략 수십건 이내로 떨어지도록 작성된 식이면 될 것 같습니다. 검색 결과 뿐만 아니라 검색 식도 같이 기재하는 이유는 정말 관련 특허가 검색되지 않는 경우도 있을 수 있기 때문에, 이를 뒷받침하기 위함입니다)\n::- 검색을 수행한 patent search site도 명시 부탁합니다 - e.g., Google Search, US PTO Search, ...\n\n:* 기술 비교\n::- 검색 결과 들 중, 특히 관련이 있는 것을 선정 후, 제안하는 발명과 비교.\n:::- 이 때, 가급적 apparatus (장치구조) 측면과 method (방법/순서도) 측면으로 구분하여 비교해주시면 좋습니다. 일반적으로 \'방법\'이 위주가 되는 알고리즘에 대한 특허라 하더라도 가급적이면 \'장치\'처럼 모듈 다이어그램이 있으면 특허로 \'등록\' 되기에 좀 더 수월합니다. 즉, 본 알고리즘/방법이 어떤 식으로 \'모듈\'화 되어, 시스템 내에서 어느 부분에 적용될 수 있고, 기존 대비 이러이러한 측면에서 구조적 차이가 있다는 식으로 설명될 수 있다면 좋습니다.\n:::- 당연히 \'방법\' 측면의, 차이가 있다면 그 부분도 다이어그램, 혹은 순서도등을 활용하여 명확히 차이를 짚어줄 필요가 있습니다. \n:::- 결국, 본 발명의 존재 가치를 설명하게 되는 것인데, 상세한 내용들은 뒤의 Section 2에서 자세하게 설명이 나올 것이므로, 이 Section 1에서는 핵심만을 요약해준다는 느낌으로 작성이 되면 좋겠습니다.\n\n\n2. 제안 기술 (본 발명)의 차별적 특징 및 그로인한 문제 개선 효과\n: 이 부분에 대한 도면과 기술(description)이 특히 강화가 되면 좋겠습니다.\n\n:* Section 1에서 요약되어 언급이 되긴 합니다만, 본격적으로 본 발명에 대한 존재 가치를 설명해주는 부분입니다. 가급적 도면을 많이 사용하여 메커니즘을 설명하고, 기존 기술 대비 차이점을 부각하는 것이 중요합니다. 그리고 그 차이로 인해서 어떤 장점/가치를 얻게 되는지가 명확하게 설명이 되면 좋겠습니다. 이를 통해 구조적인 특징/차별점과 방법을 심사위원들에게 설득하게 되므로 이 부분의 작성이 매우 중요합니다. (현재 그림-1,2,3 으로는 이러한 힘을 갖는 메시지가 잘 보이지 않으므로, 본 발명만의 차별적인 apparatus 및 method 측면을 잘 설명하는 그림들이 잘 나오는 것이 매우 중요합니다)\n \n:* 그리고 이 발명의 가치를 설명해주는 핵심 그림들이 몇 개가 존재하겠지만, 그 중에서도 대표 도면으로 세울 수 있는, 이 발명만의 차별적 특징을 가장 잘 담는 그림을 하나 선정해서 표기 부탁드립니다.\n\n\n3. 실험 결과\n\n:* 위에서 설명되고 주장된 내용들을 뒷받침할 수 있는 근거들이 실험 결과로서 제시되면 좋겠습니다.\n:* 그러나 현재 남은 일정 상, 추가로 실험을 더 하는 것은 무리일 수 있으므로, 기존의 실험 결과들이 이 특허의 존재가치로 잘 이어질 수 있도록, description을 매끄럽게 만들어주시면 좋겠습니다.\n\n\n4. 침해 적발\n\n:* 어떻게 하면 본 발명에 대한 침해 사실을 적발할 수 있는지에 대한 description이 상세히 기술되어야 합니다. 예전보다 이 침해적발 측면의 질문도 많이 까다로와졌는데요, 그냥 \"SW debugging으로 확인 가능합니다\", \"network traffic sniffing해서 protocol analyzer로 확인 가능합니다\" 수준으로 이야기하면 안되고, 그보다 한 단계 깊이 이야기를 해줄 수 있어야 합니다. 이 부분도 잘 정리가 되어야 합니다.\n\n \n우선 이 정도만 잘 되어도 크게 좋아질 것 같습니다.\n목요일 최종 제출 전에 수요일 정도라도 미리 \'중간\'본을 한 번 보내주셔도 좋습니다.\n그러면 \'도면\' 및 \'순서도\' 등에 대해서 추가 의견을 드릴 수 있을 것 같습니다.\n\n끝까지 성심으로 노력해주셔서 감사합니다.\n- 정명준 드림 -\n\n=== Automated Storage System Tiering // (c)2011 Evaluator Group, Inc. ===\n\n* Article [http://www.evaluatorgroup.com/wp-content/uploads/2011/03/EGI_Tiering_Comparison_Preso.pdf]\n\n* Agenda\n:- Tiering Technology for Selected Vendors\n::- Tiering vs. Cache\n:- Tiering Implementation & Messaging for Selected Vendors\n::- Compellent\n::- Dell EqualLogic\n::- EMC VNX\n::- EMC VMAX\n::- HP 3PAR\n::- HDS VSP\n::- IBM (DS8000 & V7000)\n::- NetApp\n::- Xiotech\n\n* Tiering vs. Caching\n:- Storage Tiers\n::- Implies a particular price and performance metric (?)\n::- Provides actual capacity\n::- All content resides on media\n::- Performance is limited only to media speed\n::- May be improved with Caching\n:- Caching\n::- Not considered as actual storage\n::- All capacity must be backed by non volatile media\n::- Performance limited to size of cache\n::- Limited use for random workloads\n\n* Flash as Cache\n:- Pros\n::- Relatively low cost way to add performance\n::- Automated, very little tuning required\n::- Highly effective for sequential read workloads\n::- Somewhat effective for random write workloads\n:- Cons\n::- Not as effective for random workloads, particularly reads\n::- Adds cost, without adding capacity\n::- More workloads are becoming more random\n:::- VMware drives seemingly random workloads to storage\n:::- VDI workloads are moderately random\n\n\n=== 만우절 뉴스 ===\n\n* [http://www.storagenewsletter.com/news/people/emc-and-netapp-exchange-ceo EMC and NetApp Exchange CEO: Tucci Replaces Georgens and Vice Versa]\n* [http://www.google.com/landing/nose/ Google Nose]\n\n=== 과제 정보 업데이트 ===\n\n과제명: Intelligent Large-scale Data Management\n: (구과제명) Real-Time Big Data Platform\n\n <pre>\n□ 부회장님 지시사항\n응용 Target을 명확화하고, 경쟁 우위 확보 가능한 목표를 설정할 것\n\n□ 지시사항에 따른 변경내용\n응용 Target을 스토리지 시스템 신사업으로 집중하여 경쟁사 대비 차별화가 가능한 \n핵심 Seed 기술에 집중하기로 함. \n\n□ 과제의 목적\n   - 데이터의 특성 발견 및 학습에 기반한 지능적 분산 데이터 관리기술 확보\n : 스토리지 시스템의 데이터 Access 성능 혁신을 위한 데이터 I/O 패턴 예측에 기반 \n   Proactive Data Placement 기술 \n : 스토리지 시스템의 저장효율 극대화를 위한 데이터의 유사성 학습 기반 데이터 \n   Deduplication 기술\n\n□ 기대되는 Business Impact\n   - 스토리지 시스템은 \'16년 1,000억불 이상이 예측되는 대규모이고 안정적인 시장임\n   - 당사는 기존 NAND/SSD 부품사업에서 고부가 시스템사업으로 Value Chain을 확장 계획 \n (신사업추진단 TF에서 스토리지 시스템 신사업 기획 중)\n\n□ Goals\n   - 데이터 I/O 속도 향상 : HW RAID대비 80% 이상(\'13), 400% 이상(\'15)\n   ※ 경쟁사 : 15%(RedHat사)\n- 데이터 저장 효율 향상 : 중복제거효율 3배@Coverage 4node(\'13), 10배@100node(\'15)\n※ 경쟁사 : 3배@4node(SolidFire사) (올해는 경쟁사 동등수준을 목표로 함. )\n\n□ Challenges\n- 복잡하고 시간에 따라 변화하는 데이터 Access Log로부터 숨겨진 패턴의 발견 및 학습.\n- 대규모 스토리지 시스템에서 분산되어 있는 데이터의 효율적인 Clustering.  \n</pre>\n\n=== Trace Data 저장용 Linux VM 및 대용량 스토리지 (10TB) ===\n\n\n\n\n\n==== Linux VM 및 대용량 스토리지 사용 정보 ====\n\n <pre>\n------- Original Message -------\n\nSender : Jaewook Oh<jaew00k.oh@samsung.com> S5/Senior Engineer/R&D Infrastructure Group/Samsung Electronics\n\nDate : 2013-04-02 17:05 (GMT+09:00)\n\nTitle : Re: Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n\n안녕하세요 전문님,\n\n우분투 12.xx 지원이 여의치 않아 일단 11.10으로 할당 진행하였습니다.\n\n첨부된 패키지 및 fuse 패키지(배포된 이미지에 설치되어 있을것으로 예상됩니다...)  설치 후,\n\nmount.ifs 75.2.251.181:/FSM2/fit_icl 마운트될곳 -obigwrite\n\n명령어로 마운트하시면 되며, 패스워드를 물어보는데 secicl123 입력하시면 됩니다.\n\n\n------- Original Message -------\n\nSender : Chae Hwan Lim<ch2036.lim@partner.samsung.com> Partner/Cloud Platform Operation Group/SAMSUNG SDS\n\nDate : 2013-04-02 16:57 (GMT+09:00)\n\nTitle : Re: [결재 통보][SBC 자원신청]실험 데이터 보관 및 전처리 작업 수행을 위한 Linux VM 신청\n\n안녕하세요 클라우드플랫폼운영그룹 임채환대리입니다.\n\n신청하신 VM을 할당 완료 하였습니다.\n\n리눅스의 경우 escort가 적용이 되지 않기 때문에 \n\nescort예외 신청을 하셔야 네트웍을 사용할 수 있습니다...\n\nIP및 ID, password는 아래와 같습니다...\n\n좋은하루되십시오...\n\n==============================\n\nIP : 75.2.252.71\n\nID : root\n\nPW: 개발100%#&\n\nVNC접속(5900) PW : qwe123\n\n접속 PORT : 22(SSH)\n                  3389(RDP)\n\n- 신청 메뉴 : IT4U - ESCORT예외신청 - 설치예외(삭제) - ESCORT 삭제 불필요\n\n - 사업장 : 종합기술원 - 종합기술원\n\n - 제조번호, 모델명 : VMware\n\n - 대상구분 : PC\n\n - 신청항목 : 인터넷 사용\n\n - OS 구분 : Linux 계열\n\n - 신청 항목중 IP / MAC 주소 입력하는 부분에서 확인은 \n\n - 터미널 모드에서 ifconfig  입력 -> \n   \n   MAC 주소는 HWaddr : 00:xx~~ 시작되는 값주소\n   \n   IP 주소는 inet addr : 75.2.252.X 주소값 입니다.\n\n감사합니다.\n\n</pre>','utf-8');
/*!40000 ALTER TABLE `mw_text` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `mw_trackbacks`
--

DROP TABLE IF EXISTS `mw_trackbacks`;
